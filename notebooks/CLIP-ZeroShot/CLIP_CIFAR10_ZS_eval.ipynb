{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "new-repo-CLIP_CIFAR10_ZS_eval.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RGlVnbugxFK2",
        "OLU-gp7n8__E",
        "9z1WQnXdLHy2",
        "UxTa8MVsvQCN",
        "iLbRqaYxzbr7",
        "lLW-8vrbrU5f",
        "vrit1GAzrU5u",
        "B5G7GsGDrU5u",
        "YnvVBO2brU5u",
        "RlIMyHeVfFEE",
        "7HPn06QE39N8",
        "M9dYlVFDF_vs",
        "Sph7dLY0fTHh"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wCVCAfpyE0A"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-7JU3Q7q_XT",
        "outputId": "73fb4aa1-1566-4310-b654-1a25398bc1a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXAPOzOK4mTl",
        "outputId": "f2077a3c-5779-4d69-8e7b-d83d88e0ee47"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Cloning CLIPPER to access modules.\n",
        "if 'CLIPPER' not in os.listdir():\n",
        "    cmd_string = 'git clone https://github.com/PAL-ML/CLIPPER.git'\n",
        "    os.system(cmd_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting httplib2==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/83/5e006e25403871ffbbf587c7aa4650158c947d46e89f2d50dcaf018464de/httplib2-0.15.0-py3-none-any.whl (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 22.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30kB 26.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 40kB 21.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 51kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 61kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 71kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 81kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 13.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 7.2MB/s \n",
            "\u001b[?25hInstalling collected packages: httplib2\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed httplib2-0.15.0\n",
            "Github User name: ashadhaz\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlVnbugxFK2"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmgIrfT8hDNE"
      },
      "source": [
        "## Install multi label metrics dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6xXPAFbe6Gp",
        "outputId": "cdd9e530-07f5-4417-80da-9b47f726d0eb"
      },
      "source": [
        "! pip install scikit-learn==0.24"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==0.24 in /usr/local/lib/python3.7/dist-packages (0.24.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKe3HqM523g"
      },
      "source": [
        "## Install CLIP dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poS-WNDixIhY",
        "outputId": "17c54596-a4ee-478b-9b88-f45e3ce20f09"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA version: 11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA-69W8M59nA",
        "outputId": "57002f73-82b4-4e40-c4b7-a9359c11c69f"
      },
      "source": [
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.7.1+cu110 in /usr/local/lib/python3.7/dist-packages (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision==0.8.2+cu110 in /usr/local/lib/python3.7/dist-packages (0.8.2+cu110)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYwBZS1N6A3d",
        "outputId": "ca40901a-1a83-474d-f25a-bafcc3157e01"
      },
      "source": [
        "! pip install ftfy regex\n",
        "! wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "--2021-05-19 07:45:23--  https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.67, 13.107.213.67, 2620:1ec:29::67, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘bpe_simple_vocab_16e6.txt.gz’\n",
            "\n",
            "bpe_simple_vocab_16 100%[===================>]   1.29M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-19 07:45:23 (22.9 MB/s) - ‘bpe_simple_vocab_16e6.txt.gz’ saved [1356917/1356917]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oIcNBYB8lz3",
        "outputId": "34c80582-97a6-41b7-97ac-700ef1b01726"
      },
      "source": [
        "!pip install git+https://github.com/Sri-vatsa/CLIP # using this fork because of visualization capabilities"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Sri-vatsa/CLIP\n",
            "  Cloning https://github.com/Sri-vatsa/CLIP to /tmp/pip-req-build-o9y6_oun\n",
            "  Running command git clone -q https://github.com/Sri-vatsa/CLIP /tmp/pip-req-build-o9y6_oun\n",
            "Requirement already satisfied (use --upgrade to upgrade): clip==1.0 from git+https://github.com/Sri-vatsa/CLIP in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Requirement already satisfied: torch~=1.7.1 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision~=0.8.2 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.8.2+cu110)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368623 sha256=38fcd22d19ddff90573e7aa71cfc59b6799273f591a069687cfd45c4051870fe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mmhh2fnc/wheels/cc/55/69/0d411dabbd5009fd069d47b47cf7839c54e595dc61725b307b\n",
            "Successfully built clip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-gp7n8__E"
      },
      "source": [
        "## Install clustering dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLg9ozo9Hvc"
      },
      "source": [
        "!pip -q install umap-learn>=0.3.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1WQnXdLHy2"
      },
      "source": [
        "## Install dataset manager dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1vvMx7_LLSp",
        "outputId": "2202e79a-6579-44e7-a6e0-abdb935c7044"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzsubsEm72rr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZI62a6G74kw"
      },
      "source": [
        "# ML Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import keras\n",
        "\n",
        "# Data processing\n",
        "import PIL\n",
        "import base64\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from matplotlib import cm\n",
        "\n",
        "# Models\n",
        "import clip\n",
        "\n",
        "# Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Misc\n",
        "import progressbar\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Modules\n",
        "from CLIPPER.code.ExperimentModules import embedding_models\n",
        "from CLIPPER.code.ExperimentModules import simclr_data_augmentations\n",
        "from CLIPPER.code.ExperimentModules.dataset_manager import DatasetManager\n",
        "from CLIPPER.code.ExperimentModules.clip_few_shot import CLIPFewShotClassifier\n",
        "from CLIPPER.code.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)\n",
        "\n",
        "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_gxQ0KbwMh"
      },
      "source": [
        "# Initialization & Constants\n",
        "\n",
        "**Edited**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bih5tBPdbx3u",
        "outputId": "ac0506dd-895a-4a29-f212-f05d2e5d5d97"
      },
      "source": [
        "dataset_name = 'CIFAR10'\n",
        "folder_name = \"CIFAR10-Embeddings-28-02-21\"\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1bK72W-Um20EQDEyChNhNJthUNbmoSEjD'\n",
        "\n",
        "# Filepaths\n",
        "# train_labels_filename = \"train_labels.npz\"\n",
        "test_labels_filename = \"test_labels.npz\"\n",
        "\n",
        "# train_embeddings_filename_suffix = \"_embeddings_train.npz\"\n",
        "test_embeddings_filename_suffix = \"_embeddings_test.npz\"\n",
        "\n",
        "\n",
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = create_expt_dir(drive, parentid, folder_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: CIFAR10-Embeddings-28-02-21, id: 1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n",
            "Experiment folder already exists. WARNING: Following with this run might overwrite existing results stored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxTa8MVsvQCN"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6S124Jfwuu5",
        "outputId": "3643ced0-5278-40cd-93f8-09c91d231d4e"
      },
      "source": [
        "def get_ndarray_from_drive(drive, folderid, filename):\n",
        "    download_file_by_name(drive, folderid, filename)\n",
        "    return np.load(filename)['data']\n",
        "\n",
        "# train_labels = get_ndarray_from_drive(drive, folderid, train_labels_filename)\n",
        "test_labels = get_ndarray_from_drive(drive, folderid, test_labels_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading test_labels.npz from GDrive\n",
            "Downloading test_labels.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p2JpaGHmqbl"
      },
      "source": [
        "dm = DatasetManager()\n",
        "\n",
        "test_data_generator = dm.load_dataset('cifar10', split='test')\n",
        "\n",
        "class_names = dm.get_class_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLbRqaYxzbr7"
      },
      "source": [
        "# Create label dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emz85fNX0Vif",
        "outputId": "99ac2681-b6d3-471e-f90a-dab0c4c77eb3"
      },
      "source": [
        "unique_labels = np.unique(test_labels)\n",
        "print(len(unique_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TubS-RLzeVM"
      },
      "source": [
        "label_dictionary = {la:[] for la in unique_labels}\n",
        "\n",
        "for i in range(len(test_labels)):\n",
        "    la = test_labels[i]\n",
        "\n",
        "    label_dictionary[la].append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP6ftkDCvKul"
      },
      "source": [
        "# CLIP zero shot eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJIGo_R86GQi"
      },
      "source": [
        "## Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv68q8TH6tvG"
      },
      "source": [
        "def start_progress_bar(bar_len):\n",
        "    widgets = [\n",
        "        ' [', \n",
        "        progressbar.Timer(format= 'elapsed time: %(elapsed)s'), \n",
        "        '] ', \n",
        "        progressbar.Bar('*'),' (', \n",
        "        progressbar.ETA(), ') ', \n",
        "        ]\n",
        "    pbar = progressbar.ProgressBar(\n",
        "        max_value=bar_len, widgets=widgets\n",
        "        ).start()\n",
        "\n",
        "    return pbar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtoopzLRStTO"
      },
      "source": [
        "def prepare_indices(\n",
        "    num_ways,\n",
        "    num_shot,\n",
        "    num_eval,\n",
        "    num_episodes,\n",
        "    label_dictionary,\n",
        "    test_labels,\n",
        "    shuffle=False\n",
        "):\n",
        "    eval_indices = []\n",
        "    train_indices = []\n",
        "    wi_y = []\n",
        "    eval_y = []\n",
        "\n",
        "    label_dictionary = {la:label_dictionary[la] for la in label_dictionary if len(label_dictionary[la]) >= (num_shot+num_eval)}\n",
        "    unique_labels = list(label_dictionary.keys())\n",
        "\n",
        "    pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "    for s in range(num_episodes):\n",
        "        # Setting random seed for replicability\n",
        "        np.random.seed(s)\n",
        "\n",
        "        _train_indices = []\n",
        "        _eval_indices = []\n",
        "\n",
        "        selected_labels = np.random.choice(unique_labels, size=num_ways, replace=False)\n",
        "        for la in selected_labels:\n",
        "            la_indices = label_dictionary[la]\n",
        "            select = np.random.choice(la_indices, size = num_shot+num_eval, replace=False)\n",
        "            tr_idx = list(select[:num_shot])\n",
        "            ev_idx = list(select[num_shot:])\n",
        "\n",
        "            _train_indices = _train_indices + tr_idx\n",
        "            _eval_indices = _eval_indices + ev_idx\n",
        "\n",
        "        if shuffle:\n",
        "            np.random.shuffle(_train_indices)\n",
        "            np.random.shuffle(_eval_indices)\n",
        "\n",
        "        train_indices.append(_train_indices)\n",
        "        eval_indices.append(_eval_indices)\n",
        "\n",
        "        _wi_y = test_labels[_train_indices]\n",
        "        _eval_y = test_labels[_eval_indices]\n",
        "\n",
        "        wi_y.append(_wi_y)\n",
        "        eval_y.append(_eval_y)\n",
        "\n",
        "        pbar.update(s+1)\n",
        "        \n",
        "    return train_indices, eval_indices, wi_y, eval_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M5aHABX7k8a"
      },
      "source": [
        "def embed_images(\n",
        "    embedding_model, \n",
        "    train_indices, \n",
        "    num_augmentations,\n",
        "    trivial=False\n",
        "    ):\n",
        "\n",
        "    def augment_image(image, num_augmentations, trivial):\n",
        "        \"\"\" Perform SimCLR augmentations on the image\n",
        "        \"\"\"\n",
        "\n",
        "        if np.max(image) > 1:\n",
        "            image = image/255\n",
        "\n",
        "        augmented_images = [image]\n",
        "\n",
        "        # augmentations = iaa.Sequential([\n",
        "        #     iaa.Affine(\n",
        "        #         translate_percent={'x':(-0.1, 0.1), 'y':(-0.1, 0.1)}, \n",
        "        #         rotate=(-15, 15),\n",
        "        #         shear=(-15, 15),\n",
        "        #     ),\n",
        "        #     iaa.Fliplr(0.5) \n",
        "        # ])\n",
        "\n",
        "        def _run_filters(image):\n",
        "            width = image.shape[1]\n",
        "            height = image.shape[0]\n",
        "            image_aug = simclr_data_augmentations.random_crop_with_resize(\n",
        "                image,\n",
        "                height,\n",
        "                width\n",
        "                )\n",
        "            image_aug = tf.image.random_flip_left_right(image_aug)\n",
        "            image_aug = simclr_data_augmentations.random_color_jitter(image_aug)\n",
        "            image_aug = simclr_data_augmentations.random_blur(\n",
        "                image_aug,\n",
        "                height,\n",
        "                width\n",
        "                )\n",
        "            image_aug = tf.reshape(image_aug, [image.shape[0], image.shape[1], 3])\n",
        "            image_aug = tf.clip_by_value(image_aug, 0., 1.)\n",
        "\n",
        "            return image_aug.numpy()\n",
        "\n",
        "        for _ in range(num_augmentations):\n",
        "            # aug_image = augmentations(image=image)\n",
        "\n",
        "            if trivial:\n",
        "                aug_image = image\n",
        "            else:\n",
        "                aug_image = _run_filters(image)\n",
        "            augmented_images.append(aug_image)\n",
        "\n",
        "        augmented_images = np.stack(augmented_images)\n",
        "        return augmented_images\n",
        "\n",
        "    embedding_model.load_model()\n",
        "\n",
        "    unique_indices = np.unique(np.array(train_indices))\n",
        "\n",
        "    ds = dm.load_dataset('cifar10', split='test')\n",
        "    embeddings = []\n",
        "    IMAGE_IDX = 'image'\n",
        "    pbar = start_progress_bar(unique_indices.size+1)\n",
        "    num_done=0\n",
        "    for idx, item in enumerate(ds):\n",
        "        if idx in unique_indices:\n",
        "            image = item[IMAGE_IDX]\n",
        "            if num_augmentations > 0:\n",
        "                aug_images = augment_image(image, num_augmentations, trivial)\n",
        "            else:\n",
        "                aug_images = image\n",
        "            \n",
        "            processed_images = embedding_model.preprocess_data(aug_images)\n",
        "            embedding = embedding_model.embed_images(processed_images)\n",
        "            embeddings.append(embedding)\n",
        "            \n",
        "            num_done += 1\n",
        "            pbar.update(num_done+1)\n",
        "\n",
        "        if idx == unique_indices[-1]:\n",
        "            break\n",
        "\n",
        "    embeddings = np.stack(embeddings)\n",
        "\n",
        "    return unique_indices, embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyW-G0AD5_rn"
      },
      "source": [
        "def evaluate_model_for_episode(\n",
        "    model,\n",
        "    eval_x,\n",
        "    eval_y,\n",
        "    label_mapping,\n",
        "    filtered_classes,\n",
        "    metrics=['hamming', 'jaccard', 'subset_accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'top1_accuracy', 'top5_accuracy', 'classwise_accuracy', 'c_accuracy'],\n",
        "    multi_label=True\n",
        "):\n",
        "    zs_weights = model.zeroshot_classifier(filtered_classes)\n",
        "    logits = model.predict_scores(eval_x, zs_weights).tolist()\n",
        "    \n",
        "    pred_y = model.predict_label(eval_x, zs_weights)\n",
        "    pred_y = [label_mapping[l] for l in pred_y]\n",
        "\n",
        "    met = model.evaluate_single_label_metrics(\n",
        "            eval_x, eval_y, label_mapping, zs_weights, metrics\n",
        "            )\n",
        "\n",
        "    return pred_y, met, logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2cWOf7SQF66"
      },
      "source": [
        "def get_label_mapping_n_class_names(eval_y, class_names):\n",
        "  label_mapping = {}\n",
        "  unique_labels = np.unique(eval_y)\n",
        "  filtered_classes = [class_names[x] for x in unique_labels]\n",
        "\n",
        "  num_classes = len(unique_labels)\n",
        "  for c in range(num_classes):\n",
        "    label_mapping[c] = unique_labels[c]\n",
        "\n",
        "  return label_mapping, filtered_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H9Kex59foo1"
      },
      "source": [
        "# chenni change\n",
        "def run_episode_through_model(\n",
        "    indices_and_embeddings,\n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y,\n",
        "    class_names,\n",
        "    num_augmentations=0,\n",
        "    train_epochs=None,\n",
        "    train_batch_size=5,\n",
        "    metrics=['hamming', 'jaccard', 'subset_accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'top1_accuracy', 'top5_accuracy', 'classwise_accuracy', 'c_accuracy'],\n",
        "    embeddings=None,\n",
        "    multi_label=True\n",
        "):\n",
        "    metrics_values = {m:[] for m in metrics}\n",
        "    indices_and_embeddings\n",
        "    eval_x = embeddings[eval_indices]\n",
        "    ep_logits = []\n",
        "    \n",
        "    label_mapping, filtered_classes = get_label_mapping_n_class_names(eval_y, class_names)\n",
        "\n",
        "    clip_fs_parameters = {\n",
        "        \"num_classes\": num_ways,\n",
        "        \"input_dims\": eval_x.shape[-1],\n",
        "        \"multi_label\": multi_label\n",
        "    }\n",
        "\n",
        "    clip_fs_cls = CLIPFewShotClassifier(clip_fs_parameters)\n",
        "    \n",
        "    pred_labels, metrics_values, logits = evaluate_model_for_episode(\n",
        "            clip_fs_cls,\n",
        "            eval_x,\n",
        "            eval_y,\n",
        "            label_mapping,\n",
        "            filtered_classes,\n",
        "            metrics=metrics,\n",
        "            multi_label=False\n",
        "    )\n",
        "    ep_logits = logits\n",
        "#cc\n",
        "    return metrics_values, ep_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUpPZ6ti6IEp"
      },
      "source": [
        "def run_evaluations(\n",
        "    indices_and_embeddings,\n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways,\n",
        "    class_names,\n",
        "    verbose=True,\n",
        "    normalize=True,\n",
        "    train_epochs=None,\n",
        "    train_batch_size=5,\n",
        "    metrics=['accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'top1_accuracy', 'top5_accuracy', 'classwise_accuracy', 'c_accuracy'],\n",
        "    embeddings=None,\n",
        "    num_augmentations=0,\n",
        "    multi_label=True\n",
        "):\n",
        "    metrics_values = {m:[] for m in metrics}\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    if verbose:\n",
        "        pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "    for idx_ep in range(num_episodes):\n",
        "        _train_indices = train_indices[idx_ep]\n",
        "        _eval_indices = eval_indices[idx_ep]\n",
        "        _wi_y = [label for label in wi_y[idx_ep]]\n",
        "        _eval_y = [label for label in eval_y[idx_ep]]\n",
        "\n",
        "        met, ep_logits = run_episode_through_model(\n",
        "            indices_and_embeddings,\n",
        "            _train_indices, \n",
        "            _eval_indices, \n",
        "            _wi_y, \n",
        "            _eval_y,\n",
        "            class_names,\n",
        "            num_augmentations=num_augmentations,\n",
        "            train_epochs=train_epochs,\n",
        "            train_batch_size=train_batch_size,\n",
        "            embeddings=embeddings,\n",
        "            metrics=metrics,\n",
        "            multi_label=multi_label\n",
        "        )\n",
        "\n",
        "        all_logits.append(ep_logits)\n",
        "\n",
        "        for m in metrics:\n",
        "            metrics_values[m].append(met[m])\n",
        "\n",
        "        if verbose:\n",
        "            pbar.update(idx_ep+1)\n",
        "\n",
        "    return metrics_values, all_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVO25nDT88qK"
      },
      "source": [
        "def get_best_metric(mt, metric_name, optimal='max'):\n",
        "    if optimal=='max':\n",
        "        opt_value = np.max(np.mean(np.array(mt[metric_name]), axis=0))\n",
        "    if optimal=='min':\n",
        "        opt_value = np.min(np.mean(np.array(mt[metric_name]), axis=0))\n",
        "\n",
        "    return opt_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8CNr6I4rU5d"
      },
      "source": [
        "# 5 way 5 shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g73bz0lqrU5e"
      },
      "source": [
        "## Picking indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm6j-e0brU5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a249d7-4a5d-4551-b295-dba05b7b8d0e"
      },
      "source": [
        "num_ways = 5\n",
        "num_shot = 5\n",
        "num_eval = 15\n",
        "shuffle = False\n",
        "num_episodes = 100\n",
        "\n",
        "train_indices, eval_indices, wi_y, eval_y = prepare_indices(\n",
        "    num_ways, num_shot, num_eval, num_episodes, label_dictionary, test_labels, shuffle\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |*********************             | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5Ov81G5BUJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b25ed57d-0f36-4f1e-812d-edb0fd478b03"
      },
      "source": [
        "embedding_model = embedding_models.CLIPEmbeddingWrapper()\n",
        "num_augmentations = 0\n",
        "trivial=False\n",
        "\n",
        "indices, embeddings = embed_images(\n",
        "    embedding_model, \n",
        "    train_indices, \n",
        "    num_augmentations,\n",
        "    trivial=trivial\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:33] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLW-8vrbrU5f"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghmre8xB5Tft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6f564a-0402-4c5a-fe05-de5509cba1a8"
      },
      "source": [
        "clip_embeddings_test_fn = \"clip\" + test_embeddings_filename_suffix\n",
        "clip_embeddings_test = get_ndarray_from_drive(drive, folderid, clip_embeddings_test_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading clip_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGTJsU6yN0S0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145a2b04-1bf5-4e01-dd74-62957a1adb79"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "if trivial:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_clip_zs_metrics_with_logits.json\"\n",
        "else:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_clip_zs_metrics_with_logits.json\"\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "download_file_by_name(drive, folderid, results_filename)\n",
        "if results_filename in os.listdir():\n",
        "    with open(results_filename, 'r') as f:\n",
        "      #cc\n",
        "        json_loaded = json.load(f)\n",
        "        #cc\n",
        "        clip_metrics_over_train_epochs = json_loaded['metrics']\n",
        "        #cc\n",
        "        logits_over_train_epochs = json_loaded[\"logits\"]\n",
        "else:\n",
        "    clip_metrics_over_train_epochs = []  \n",
        "    logits_over_train_epochs = []   \n",
        "\n",
        "train_epochs_arr = [0]\n",
        "multi_label=False\n",
        "# metrics_vals = ['hamming', 'jaccard', 'f1_score'] # ['accuracy', 'f1_score']\n",
        "\n",
        "for idx, train_epochs in enumerate(train_epochs_arr):\n",
        "    if idx < len(clip_metrics_over_train_epochs):\n",
        "        continue\n",
        "    print(train_epochs)\n",
        "    #cc\n",
        "    clip_metrics_thresholds, all_logits = run_evaluations(\n",
        "        (indices, embeddings),\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        class_names,\n",
        "        train_epochs=train_epochs,\n",
        "        num_augmentations=num_augmentations,\n",
        "        embeddings=clip_embeddings_test\n",
        "    )\n",
        "    clip_metrics_over_train_epochs.append(clip_metrics_thresholds)\n",
        "    #cc\n",
        "    logits_over_train_epochs.append(all_logits)\n",
        "\n",
        "#cc\n",
        "    fin_list = []\n",
        "    #cc the whole for loop\n",
        "    for a1 in wi_y:\n",
        "      fin_a1_list = []\n",
        "      for a2 in a1:\n",
        "        new_val = str(a2)\n",
        "        fin_a1_list.append(new_val)\n",
        "      fin_list.append(fin_a1_list)\n",
        "\n",
        "    with open(results_filename, 'w') as f:\n",
        "      #cc\n",
        "        results = {'metrics': clip_metrics_over_train_epochs,\n",
        "                   \"logits\": logits_over_train_epochs,\n",
        "                   \"true_labels\": fin_list}\n",
        "        json.dump(results, f)\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    #delete_file_by_name(drive, folderid, results_filename)\n",
        "    #save_to_drive(drive, folderid, results_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:09:52] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8uyo_T8rU5h"
      },
      "source": [
        "if trivial:\n",
        "    PLOT_DIR = \"NewMetrics_clip_zs_Sigmoid_MiniImagenet\" + \"_0t\" + str(num_ways) + \"w\" + str(num_shot) + \"s\" + str(num_augmentations) + \"a_trivial_plots\"\n",
        "else:\n",
        "    PLOT_DIR = \"NewMetrics_clip_zs_Sigmoid_MiniImagenet\" + \"_0t\" + str(num_ways) + \"w\" + str(num_shot) + \"s\" + str(num_augmentations) + \"a_plots\"\n",
        "os.mkdir(PLOT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTID6tl2rFhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8661a863-c73b-40bc-fa87-e424ebc801ec"
      },
      "source": [
        "# chenni change whole block\n",
        "all_metrics = ['accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'top1_accuracy', 'top5_accuracy', 'classwise_accuracy', 'c_accuracy']\n",
        "\n",
        "final_dict = {}\n",
        "for ind_metric in all_metrics:\n",
        "  vals = []\n",
        "  final_array = []\n",
        "  for mt in clip_metrics_over_train_epochs:\n",
        "      ret_val = get_best_metric(mt,ind_metric,\"max\")\n",
        "      vals.append(ret_val)\n",
        "\n",
        "  final_array.append(vals)\n",
        "  final_dict[ind_metric] = final_array\n",
        "\n",
        "if trivial:\n",
        "    graph_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_clip_zs_metrics_graphs.json\"\n",
        "else:\n",
        "    graph_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_clip_zs_metrics_graphs.json\"\n",
        "\n",
        "with open(graph_filename, 'w') as f:\n",
        "        json.dump(final_dict, f)\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "delete_file_by_name(drive, folderid, graph_filename)\n",
        "save_to_drive(drive, folderid, graph_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsCIFAR10_0t5w5s0a_clip_zs_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRc9bHsURFDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f760582d-234c-4e33-f639-3d00e36ca2f4"
      },
      "source": [
        "zip_dirname = PLOT_DIR + \".zip\"\n",
        "zip_source = PLOT_DIR\n",
        "! zip -r $zip_dirname $zip_source\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "save_to_drive(drive, folderid, zip_dirname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: NewMetrics_clip_zs_Sigmoid_MiniImagenet_0t5w5s0a_plots/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded NewMetrics_clip_zs_Sigmoid_MiniImagenet_0t5w5s0a_plots.zip to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrit1GAzrU5u"
      },
      "source": [
        "# 10 way 5 shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5G7GsGDrU5u"
      },
      "source": [
        "## Picking indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvDuWsZerU5u",
        "outputId": "daa0172e-dac5-4fe4-acc3-f68f9026838e"
      },
      "source": [
        "num_ways = 10\n",
        "num_shot = 5\n",
        "num_eval = 5\n",
        "shuffle = False\n",
        "num_episodes = 100\n",
        "\n",
        "train_indices, eval_indices, wi_y, eval_y = prepare_indices(\n",
        "    num_ways, num_shot, num_eval, num_episodes, label_dictionary, test_labels, shuffle\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |**************************        | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLK5V-xFE6V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1415231-efe4-4c13-be99-59a05042fab4"
      },
      "source": [
        "embedding_model = embedding_models.CLIPEmbeddingWrapper()\n",
        "num_augmentations = 0\n",
        "trivial=False\n",
        "\n",
        "indices, embeddings = embed_images(\n",
        "    embedding_model, \n",
        "    train_indices, \n",
        "    num_augmentations,\n",
        "    trivial=trivial\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:53] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVBO2brU5u"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHwC6CiqrU5u",
        "outputId": "c3465683-fd16-4ea0-8b17-b18c8c8d5b7e"
      },
      "source": [
        "clip_embeddings_test_fn = \"clip\" + test_embeddings_filename_suffix\n",
        "clip_embeddings_test = get_ndarray_from_drive(drive, folderid, clip_embeddings_test_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading clip_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHkvWSCtFJnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99b97f3-08cd-4b2b-c20f-4a7af4c2f2cf"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "if trivial:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_clip_zs_metrics_with_logits.json\"\n",
        "else:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_metrics_clip_zs_with_logits.json\"\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "download_file_by_name(drive, folderid, results_filename)\n",
        "if results_filename in os.listdir():\n",
        "    with open(results_filename, 'r') as f:\n",
        "      #cc\n",
        "        json_loaded = json.load(f)\n",
        "        #cc\n",
        "        clip_metrics_over_train_epochs = json_loaded['metrics']\n",
        "        #cc\n",
        "        logits_over_train_epochs = json_loaded[\"logits\"]\n",
        "else:\n",
        "    clip_metrics_over_train_epochs = []  \n",
        "    #cc  \n",
        "    logits_over_train_epochs = []   \n",
        "\n",
        "train_epochs_arr = [0]\n",
        "multi_label=False\n",
        "# metrics_vals = ['hamming', 'jaccard', 'f1_score'] # ['accuracy', 'f1_score']\n",
        "\n",
        "for idx, train_epochs in enumerate(train_epochs_arr):\n",
        "    if idx < len(clip_metrics_over_train_epochs):\n",
        "        continue\n",
        "    print(train_epochs)\n",
        "    #cc\n",
        "    clip_metrics_thresholds, all_logits = run_evaluations(\n",
        "        (indices, embeddings),\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        class_names,\n",
        "        train_epochs=train_epochs,\n",
        "        num_augmentations=num_augmentations,\n",
        "        embeddings=clip_embeddings_test\n",
        "    )\n",
        "    clip_metrics_over_train_epochs.append(clip_metrics_thresholds)\n",
        "    #cc\n",
        "    logits_over_train_epochs.append(all_logits)\n",
        "\n",
        "#cc\n",
        "    fin_list = []\n",
        "    #cc the whole for loop\n",
        "    for a1 in wi_y:\n",
        "      fin_a1_list = []\n",
        "      for a2 in a1:\n",
        "        new_val = str(a2)\n",
        "        fin_a1_list.append(new_val)\n",
        "      fin_list.append(fin_a1_list)\n",
        "\n",
        "    with open(results_filename, 'w') as f:\n",
        "      #cc\n",
        "        results = {'metrics': clip_metrics_over_train_epochs,\n",
        "                   \"logits\": logits_over_train_epochs,\n",
        "                   \"true_labels\": fin_list}\n",
        "        json.dump(results, f)\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    delete_file_by_name(drive, folderid, results_filename)\n",
        "    save_to_drive(drive, folderid, results_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:09:50] |**********************************| (ETA:  00:00:00) WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsCIFAR10_0t10w5s0a_metrics_clip_zs_with_logits.json to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7-911OnFJnP"
      },
      "source": [
        "if trivial:\n",
        "    PLOT_DIR = \"NewMetrics_clip_zs_Sigmoid_MiniImagenet\" + \"_0t\" + str(num_ways) + \"w\" + str(num_shot) + \"s\" + str(num_augmentations) + \"a_trivial_plots\"\n",
        "else:\n",
        "    PLOT_DIR = \"NewMetrics_clip_zs_Sigmoid_MiniImagenet\" + \"_0t\" + str(num_ways) + \"w\" + str(num_shot) + \"s\" + str(num_augmentations) + \"a_plots\"\n",
        "os.mkdir(PLOT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sht4dvfFJnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757e856d-3531-4f0c-9c6b-f5ea935dc91c"
      },
      "source": [
        "all_metrics = ['accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'top1_accuracy', 'top5_accuracy', 'classwise_accuracy', 'c_accuracy']\n",
        "\n",
        "final_dict = {}\n",
        "for ind_metric in all_metrics:\n",
        "  vals = []\n",
        "  final_array = []\n",
        "  for mt in clip_metrics_over_train_epochs:\n",
        "      ret_val = get_best_metric(mt,ind_metric,\"max\")\n",
        "      vals.append(ret_val)\n",
        "\n",
        "  final_array.append(vals)\n",
        "  final_dict[ind_metric] = final_array\n",
        "\n",
        "if trivial:\n",
        "    graph_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_clip_zs_metrics_graphs.json\"\n",
        "else:\n",
        "    graph_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_clip_zs_metrics_graphs.json\"\n",
        "\n",
        "with open(graph_filename, 'w') as f:\n",
        "        json.dump(final_dict, f)\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "delete_file_by_name(drive, folderid, graph_filename)\n",
        "save_to_drive(drive, folderid, graph_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsCIFAR10_0t10w5s0a_clip_zs_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWMwEGMLFJnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5710fbd4-fad3-4536-bd92-03ca7ce0e937"
      },
      "source": [
        "zip_dirname = PLOT_DIR + \".zip\"\n",
        "zip_source = PLOT_DIR\n",
        "! zip -r $zip_dirname $zip_source\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "save_to_drive(drive, folderid, zip_dirname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: NewMetrics_clip_zs_Sigmoid_MiniImagenet_0t10w5s0a_plots/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded NewMetrics_clip_zs_Sigmoid_MiniImagenet_0t10w5s0a_plots.zip to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlIMyHeVfFEE"
      },
      "source": [
        "# 5 way 1 shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HPn06QE39N8"
      },
      "source": [
        "## Picking indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jup3-49v_iuU",
        "outputId": "fbe93eb2-d67e-40c9-88fd-e34c39c10e0b"
      },
      "source": [
        "num_ways = 5\n",
        "num_shot = 1\n",
        "num_eval = 19\n",
        "shuffle = False\n",
        "num_episodes = 100\n",
        "\n",
        "train_indices, eval_indices, wi_y, eval_y = prepare_indices(\n",
        "    num_ways, num_shot, num_eval, num_episodes, label_dictionary, test_labels, shuffle\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |*********************             | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GTEuYo1Fo27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45f599c-7c5a-41f6-b531-d67c46e14476"
      },
      "source": [
        "embedding_model = embedding_models.CLIPEmbeddingWrapper()\n",
        "num_augmentations = 0\n",
        "trivial=False\n",
        "\n",
        "indices, embeddings = embed_images(\n",
        "    embedding_model, \n",
        "    train_indices, \n",
        "    num_augmentations,\n",
        "    trivial=trivial\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:17] |********************************* | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9dYlVFDF_vs"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y6RpvnEF_vs",
        "outputId": "cd01bf32-63e8-41af-e994-6f5a4e4b8957"
      },
      "source": [
        "clip_embeddings_test_fn = \"clip\" + test_embeddings_filename_suffix\n",
        "clip_embeddings_test = get_ndarray_from_drive(drive, folderid, clip_embeddings_test_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading clip_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6CQnw11FTIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b59aaef-8026-4ecc-d01e-08bb8798e704"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "if trivial:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_clip_zs_metrics_with_logits.json\"\n",
        "else:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_clip_zs_metrics_with_logits.json\"\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "download_file_by_name(drive, folderid, results_filename)\n",
        "if results_filename in os.listdir():\n",
        "    with open(results_filename, 'r') as f:\n",
        "      #cc\n",
        "        json_loaded = json.load(f)\n",
        "        #cc\n",
        "        clip_metrics_over_train_epochs = json_loaded['metrics']\n",
        "        #cc\n",
        "        logits_over_train_epochs = json_loaded[\"logits\"]\n",
        "else:\n",
        "    clip_metrics_over_train_epochs = []  \n",
        "    #cc  \n",
        "    logits_over_train_epochs = []   \n",
        "\n",
        "train_epochs_arr = [0]\n",
        "multi_label=False\n",
        "# metrics_vals = ['hamming', 'jaccard', 'f1_score'] # ['accuracy', 'f1_score']\n",
        "\n",
        "for idx, train_epochs in enumerate(train_epochs_arr):\n",
        "    if idx < len(clip_metrics_over_train_epochs):\n",
        "        continue\n",
        "    print(train_epochs)\n",
        "    #cc\n",
        "    clip_metrics_thresholds, all_logits = run_evaluations(\n",
        "        (indices, embeddings),\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        class_names,\n",
        "        train_epochs=train_epochs,\n",
        "        num_augmentations=num_augmentations,\n",
        "        embeddings=clip_embeddings_test\n",
        "    )\n",
        "    clip_metrics_over_train_epochs.append(clip_metrics_thresholds)\n",
        "    #cc\n",
        "    logits_over_train_epochs.append(all_logits)\n",
        "\n",
        "#cc\n",
        "    fin_list = []\n",
        "    #cc the whole for loop\n",
        "    for a1 in wi_y:\n",
        "      fin_a1_list = []\n",
        "      for a2 in a1:\n",
        "        new_val = str(a2)\n",
        "        fin_a1_list.append(new_val)\n",
        "      fin_list.append(fin_a1_list)\n",
        "\n",
        "    with open(results_filename, 'w') as f:\n",
        "      #cc\n",
        "        results = {'metrics': clip_metrics_over_train_epochs,\n",
        "                   \"logits\": logits_over_train_epochs,\n",
        "                   \"true_labels\": fin_list}\n",
        "        json.dump(results, f)\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    delete_file_by_name(drive, folderid, results_filename)\n",
        "    save_to_drive(drive, folderid, results_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:10:00] |**********************************| (ETA:  00:00:00) WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsCIFAR10_0t5w1s0a_clip_zs_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGo3102kFTIy"
      },
      "source": [
        "if trivial:\n",
        "    PLOT_DIR = \"NewMetrics_clip_zs_Sigmoid_MiniImagenet\" + \"_0t\" + str(num_ways) + \"w\" + str(num_shot) + \"s\" + str(num_augmentations) + \"a_trivial_plots\"\n",
        "else:\n",
        "    PLOT_DIR = \"NewMetrics_clip_zs_Sigmoid_MiniImagenet\" + \"_0t\" + str(num_ways) + \"w\" + str(num_shot) + \"s\" + str(num_augmentations) + \"a_plots\"\n",
        "os.mkdir(PLOT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bOX_AWEFTIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79809cfd-718c-4d1c-b7b2-4b24141cb247"
      },
      "source": [
        "all_metrics = ['accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'top1_accuracy', 'top5_accuracy', 'classwise_accuracy', 'c_accuracy']\n",
        "\n",
        "final_dict = {}\n",
        "for ind_metric in all_metrics:\n",
        "  vals = []\n",
        "  final_array = []\n",
        "  for mt in clip_metrics_over_train_epochs:\n",
        "      ret_val = get_best_metric(mt,ind_metric,\"max\")\n",
        "      vals.append(ret_val)\n",
        "\n",
        "  final_array.append(vals)\n",
        "  final_dict[ind_metric] = final_array\n",
        "\n",
        "if trivial:\n",
        "    graph_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_clip_zs_metrics_graphs.json\"\n",
        "else:\n",
        "    graph_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_clip_zs_metrics_graphs.json\"\n",
        "\n",
        "with open(graph_filename, 'w') as f:\n",
        "        json.dump(final_dict, f)\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "delete_file_by_name(drive, folderid, graph_filename)\n",
        "save_to_drive(drive, folderid, graph_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsCIFAR10_0t5w1s0a_clip_zs_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZjpIIX6FTIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e85344-5ff3-4b66-ee3e-c476b07a6bea"
      },
      "source": [
        "zip_dirname = PLOT_DIR + \".zip\"\n",
        "zip_source = PLOT_DIR\n",
        "! zip -r $zip_dirname $zip_source\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "save_to_drive(drive, folderid, zip_dirname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: NewMetrics_clip_zs_Sigmoid_MiniImagenet_0t5w1s0a_plots/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded NewMetrics_clip_zs_Sigmoid_MiniImagenet_0t5w1s0a_plots.zip to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBhFDrzlfTHf"
      },
      "source": [
        "# 10 way 1 shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u112WKcfTHg"
      },
      "source": [
        "## Picking indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-th0mOYQfTHg",
        "outputId": "417aa3b6-64fa-4bbf-e233-29677bcc9e95"
      },
      "source": [
        "num_ways = 10\n",
        "num_shot = 1\n",
        "num_eval = 10\n",
        "shuffle = False\n",
        "num_episodes = 100\n",
        "\n",
        "train_indices, eval_indices, wi_y, eval_y = prepare_indices(\n",
        "    num_ways, num_shot, num_eval, num_episodes, label_dictionary, test_labels, shuffle\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |*******************************   | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-wHhnx9F2v2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726d8081-bd40-4f31-d87a-f33e74d44f86"
      },
      "source": [
        "embedding_model = embedding_models.CLIPEmbeddingWrapper()\n",
        "num_augmentations = 0\n",
        "trivial=False\n",
        "\n",
        "indices, embeddings = embed_images(\n",
        "    embedding_model, \n",
        "    train_indices, \n",
        "    num_augmentations,\n",
        "    trivial=trivial\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:23] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sph7dLY0fTHh"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wBzaqB3fTHh",
        "outputId": "dcb36edd-ba14-4a19-8f23-18d3230dc77a"
      },
      "source": [
        "clip_embeddings_test_fn = \"clip\" + test_embeddings_filename_suffix\n",
        "clip_embeddings_test = get_ndarray_from_drive(drive, folderid, clip_embeddings_test_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading clip_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMTxo_ZaFXxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e09472-25b0-46b9-ea5e-c6c3c93c8551"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "if trivial:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_clip_zs_metrics_with_logits.json\"\n",
        "else:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_clip_zs_metrics_with_logits.json\"\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "download_file_by_name(drive, folderid, results_filename)\n",
        "if results_filename in os.listdir():\n",
        "    with open(results_filename, 'r') as f:\n",
        "      #cc\n",
        "        json_loaded = json.load(f)\n",
        "        #cc\n",
        "        clip_metrics_over_train_epochs = json_loaded['metrics']\n",
        "        #cc\n",
        "        logits_over_train_epochs = json_loaded[\"logits\"]\n",
        "else:\n",
        "    clip_metrics_over_train_epochs = []  \n",
        "    #cc  \n",
        "    logits_over_train_epochs = []   \n",
        "\n",
        "train_epochs_arr = [0]\n",
        "multi_label=False\n",
        "# metrics_vals = ['hamming', 'jaccard', 'f1_score'] # ['accuracy', 'f1_score']\n",
        "\n",
        "for idx, train_epochs in enumerate(train_epochs_arr):\n",
        "    if idx < len(clip_metrics_over_train_epochs):\n",
        "        continue\n",
        "    print(train_epochs)\n",
        "    #cc\n",
        "    clip_metrics_thresholds, all_logits = run_evaluations(\n",
        "        (indices, embeddings),\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        class_names,\n",
        "        train_epochs=train_epochs,\n",
        "        num_augmentations=num_augmentations,\n",
        "        embeddings=clip_embeddings_test\n",
        "    )\n",
        "    clip_metrics_over_train_epochs.append(clip_metrics_thresholds)\n",
        "    #cc\n",
        "    logits_over_train_epochs.append(all_logits)\n",
        "\n",
        "#cc\n",
        "    fin_list = []\n",
        "    #cc the whole for loop\n",
        "    for a1 in wi_y:\n",
        "      fin_a1_list = []\n",
        "      for a2 in a1:\n",
        "        new_val = str(a2)\n",
        "        fin_a1_list.append(new_val)\n",
        "      fin_list.append(fin_a1_list)\n",
        "\n",
        "    with open(results_filename, 'w') as f:\n",
        "      #cc\n",
        "        results = {'metrics': clip_metrics_over_train_epochs,\n",
        "                   \"logits\": logits_over_train_epochs,\n",
        "                   \"true_labels\": fin_list}\n",
        "        json.dump(results, f)\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    delete_file_by_name(drive, folderid, results_filename)\n",
        "    save_to_drive(drive, folderid, results_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:09:54] |**********************************| (ETA:  00:00:00) WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsCIFAR10_0t10w1s0a_clip_zs_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeskwalZFXxN"
      },
      "source": [
        "if trivial:\n",
        "    PLOT_DIR = \"NewMetrics_clip_zs_Sigmoid_MiniImagenet\" + \"_0t\" + str(num_ways) + \"w\" + str(num_shot) + \"s\" + str(num_augmentations) + \"a_trivial_plots\"\n",
        "else:\n",
        "    PLOT_DIR = \"NewMetrics_clip_zs_Sigmoid_MiniImagenet\" + \"_0t\" + str(num_ways) + \"w\" + str(num_shot) + \"s\" + str(num_augmentations) + \"a_plots\"\n",
        "os.mkdir(PLOT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TYQpdqDFXxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5174fe7f-8381-4a79-864a-233b686d878e"
      },
      "source": [
        "all_metrics = ['accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'top1_accuracy', 'top5_accuracy', 'classwise_accuracy', 'c_accuracy']\n",
        "\n",
        "final_dict = {}\n",
        "for ind_metric in all_metrics:\n",
        "  vals = []\n",
        "  final_array = []\n",
        "  for mt in clip_metrics_over_train_epochs:\n",
        "      ret_val = get_best_metric(mt,ind_metric,\"max\")\n",
        "      vals.append(ret_val)\n",
        "\n",
        "  final_array.append(vals)\n",
        "  final_dict[ind_metric] = final_array\n",
        "\n",
        "if trivial:\n",
        "    graph_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_clip_zs_metrics_graphs.json\"\n",
        "else:\n",
        "    graph_filename = \"new_metrics\"+dataset_name+\"_0t\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_clip_zs_metrics_graphs.json\"\n",
        "\n",
        "with open(graph_filename, 'w') as f:\n",
        "        json.dump(final_dict, f)\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "delete_file_by_name(drive, folderid, graph_filename)\n",
        "save_to_drive(drive, folderid, graph_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsCIFAR10_0t10w1s0a_clip_zs_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dkyC88hFXxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364eae50-ee99-48b4-f2f1-a4c200a0e68b"
      },
      "source": [
        "zip_dirname = PLOT_DIR + \".zip\"\n",
        "zip_source = PLOT_DIR\n",
        "! zip -r $zip_dirname $zip_source\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "save_to_drive(drive, folderid, zip_dirname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: NewMetrics_clip_zs_Sigmoid_MiniImagenet_0t10w1s0a_plots/ (stored 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Uploaded NewMetrics_clip_zs_Sigmoid_MiniImagenet_0t10w1s0a_plots.zip to https://drive.google.com/drive/u/1/folders/1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}