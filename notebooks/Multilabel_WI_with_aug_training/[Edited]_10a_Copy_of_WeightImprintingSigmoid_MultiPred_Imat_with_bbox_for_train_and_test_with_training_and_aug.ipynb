{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Edited] 10a Copy of WeightImprintingSigmoid_MultiPred_Imat with bbox for train and test with training and aug.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RGlVnbugxFK2",
        "3rKe3HqM523g",
        "OLU-gp7n8__E",
        "9z1WQnXdLHy2",
        "NzsubsEm72rr",
        "zU_gxQ0KbwMh",
        "UxTa8MVsvQCN",
        "xP6ftkDCvKul",
        "fJIGo_R86GQi",
        "vQ-tz9Imw8pu",
        "TSW3LlUl4fm7",
        "bV6FE5x64im2",
        "Dfr5vC9A4sHg",
        "9VIIelzQ4xLY"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wCVCAfpyE0A"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-7JU3Q7q_XT",
        "outputId": "4f15022b-1cd6-4e7e-a2ed-7e92aa319871"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXAPOzOK4mTl",
        "outputId": "d0178834-a9e9-4911-d6ec-a3ccf2895395"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Cloning PAL_2021 to access modules.\n",
        "# Need password to access private repo.\n",
        "\n",
        "if 'PAL_2021' not in os.listdir():\n",
        "    cmd_string = 'git clone https://github.com/PAL-ML/CLIPPER.git'\n",
        "    os.system(cmd_string)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting httplib2==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/83/5e006e25403871ffbbf587c7aa4650158c947d46e89f2d50dcaf018464de/httplib2-0.15.0-py3-none-any.whl (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30kB 14.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 40kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 5.9MB/s \n",
            "\u001b[?25hInstalling collected packages: httplib2\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed httplib2-0.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlVnbugxFK2"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lslwocJKfUeR",
        "outputId": "2437d537-2971-4ed1-ff78-b7090c76c208"
      },
      "source": [
        "!pip install scikit-learn==0.24.1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.24.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1) (1.4.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKe3HqM523g"
      },
      "source": [
        "## Install CLIP dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poS-WNDixIhY"
      },
      "source": [
        "# import subprocess\n",
        "\n",
        "# CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "# print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "# if CUDA_version == \"10.0\":\n",
        "#     torch_version_suffix = \"+cu100\"\n",
        "# elif CUDA_version == \"10.1\":\n",
        "#     torch_version_suffix = \"+cu101\"\n",
        "# elif CUDA_version == \"10.2\":\n",
        "#     torch_version_suffix = \"\"\n",
        "# else:\n",
        "#     torch_version_suffix = \"+cu110\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-69W8M59nA"
      },
      "source": [
        "# ! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYwBZS1N6A3d"
      },
      "source": [
        "# ! pip install ftfy regex"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9oIcNBYB8lz3",
        "outputId": "9a7aadba-d532-4eb7-d92b-0b38cf589507"
      },
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-wtcug5i6\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-wtcug5i6\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/da/d215a091986e5f01b80f5145cff6f22e2dc57c6b048aab2e882a07018473/ftfy-6.0.3.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Collecting torch~=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n",
            "\u001b[?25hCollecting torchvision~=0.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 22.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip, ftfy\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368708 sha256=e843beab9ae1afbec4026c335a81e9c13e6fe5a63f9d5587a390887ee51073d7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3ek7uso1/wheels/79/51/d7/69f91d37121befe21d9c52332e04f592e17d1cabc7319b3e09\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-cp37-none-any.whl size=41916 sha256=a7df71ac5354a10f426cb36e23188fbd1b9c47c3d601cdbee31a001d4ea4cff3\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/2c/e6/109c8a28fef7a443f67ba58df21fe1d0067ac3322e75e6b0b7\n",
            "Successfully built clip ftfy\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ftfy, torch, torchvision, clip\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed clip-1.0 ftfy-6.0.3 torch-1.7.1 torchvision-0.8.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-gp7n8__E"
      },
      "source": [
        "## Install clustering dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLg9ozo9Hvc"
      },
      "source": [
        "!pip -q install umap-learn>=0.3.7"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1WQnXdLHy2"
      },
      "source": [
        "## Install dataset manager dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1vvMx7_LLSp",
        "outputId": "5abd89f7-123e-4bbb-e6fd-e9c2cf56f003"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=7169ba1e436c9c74ca26fb276befd269bcb4206358afc2c45f9a22f404e00a69\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzsubsEm72rr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZI62a6G74kw"
      },
      "source": [
        "# ML Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import keras\n",
        "\n",
        "# Data processing\n",
        "import PIL\n",
        "import base64\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "from skimage.measure import label, regionprops\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from matplotlib import cm\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Models\n",
        "import clip\n",
        "\n",
        "# Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Clustering\n",
        "# import umap\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "#from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Misc\n",
        "import progressbar\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.metrics import jaccard_score, hamming_loss, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "# Modules\n",
        "# from PAL_2021.PAL_HILL.ExperimentModules import embedding_models\n",
        "from CLIPPER.code.ExperimentModules.dataset_manager import DatasetManager\n",
        "from CLIPPER.code.ExperimentModules.weight_imprinting_classifier import WeightImprintingClassifier\n",
        "from CLIPPER.code.ExperimentModules import simclr_data_augmentations\n",
        "from CLIPPER.code.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)\n",
        "\n",
        "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5iwzjEGcFOI"
      },
      "source": [
        "import os, logging\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)\n",
        "logging.getLogger(\"tensorflow_hub\").setLevel(logging.CRITICAL)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_gxQ0KbwMh"
      },
      "source": [
        "# Initialization & Constants\n",
        "\n",
        "**Edited**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bih5tBPdbx3u",
        "outputId": "ec7839b0-bd31-494a-c060-03f9ee547c06"
      },
      "source": [
        "dataset_name = 'IMaterialist'\n",
        "folder_name = \"FGCVIMaterialist-Embeddings-24-03-21\"\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1bK72W-Um20EQDEyChNhNJthUNbmoSEjD'\n",
        "\n",
        "# Filepaths\n",
        "train_labels_filename = \"train_labels.npz\"\n",
        "val_labels_filename = \"val_labels.npz\"\n",
        "test_labels_filename = \"test_labels.npz\"\n",
        "\n",
        "train_embeddings_filename_suffix = \"_embeddings_train.npz\"\n",
        "val_embeddings_filename_suffix = \"_embeddings_val.npz\"\n",
        "test_embeddings_filename_suffix = \"_embeddings_test.npz\"\n",
        "\n",
        "\n",
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = create_expt_dir(drive, parentid, folder_name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: FGCVIMaterialist-Embeddings-24-03-21, id: 1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Experiment folder already exists. WARNING: Following with this run might overwrite existing results stored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxTa8MVsvQCN"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI-Sx_zz0-jc"
      },
      "source": [
        "LABEL_PATH = '/content/gdrive/MyDrive/PAL_HILL_2021/Experiments/FGCVIMaterialist-Embeddings-24-03-21/train_labels.npz'\n",
        "IMG_PATH = '/content/gdrive/MyDrive/PAL_HILL_2021/Datasets/imaterialist-fashion'\n",
        "# IMG_LIST_PATH = '/content/drive/MyDrive/PAL_HILL_2021/Datasets/Coco2017Train/img_list.npz'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6S124Jfwuu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d311a16f-c21c-4e1b-8fa7-b8405ed9524d"
      },
      "source": [
        "def get_ndarray_from_drive(drive, folderid, filename):\n",
        "    download_file_by_name(drive, folderid, filename)\n",
        "    return np.load(filename, allow_pickle=True)['arr_0']\n",
        "\n",
        "train_labels = get_ndarray_from_drive(drive, folderid, train_labels_filename)\n",
        "# val_labels = get_ndarray_from_drive(drive, folderid, val_labels_filename)\n",
        "# test_labels = get_ndarray_from_drive(drive, folderid, test_labels_filename)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train_labels.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlwqmSoomhKb"
      },
      "source": [
        "data_folder = '/content/gdrive/MyDrive/PAL_HILL_2021/Datasets/imaterialist-fashion/'\n",
        "data_df = pd.read_csv('/content/gdrive/MyDrive/PAL_HILL_2021/Datasets/imaterialist-fashion/train.csv')\n",
        "split = 'train'\n",
        "image_dir = os.path.join(data_folder, split)\n",
        "class_id_col = data_df['ClassId'].copy().values\n",
        "image_id_col = data_df['ImageId'].copy().values\n",
        "image_fn_col = data_df['ImageId'].copy().apply(lambda x: os.path.join(image_dir, x+'.jpg')).values\n",
        "encoded_pixels_col = data_df['EncodedPixels'].copy().values\n",
        "height_col = data_df['Height'].copy().values\n",
        "width_col = data_df['Width'].copy().values\n",
        "attributes_ids_col = data_df['AttributesIds'].copy().fillna('').values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ-qMXhGrA_l"
      },
      "source": [
        "final_train_labels = train_labels\n",
        "for i in range(len(final_train_labels)):\n",
        "    la = final_train_labels[i]\n",
        "    temp_array = []\n",
        "\n",
        "    for l in la:\n",
        "      if l <= 293:\n",
        "        temp_array.append(l)\n",
        "\n",
        "    fin_array = np.array(temp_array)\n",
        "    train_labels[i] = fin_array"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "222ZNgXkG1i_"
      },
      "source": [
        "labels_per_img = []\n",
        "id_per_img = []\n",
        "j = 1\n",
        "s = set()\n",
        "for l in final_train_labels[0]:\n",
        "  s.add(l)\n",
        "for i in range(1, len(final_train_labels)):\n",
        "  if image_id_col[j] == image_id_col[j-1]:\n",
        "    for l in final_train_labels[i]:\n",
        "      s.add(l)\n",
        "  else:\n",
        "    labels_per_img.append(list(s))\n",
        "    s.clear()\n",
        "    id_per_img.append(image_id_col[j-1])\n",
        "  j+=1\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-f4BEcDgeVC"
      },
      "source": [
        "# Init model (Clip)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3jcG0Bugh9R"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLbRqaYxzbr7"
      },
      "source": [
        "# Create label dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emz85fNX0Vif"
      },
      "source": [
        "unique_labels = []\n",
        "for i in range(294):\n",
        "  unique_labels.append(i)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TubS-RLzeVM"
      },
      "source": [
        "label_dictionary = {la:[] for la in unique_labels}\n",
        "\n",
        "for i in range(int(len(final_train_labels)/2)):\n",
        "    la = final_train_labels[i]\n",
        "\n",
        "    for l in la:\n",
        "        label_dictionary[l].append(i)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP6ftkDCvKul"
      },
      "source": [
        "# Weight Imprinting models on train data embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJIGo_R86GQi"
      },
      "source": [
        "## Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbvErkzf4ioS"
      },
      "source": [
        "def encode_aug_img(images):\n",
        "  images *= 255\n",
        "  images = images.astype('uint8')\n",
        "  embeddings = []\n",
        "  for img in images:\n",
        "    pil_img = Image.fromarray(img.astype('uint8'))\n",
        "    preproc_img = preprocess(pil_img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      _emb = model.encode_image(preproc_img)  \n",
        "    embeddings.append(_emb.cpu().detach().numpy()[0])\n",
        "    del _emb\n",
        "    del pil_img\n",
        "    del preproc_img\n",
        "  #embeddings.append(np.array(emb_per_img))\n",
        "    #del emb_per_img\n",
        "  return np.array(embeddings)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQgfGwZgqL17"
      },
      "source": [
        "def _process_encoded_pixels(row):\n",
        "\t\tdef get_pixel_loc(value):\n",
        "\t\t    x = value%height\n",
        "\t\t    y = value//height\n",
        "\n",
        "\t\t    return x, y\n",
        "\n",
        "\t\tdef process_encoded_pixels_string(encoded_pixels):\n",
        "\t\t    mask_pixels = []\n",
        "\t\t    ep_list = [int(ep_item) for ep_item in encoded_pixels.split(' ')]\n",
        "\n",
        "\t\t    idx = 0\n",
        "\t\t    while idx < len(ep_list):\n",
        "\t\t        pixel = ep_list[idx]\n",
        "\t\t        num_pixels = ep_list[idx+1]\n",
        "\n",
        "\t\t        for np in range(num_pixels):\n",
        "\t\t            mask_pixels.append(pixel+np)\n",
        "\t\t        \n",
        "\t\t        idx += 2\n",
        "\n",
        "\t\t    return mask_pixels\n",
        "\n",
        "\t\tdef get_mask(mask_pixels, height, width):\n",
        "\t\t    mask = np.zeros((height, width))\n",
        "\t\t    for mp in mask_pixels:\n",
        "\t\t        x, y = get_pixel_loc(mp)\n",
        "\t\t        mask[x, y] = 1\n",
        "\t\t    \n",
        "\t\t    return mask\n",
        "\n",
        "\t\tencoded_pixels = row[0]# .numpy().decode('utf=8')\n",
        "\t\theight = int(row[1])\n",
        "\t\twidth = int(row[2])\n",
        "\t\tmask_pixels = process_encoded_pixels_string(encoded_pixels)\n",
        "\t\tmask = get_mask(mask_pixels, height, width)\n",
        "\n",
        "\t\treturn mask"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvYX9mC0wsPN"
      },
      "source": [
        "def generate_masks(indices):\n",
        "  masks_for_index = []\n",
        "  for i in indices:\n",
        "    img = mpimg.imread(data_folder + split + '/' + image_id_col[i] + '.jpg')\n",
        "    # print(\"index i = {} has shape = {}\".format(i, img.shape))\n",
        "    mask = _process_encoded_pixels((encoded_pixels_col[i], height_col[i], width_col[i]))\n",
        "    props = regionprops(mask.astype(int))\n",
        "    for prop in props:\n",
        "      if img.ndim == 2:\n",
        "        masks_for_index.append(img[prop.bbox[0]: prop.bbox[2], prop.bbox[1]:prop.bbox[3]])\n",
        "      else:\n",
        "        masks_for_index.append(img[prop.bbox[0]: prop.bbox[2], prop.bbox[1]:prop.bbox[3], :])\n",
        "      break\n",
        "  return masks_for_index"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1rYFOJQNnhd"
      },
      "source": [
        "def generate_patch_list(indices, episode):\n",
        "  patches_res = []\n",
        "  for i in indices:\n",
        "    img = mpimg.imread(IMG_PATH + i.zfill(12) + '.jpg')\n",
        "    # fig, ax = plt.subplots()\n",
        "    # ax.imshow(img)\n",
        "    for j in labels[i]:\n",
        "      if j['category_id'] in selected_labels_per_episode[episode]:\n",
        "        x = int(j['bbox'][0])\n",
        "        x1 = int(j['bbox'][0] + j['bbox'][2])\n",
        "        y = int(j['bbox'][1])\n",
        "        y1 = int(j['bbox'][1] + j['bbox'][3])\n",
        "        # rect = patches.Rectangle((j['bbox'][0], j['bbox'][1]), j['bbox'][2], j['bbox'][3], linewidth=1, edgecolor='r', facecolor='none')\n",
        "        # ax.add_patch(rect)\n",
        "        patches_res.append(img[y:y1, x:x1, :])\n",
        "  return patches_res"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8UKZU6JEoVs"
      },
      "source": [
        "def generate_patch_list_per_img(indices, episode):\n",
        "  patches_res = []\n",
        "  for i in indices:\n",
        "    img = mpimg.imread(IMG_PATH + i.zfill(12) + '.jpg')\n",
        "    # fig, ax = plt.subplots()\n",
        "    # ax.imshow(img)\n",
        "    _patches_per_img = []\n",
        "    for j in labels[i]:\n",
        "      if j['category_id'] in selected_labels_per_episode[episode]:\n",
        "        x = int(j['bbox'][0])\n",
        "        x1 = int(j['bbox'][0] + j['bbox'][2])\n",
        "        y = int(j['bbox'][1])\n",
        "        y1 = int(j['bbox'][1] + j['bbox'][3])\n",
        "        # rect = patches.Rectangle((j['bbox'][0], j['bbox'][1]), j['bbox'][2], j['bbox'][3], linewidth=1, edgecolor='r', facecolor='none')\n",
        "        # ax.add_patch(rect)\n",
        "        _patches_per_img.append(img[y:y1, x:x1, :])\n",
        "    patches_res.append(_patches_per_img)\n",
        "    del _patches_per_img\n",
        "  return patches_res"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmwNhL0G-MS_"
      },
      "source": [
        "def encode_patch(patches):\n",
        "  embeddings = []\n",
        "  pil_img = Image.fromarray(patches)\n",
        "  preproc_img = preprocess(pil_img).unsqueeze(0).to(device)\n",
        "  with torch.no_grad():\n",
        "    _emb = model.encode_image(preproc_img)  \n",
        "  return np.array(_emb.cpu().detach().numpy()[0])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeU4N5MBSjj-"
      },
      "source": [
        "# for full images we just need the index of the image eg '34'\n",
        "def encode_full_img(indices):\n",
        "  embeddings = []\n",
        "  for i in indices:\n",
        "    img = mpimg.imread(data_folder + split + '/' + id_per_img[i] + '.jpg')\n",
        "    pil_img = Image.fromarray(img)\n",
        "    preproc_img = preprocess(pil_img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      _emb = model.encode_image(preproc_img)  \n",
        "    embeddings.append(_emb.cpu().detach().numpy()[0])\n",
        "    del _emb\n",
        "    del pil_img\n",
        "    del preproc_img\n",
        "    #embeddings.append(np.array(emb_per_img))\n",
        "    #del emb_per_img\n",
        "  return np.array(embeddings)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv68q8TH6tvG"
      },
      "source": [
        "def start_progress_bar(bar_len):\n",
        "    widgets = [\n",
        "        ' [', \n",
        "        progressbar.Timer(format= 'elapsed time: %(elapsed)s'), \n",
        "        '] ', \n",
        "        progressbar.Bar('*'),' (', \n",
        "        progressbar.ETA(), ') ', \n",
        "        ]\n",
        "    pbar = progressbar.ProgressBar(\n",
        "        max_value=bar_len, widgets=widgets\n",
        "        ).start()\n",
        "    return pbar"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckJak5yodYTQ"
      },
      "source": [
        "def evaluate_multi_label_metrics(wi_cls, x, \n",
        "        y, \n",
        "        label_mapping, \n",
        "        threshold=0.7,\n",
        "        metrics=['hamming', 'jaccard', 'subset_accuracy', 'f1_score']):    \n",
        "        hamming_score = 0\n",
        "        jaccard_index = 0\n",
        "        pred = wi_cls.predict_multi_label(x, threshold)\n",
        "        pred_mapped = [[label_mapping[val] for val in p] for p in pred]\n",
        "\n",
        "        mlb = MultiLabelBinarizer()\n",
        "        y_bin = mlb.fit_transform(y)\n",
        "        pred_bin = mlb.transform(pred_mapped)\n",
        "\n",
        "        # for i, pred_list in enumerate(pred):\n",
        "        #     label_list = set(y[i])\n",
        "        #     pred_list = set([label_mapping[p] for p in pred_list])\n",
        "\n",
        "        #     len_intersection = len(label_list.intersection(pred_list))\n",
        "        #     len_union = len(label_list.union(pred_list))\n",
        "\n",
        "        #     if 'hamming' in metrics:\n",
        "        #         hamming_score += len_union - len_intersection\n",
        "        #     if 'jaccard' in metrics:\n",
        "        #         jaccard_index += len_intersection/len_union\n",
        "\n",
        "        metric_values = {}\n",
        "        if 'hamming' in metrics:\n",
        "            # hamming_score = hamming_score / (len(y)*len(label_mapping))\n",
        "            hamming_score = hamming_loss(y_bin, pred_bin)\n",
        "            metric_values['hamming'] = hamming_score\n",
        "        if 'jaccard' in metrics:\n",
        "            # jaccard_index = jaccard_index / len(y)\n",
        "            jaccard_index = jaccard_score(y_bin, pred_bin, average='samples', zero_division = 1.0)\n",
        "            metric_values['jaccard'] = jaccard_index\n",
        "        if 'subset_accuracy' in metrics:\n",
        "            subset_accuracy = accuracy_score(y_bin, pred_bin)\n",
        "            metric_values['subset_accuracy'] = subset_accuracy\n",
        "        if 'f1_score' in metrics:\n",
        "            f1_score_value = f1_score(y_bin, pred_bin, average='samples', zero_division = 1.0)\n",
        "            metric_values['f1_score'] = f1_score_value\n",
        "\n",
        "        return metric_values"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUpPZ6ti6IEp"
      },
      "source": [
        "#NOT USED IN THIS NOTEBOOK. CHANGE THE BELOW FUNCTION\n",
        "def run_evaluations(\n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways,\n",
        "    verbose=True,\n",
        "    normalize=True,\n",
        "    metrics=[\"hamming\", \"jaccard\"],\n",
        "    threshold=0.72\n",
        "):\n",
        "    metrics_values = {m:[] for m in metrics}\n",
        "\n",
        "    if verbose:\n",
        "        pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "    for i in range(num_episodes):\n",
        "        # wi_x = embeddings[train_indices[i]]\n",
        "        \n",
        "        # wi_x_tmp = train_patches_per_episode[i] #generate_patch_list(train_indices[i]) #generate_patch_list(train_indices[i])\n",
        "        wi_x = train_emb_per_episode[i] #encode_image(wi_x_tmp)\n",
        "        '''\n",
        "        Edit the patches before final run\n",
        "        '''\n",
        "        # patch_list = eval_patches_per_episode[i]  #generate_patch_list(eval_indices[i]) #patch_list_tmp #generate_patch_list(eval_indices[i]) #numpy array of patches generated from the images located at eval_indices[i]\n",
        "        eval_x_embeddings = eval_emb_per_episode[i] #encode_image(patch_list) #list of embeddings of patches\n",
        "        # dim_1 = eval_x_embeddings.shape[0]\n",
        "        # dim_2 = eval_x_embeddings.shape[1]\n",
        "        # dim_3 = eval_x_embeddings.shape[2]\n",
        "        # eval_x_embeddings = eval_x_embeddings.reshape((dim_1*dim_2, dim_3))\n",
        "\n",
        "        if normalize:\n",
        "            # print(\"wi_x.shape: {}\".format(wi_x.shape))\n",
        "            # print(\"eval_x_embeddings.shape: {}\".format(eval_x_embeddings.shape))\n",
        "            wi_x = WeightImprintingClassifier.preprocess_input(wi_x)\n",
        "            eval_x_embeddings =  WeightImprintingClassifier.preprocess_input(eval_x_embeddings)\n",
        "            # eval_x_embeddings_norm = []\n",
        "            # for k in range(len(eval_x_embeddings)):\n",
        "            #   _eval_x_embeddings = WeightImprintingClassifier.preprocess_input(eval_x_embeddings[k])\n",
        "            #   eval_x_embeddings_norm.append(_eval_x_embeddings)\n",
        "\n",
        "        wi_weights, label_mapping = WeightImprintingClassifier.get_imprinting_weights(\n",
        "            wi_x, wi_y[i], False, True\n",
        "            )\n",
        "\n",
        "        wi_parameters = {\n",
        "            \"num_classes\": num_ways,\n",
        "            \"input_dims\": wi_x.shape[-1],\n",
        "            \"scale\": False,\n",
        "            \"dense_layer_weights\": wi_weights,\n",
        "            \"multi_label\": True\n",
        "        }\n",
        "\n",
        "        wi_cls = WeightImprintingClassifier(wi_parameters)\n",
        "\n",
        "        # _pred_y = wi_cls.predict_multi_label(eval_x, threshold)\n",
        "        # for j in range(len(_eval_y)):\n",
        "        #     print([label_mapping[p] for p in _pred_y[j]], \" vs \", _eval_y[j])\n",
        "\n",
        "        # Evaluate the weight imprinting model\n",
        "        \n",
        "        # eval_x_embeddings = eval_x_embeddings.reshape((dim_1, dim_2, dim_3))\n",
        "        # print(\"eval_x_embeddings.shape before loop: {}\".format(eval_x_embeddings.shape))\n",
        "\n",
        "        \n",
        "        pred_eval_labels = []\n",
        "        for ind in range(len(eval_x_embeddings_norm)):\n",
        "          # print(\"Index = {}\".format(ind))\n",
        "          _pred_per_patch = []\n",
        "          for patch_no in range(len(eval_x_embeddings_norm[ind])):\n",
        "            # print(\"Patch = {}\".format(patch_no))\n",
        "            # plt.imshow(patch_list[ind][patch_no])\n",
        "            # plt.show()\n",
        "            # print(\"eval_x_embeddings.shape in loop: {}\".format(eval_x_embeddings[ind][patch_no].shape))  \n",
        "            _pred_label = wi_cls.predict_multi_label(eval_x_embeddings_norm[ind][patch_no].reshape(1,512), threshold = threshold)\n",
        "            mp_map = [[label_mapping[v] for v in p] for p in _pred_label]\n",
        "            for m in mp_map[0]:\n",
        "              if m:\n",
        "                _pred_per_patch.append(m)\n",
        "          pred_eval_labels.append(_pred_per_patch)\n",
        "\n",
        "          del _pred_per_patch\n",
        "          \n",
        "        mlb = MultiLabelBinarizer()\n",
        "        y_bin = mlb.fit_transform(eval_y[i])\n",
        "        pred_bin = mlb.transform(pred_eval_labels)\n",
        "        if 'hamming' in metrics:\n",
        "          metrics_values['hamming'].append(hamming_loss(y_bin, pred_bin))\n",
        "        if 'jaccard' in metrics:\n",
        "          jaccard_index = jaccard_score(y_bin, pred_bin, average='samples')\n",
        "          metrics_values['jaccard'].append(jaccard_index)\n",
        "        if 'subset_accuracy' in metrics:\n",
        "          subset_accuracy = accuracy_score(y_bin, pred_bin)\n",
        "          metrics_values['subset_accuracy'].append(subset_accuracy)\n",
        "        if 'f1_score' in metrics:\n",
        "          f1_score_value = f1_score(y_bin, pred_bin, average='samples')\n",
        "          metrics_values['f1_score'].append(f1_score_value)\n",
        "        \n",
        "        \n",
        "        # _pred_label = wi_cls.predict_multi_label(eval_x_embeddings, threshold = threshold)\n",
        "        # mp_map = [[label_mapping[v] for v in p] for p in _pred_label]\n",
        "        for j in range(len(eval_y[i])):\n",
        "          # plt.imshow(eval_patches_per_episode[i][j])\n",
        "          # plt.show()\n",
        "          img = mpimg.imread(IMG_PATH + eval_indices[i][j].zfill(12) + '.jpg')\n",
        "          fig, ax = plt.subplots()\n",
        "          ax.imshow(img)\n",
        "          plt.show()\n",
        "          print(\"True label = {}\".format(eval_y[i][j]))\n",
        "          print(\"Pred label = {}\".format(pred_eval_labels[j]))\n",
        "        # met = evaluate_multi_label_metrics(wi_cls,\n",
        "        #     eval_x_embeddings, eval_y[i], label_mapping, threshold, metrics\n",
        "        #     )\n",
        "        \n",
        "        # for m in met:\n",
        "        #     metrics_values[m].append(met[m])\n",
        "\n",
        "        del wi_x\n",
        "        # del eval_x\n",
        "        del wi_cls\n",
        "        break\n",
        "        if verbose:\n",
        "            pbar.update(i+1)\n",
        "\n",
        "    return metrics_values"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOupvAnU2BcX"
      },
      "source": [
        "def run_evaluations_clip(\n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways,\n",
        "    verbose=True,\n",
        "    normalize=True,\n",
        "    metrics=[\"hamming\", \"jaccard\", 'f1_score', 'subset_accuracy'],\n",
        "    threshold=0.72,\n",
        "):\n",
        "    metrics_values = {m:[] for m in metrics}\n",
        "\n",
        "    if verbose:\n",
        "        pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "    for i in range(num_episodes):\n",
        "        wi_x = train_emb_per_episode[i]\n",
        "        eval_x_embeddings = eval_emb_per_episode[i]\n",
        "\n",
        "        if normalize:\n",
        "            wi_x = WeightImprintingClassifier.preprocess_input(wi_x)\n",
        "            eval_x_embeddings = WeightImprintingClassifier.preprocess_input(eval_x_embeddings)\n",
        "\n",
        "        wi_weights, label_mapping = WeightImprintingClassifier.get_imprinting_weights(\n",
        "            wi_x, wi_y[i], False, True\n",
        "            )\n",
        "\n",
        "        wi_parameters = {\n",
        "            \"num_classes\": num_ways,\n",
        "            \"input_dims\": wi_x.shape[-1],\n",
        "            \"scale\": False,\n",
        "            \"dense_layer_weights\": wi_weights,\n",
        "            \"multi_label\": True\n",
        "        }\n",
        "\n",
        "        wi_cls = WeightImprintingClassifier(wi_parameters)\n",
        "\n",
        "        # _pred_y = wi_cls.predict_multi_label(eval_x, threshold)\n",
        "\n",
        "        # for j in range(len(_eval_y)):\n",
        "        #     print([label_mapping[p] for p in _pred_y[j]], \" vs \", _eval_y[j])\n",
        "\n",
        "        # Evaluate the weight imprinting model\n",
        "        met = wi_cls.evaluate_multi_label_metrics(\n",
        "            eval_x_embeddings, eval_y[i], label_mapping, threshold, metrics\n",
        "            )\n",
        "        \n",
        "        for m in met:\n",
        "            metrics_values[m].append(met[m])\n",
        "\n",
        "        del wi_x\n",
        "        # del eval_x\n",
        "        del wi_cls\n",
        "\n",
        "        if verbose:\n",
        "            pbar.update(i+1)\n",
        "\n",
        "    return metrics_values"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HihAXoqMIDew"
      },
      "source": [
        "def run_train_loop_old( \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways,\n",
        "    verbose=True,\n",
        "    normalize=True,\n",
        "    train_epochs_loop=[5],\n",
        "    train_batch_size=5,\n",
        "    metrics=[\"hamming\", \"jaccard\", \"f1_score\"],\n",
        "    threshold=0.72\n",
        "):\n",
        "    metrics_values = [{m:[] for m in metrics} for _ in range(len(train_epochs_loop)+1)]\n",
        "\n",
        "\n",
        "    if verbose:\n",
        "        pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "    for idx_ep in range(num_episodes):\n",
        "        wi_x = train_emb_reshaped[idx_ep]\n",
        "        eval_x = eval_emb_per_episode[idx_ep]\n",
        "        # print(eval_x.shape)\n",
        "\n",
        "        _wi_y = wi_y[idx_ep]\n",
        "        wi_y_ = []\n",
        "        for i in range(len(_wi_y)):\n",
        "          for j in range(num_augmentations+1):\n",
        "            wi_y_.append(_wi_y[i])\n",
        "        \n",
        "        if normalize:\n",
        "            wi_x = WeightImprintingClassifier.preprocess_input(wi_x)\n",
        "            eval_x = WeightImprintingClassifier.preprocess_input(eval_x)\n",
        "\n",
        "        eval_x = np.array(eval_x)\n",
        "        dim1, dim2 = eval_x.shape[0], eval_x.shape[-1]\n",
        "        eval_x = eval_x.reshape(dim1, dim2)\n",
        "        \n",
        "        wi_weights, label_mapping = WeightImprintingClassifier.get_imprinting_weights(\n",
        "            wi_x, wi_y_, False, True\n",
        "            )\n",
        "\n",
        "        wi_parameters = {\n",
        "            \"num_classes\": num_ways,\n",
        "            \"input_dims\": wi_x.shape[-1],\n",
        "            \"scale\": False,\n",
        "            \"dense_layer_weights\": wi_weights,\n",
        "            \"multi_label\": True\n",
        "        }\n",
        "\n",
        "        wi_cls = WeightImprintingClassifier(wi_parameters)\n",
        "\n",
        "        met = wi_cls.evaluate_multi_label_metrics(\n",
        "            eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "            )\n",
        "        for m in met:\n",
        "            metrics_values[0][m].append(met[m])\n",
        "        \n",
        "\n",
        "        for idx_tr_ep in range(len(train_epochs_loop)):\n",
        "            ep_y = wi_y_\n",
        "            rev_label_mapping = {label_mapping[val]:val for val in label_mapping}\n",
        "            train_y = np.zeros((len(ep_y), num_ways))\n",
        "            for idx_y, _y in enumerate(ep_y):\n",
        "                for l in _y:\n",
        "                    train_y[idx_y, rev_label_mapping[l]] = 1\n",
        "\n",
        "\n",
        "            wi_cls.train(wi_x, train_y, train_epochs_loop[idx_tr_ep], train_batch_size)\n",
        "\n",
        "            met = wi_cls.evaluate_multi_label_metrics(\n",
        "                eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "                )\n",
        "            for m in met:\n",
        "                metrics_values[idx_tr_ep+1][m].append(met[m])\n",
        "\n",
        "\n",
        "        # _pred_y = wi_cls.predict_multi_label(eval_x, threshold)\n",
        "        # for j in range(len(_eval_y)):\n",
        "        #     print([label_mapping[p] for p in _pred_y[j]], \" vs \", _eval_y[j])\n",
        "\n",
        "        # met = wi_cls.evaluate_multi_label_metrics(\n",
        "        #     eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "        #     )\n",
        "        \n",
        "        # for m in met:\n",
        "        #     metrics_values[m].append(met[m])\n",
        "\n",
        "        del wi_x\n",
        "        del eval_x\n",
        "        del wi_cls\n",
        "\n",
        "        if verbose:\n",
        "            pbar.update(idx_ep+1)\n",
        "\n",
        "    return metrics_values"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGsm7UkDs-HR"
      },
      "source": [
        "def run_train_loop( \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways,\n",
        "    verbose=True,\n",
        "    normalize=True,\n",
        "    train_epochs_loop=[5],\n",
        "    train_batch_size=5,\n",
        "    metrics=['hamming', 'jaccard', 'subset_accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'classwise_accuracy', 'c_accuracy'],\n",
        "    threshold=0.72\n",
        "):\n",
        "    metrics_values = [{m:[] for m in metrics} for _ in range(len(train_epochs_loop)+1)]\n",
        "\n",
        "    if verbose:\n",
        "        pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "    all_logits = []   #cc\n",
        "\n",
        "    for idx_ep in range(num_episodes):\n",
        "        wi_x = train_emb_reshaped[idx_ep]\n",
        "        eval_x = eval_emb_per_episode[idx_ep]\n",
        "\n",
        "        ep_logits = []  #cc\n",
        "\n",
        "        _wi_y = wi_y[idx_ep]\n",
        "        wi_y_ = []\n",
        "        for i in range(len(_wi_y)):\n",
        "          for j in range(num_augmentations+1):\n",
        "            wi_y_.append(_wi_y[i])\n",
        "        \n",
        "        if normalize:\n",
        "            wi_x = WeightImprintingClassifier.preprocess_input(wi_x)\n",
        "            eval_x = WeightImprintingClassifier.preprocess_input(eval_x)\n",
        "\n",
        "        eval_x = np.array(eval_x)\n",
        "        dim1, dim2 = eval_x.shape[0], eval_x.shape[-1]\n",
        "        eval_x = eval_x.reshape(dim1, dim2)\n",
        "\n",
        "        wi_weights, label_mapping = WeightImprintingClassifier.get_imprinting_weights(\n",
        "            wi_x, wi_y_, False, True\n",
        "            )\n",
        "\n",
        "        wi_parameters = {\n",
        "            \"num_classes\": num_ways,\n",
        "            \"input_dims\": wi_x.shape[-1],\n",
        "            \"scale\": False,\n",
        "            \"dense_layer_weights\": wi_weights,\n",
        "            \"multi_label\": True\n",
        "        }\n",
        "\n",
        "        wi_cls = WeightImprintingClassifier(wi_parameters)\n",
        "\n",
        "        met = wi_cls.evaluate_multi_label_metrics(\n",
        "            eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "            )\n",
        "        for m in met:\n",
        "            metrics_values[0][m].append(met[m])\n",
        "        \n",
        "\n",
        "        for idx_tr_ep in range(len(train_epochs_loop)):\n",
        "            ep_y = wi_y_\n",
        "            rev_label_mapping = {label_mapping[val]:val for val in label_mapping}\n",
        "            train_y = np.zeros((len(ep_y), num_ways))\n",
        "            for idx_y, _y in enumerate(ep_y):\n",
        "                for l in _y:\n",
        "                    train_y[idx_y, rev_label_mapping[l]] = 1\n",
        "\n",
        "\n",
        "            wi_cls.train(wi_x, train_y, train_epochs_loop[idx_tr_ep], train_batch_size)\n",
        "\n",
        "            logits = wi_cls.predict_scores(eval_x).tolist()  #cc\n",
        "            ep_logits.append(logits)  #cc\n",
        "\n",
        "            met = wi_cls.evaluate_multi_label_metrics(\n",
        "                eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "                )\n",
        "            for m in met:\n",
        "                metrics_values[idx_tr_ep+1][m].append(met[m])\n",
        "\n",
        "        all_logits.append(ep_logits)  #cc\n",
        "        # _pred_y = wi_cls.predict_multi_label(eval_x, threshold)\n",
        "        # for j in range(len(_eval_y)):\n",
        "        #     print([label_mapping[p] for p in _pred_y[j]], \" vs \", _eval_y[j])\n",
        "\n",
        "        # met = wi_cls.evaluate_multi_label_metrics(\n",
        "        #     eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "        #     )\n",
        "        \n",
        "        # for m in met:\n",
        "        #     metrics_values[m].append(met[m])\n",
        "\n",
        "        del wi_x\n",
        "        del eval_x\n",
        "        del wi_cls\n",
        "\n",
        "        if verbose:\n",
        "            pbar.update(idx_ep+1)\n",
        "\n",
        "    return metrics_values, all_logits #cc"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPNsYE4H5IZO"
      },
      "source": [
        "def embed_augmented_imgs(image, num_augmentations, trivial=False):\n",
        "  if np.max(image) > 1:\n",
        "    image = image/255\n",
        "    \n",
        "  def augment_image(image, num_augmentations, trivial=False):\n",
        "      \"\"\" Perform SimCLR augmentations on the image\n",
        "      \"\"\"\n",
        "\n",
        "      augmented_images = [image]\n",
        "\n",
        "      def _run_filters(image):\n",
        "          width = image.shape[1]\n",
        "          height = image.shape[0]\n",
        "          image_aug = simclr_data_augmentations.random_crop_with_resize(\n",
        "              image,\n",
        "              height,\n",
        "              width\n",
        "              )\n",
        "          image_aug = tf.image.random_flip_left_right(image_aug)\n",
        "          image_aug = simclr_data_augmentations.random_color_jitter(image_aug)\n",
        "          image_aug = simclr_data_augmentations.random_blur(\n",
        "              image_aug,\n",
        "              height,\n",
        "              width\n",
        "              )\n",
        "          image_aug = tf.reshape(image_aug, [image.shape[0], image.shape[1], 3])\n",
        "          image_aug = tf.clip_by_value(image_aug, 0., 1.)\n",
        "\n",
        "          return image_aug.numpy()\n",
        "\n",
        "      for _ in range(num_augmentations):\n",
        "          # aug_image = augmentations(image=image)\n",
        "          if trivial:\n",
        "              aug_image = image\n",
        "          else:\n",
        "              aug_image = _run_filters(image)\n",
        "\n",
        "          augmented_images.append(aug_image)\n",
        "\n",
        "      augmented_images = np.stack(augmented_images)\n",
        "      return augmented_images\n",
        "\n",
        "  if num_augmentations > 0:\n",
        "      aug_images = augment_image(image, num_augmentations, trivial)\n",
        "  else:\n",
        "      aug_images = np.array([image])\n",
        "\n",
        "  embeddings = encode_aug_img(aug_images)\n",
        "  return embeddings"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kyoDlwpGS0g"
      },
      "source": [
        "def get_max_mean_jaccard_index_by_threshold(metrics_thresholds):\n",
        "    max_mean_jaccard = np.max([np.mean(mt['jaccard']) for mt in metrics_thresholds])\n",
        "    return max_mean_jaccard\n",
        "\n",
        "def get_max_mean_f1_score_by_threshold(metrics_thresholds):\n",
        "    max_mean_f1_score = np.max([np.mean(mt['f1_score']) for mt in metrics_thresholds])\n",
        "    return max_mean_f1_score"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVkxudfBReZY"
      },
      "source": [
        "def get_max_mean_jaccard_index_with_threshold(metrics_thresholds):\n",
        "    max_mean_jaccard = np.max([np.mean(mt['jaccard']) for mt in metrics_thresholds])\n",
        "    threshold = np.argmax([np.mean(mt['jaccard']) for mt in metrics_thresholds])\n",
        "    return max_mean_jaccard, threshold\n",
        "\n",
        "def get_max_mean_f1_score_with_threshold(metrics_thresholds):\n",
        "    max_mean_f1 = np.max([np.mean(mt['o_f1']) for mt in metrics_thresholds])\n",
        "    threshold = np.argmax([np.mean(mt['o_f1']) for mt in metrics_thresholds])\n",
        "    return max_mean_f1, threshold"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf90owtyrEdE"
      },
      "source": [
        "# chenni change whole block\n",
        "def get_best_metric_and_threshold(metrics_thresholds, metric_name, thresholds, optimal='max'):\n",
        "    if optimal=='max':\n",
        "        opt_value = np.max([np.mean(mt[metric_name]) for mt in metrics_thresholds])\n",
        "        opt_threshold = thresholds[np.argmax([np.mean(mt[metric_name]) for mt in metrics_thresholds])]\n",
        "    if optimal=='min':\n",
        "        opt_value = np.min([np.mean(mt[metric_name]) for mt in metrics_thresholds])\n",
        "        opt_threshold = thresholds[np.argmin([np.mean(mt[metric_name]) for mt in metrics_thresholds])]\n",
        "\n",
        "    return opt_value, opt_threshold"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gbrauRSrQuu"
      },
      "source": [
        "def save_trends(num_ways, num_shot, num_augmentations, trivial, clip_metrics_thresholds, logits_thresholds):\n",
        "  # chenni change whole block\n",
        "  all_metrics = ['hamming', 'jaccard', 'subset_accuracy', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'c_accuracy']\n",
        "\n",
        "  f1_vals = []\n",
        "  f1_t_vals = []\n",
        "  jaccard_vals = []\n",
        "  jaccard_t_vals = []\n",
        "\n",
        "  final_dict = {}\n",
        "  for ind_metric in all_metrics:\n",
        "    vals = []\n",
        "    t_vals = []\n",
        "    final_array = []\n",
        "    for mt in clip_metrics_thresholds:\n",
        "      if ind_metric == \"hamming\":\n",
        "        ret_val, ret_t_val = get_best_metric_and_threshold(mt,ind_metric,thresholds,\"min\")\n",
        "      else:\n",
        "        ret_val, ret_t_val = get_best_metric_and_threshold(mt,ind_metric,thresholds,\"max\")\n",
        "      vals.append(ret_val)\n",
        "      t_vals.append(ret_t_val)\n",
        "\n",
        "    final_array.append(vals)\n",
        "    final_array.append(t_vals)\n",
        "    final_dict[ind_metric] = final_array\n",
        "\n",
        "  if trivial:\n",
        "      graph_filename = \"new_metrics\"+dataset_name+ \"_Patch_Patch\"+\"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_metrics_graphs.json\"\n",
        "  else:\n",
        "      graph_filename = \"new_metrics\"+dataset_name+ \"_Patch_Patch\"+\"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_metrics_graphs.json\"\n",
        "\n",
        "  with open(graph_filename, 'w') as f:\n",
        "          json.dump(final_dict, f)\n",
        "\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  delete_file_by_name(drive, folderid, graph_filename)\n",
        "  save_to_drive(drive, folderid, graph_filename)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apDLqadSrVy0"
      },
      "source": [
        " #cc whole block\n",
        "def save_results(num_ways, num_shots, num_aug, trivial, clip_metrics_thresholds, logits_thresholds):\n",
        "  if trivial:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+ \"_Patch_Patch\" + \"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_metrics_with_logits.json\"\n",
        "  else:\n",
        "    #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+ \"_Patch_Patch\" + \"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_metrics_with_logits.json\"\n",
        "\n",
        "  with open(results_filename, 'w') as f:\n",
        "    #cc\n",
        "    results = {'metrics': clip_metrics_thresholds,\n",
        "                \"logits\": logits_thresholds,\n",
        "                }\n",
        "    json.dump(results, f)\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  delete_file_by_name(drive, folderid, results_filename)\n",
        "  save_to_drive(drive, folderid, results_filename)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHs46yaOItTW"
      },
      "source": [
        "## Setting multiple thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlo2bBCAIyQj",
        "outputId": "917d5393-7946-4360-9bfa-5683bd39b48e"
      },
      "source": [
        "thresholds = np.arange(0.3, 0.72, 0.01)\n",
        "thresholds"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3 , 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 ,\n",
              "       0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51,\n",
              "       0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62,\n",
              "       0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7 , 0.71])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1mgLWl5N0hY"
      },
      "source": [
        "def plot_metrics_by_threshold(\n",
        "    metrics_thresholds, \n",
        "    thresholds, \n",
        "    metrics=['jaccard', 'hamming', 'f1_score'],\n",
        "    title_suffix=\"\"\n",
        "):\n",
        "    legend = []\n",
        "    fig = plt.figure(figsize=(7,7))\n",
        "    plt.grid(True)\n",
        "\n",
        "    if 'jaccard' in metrics:\n",
        "        mean_jaccard_threshold = [np.mean(mt['jaccard']) for mt in metrics_thresholds]\n",
        "        opt_threshold_jaccard = thresholds[np.argmax(mean_jaccard_threshold)]\n",
        "        plt.plot(thresholds, mean_jaccard_threshold, c='blue')\n",
        "        plt.axvline(opt_threshold_jaccard, ls=\"--\", c='blue')\n",
        "        legend.append(\"Jaccard Index\")\n",
        "        legend.append(opt_threshold_jaccard)\n",
        "    if 'hamming' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['hamming']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='green')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='green')\n",
        "        legend.append(\"Hamming Score\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'f1_score' in metrics:\n",
        "        mean_f1_threshold = [np.mean(mt['f1_score']) for mt in metrics_thresholds]\n",
        "        opt_threshold_f1 = thresholds[np.argmax(mean_f1_threshold)]\n",
        "        plt.plot(thresholds, mean_f1_threshold, c='red')\n",
        "        plt.axvline(opt_threshold_f1, ls=\"--\", c='red')\n",
        "        legend.append(\"F1 Score\")\n",
        "        legend.append(opt_threshold_f1)\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend(legend)\n",
        "    plt.title(title_suffix+\" Multi label metrics by threshold\")\n",
        "    plt.show()\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8CNr6I4rU5d"
      },
      "source": [
        "# 5 way 5 shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g73bz0lqrU5e"
      },
      "source": [
        "## Picking indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_rlD8M0rMxZ"
      },
      "source": [
        "img_list = os.listdir(data_folder + split)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm6j-e0brU5f",
        "outputId": "7cdfc704-a881-41dc-9509-3f48ce12f3f3"
      },
      "source": [
        "num_ways = 5\n",
        "num_shot = 5\n",
        "num_eval = 10\n",
        "eval_indices = []\n",
        "train_indices = []\n",
        "wi_y = []\n",
        "eval_y = []\n",
        "shuffle = False\n",
        "sort = True\n",
        "num_episodes = 10\n",
        "selected_labels_per_episode = []\n",
        "\n",
        "label_dictionary = {la:label_dictionary[la] for la in label_dictionary if len(label_dictionary[la]) >= (num_shot+num_eval)}\n",
        "unique_labels = list(label_dictionary.keys())\n",
        "\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "for s in range(num_episodes):\n",
        "    # Setting random seed for replicability\n",
        "    np.random.seed(s)\n",
        "\n",
        "    _train_indices = []\n",
        "    _eval_indices = []\n",
        "\n",
        "    selected_labels = np.random.choice(unique_labels, size=num_ways, replace=False)\n",
        "    selected_labels_per_episode.append(selected_labels)\n",
        "    for la in selected_labels:\n",
        "        la_indices_train = label_dictionary[la]\n",
        "        la_indices_eval = label_dictionary[la]\n",
        "        \n",
        "        tr_idx = []\n",
        "        ev_idx = []\n",
        "        while len(tr_idx) < num_shot:\n",
        "            idx = np.random.choice(la_indices_train)\n",
        "            fname = image_id_col[idx] + '.jpg'\n",
        "            if fname in img_list:\n",
        "              img = mpimg.imread(data_folder + split + '/' + image_id_col[idx] + '.jpg')\n",
        "              if img.ndim!=3:\n",
        "                del img\n",
        "                continue\n",
        "            \n",
        "            if idx not in _train_indices and idx not in _eval_indices and idx not in tr_idx and fname in img_list:\n",
        "                tr_idx.append(idx)\n",
        "        while len(ev_idx) < num_eval:\n",
        "            idx = np.random.choice(la_indices_eval)\n",
        "            fname = image_id_col[idx] + '.jpg'\n",
        "            if fname in img_list:\n",
        "              img = mpimg.imread(data_folder + split + '/' + image_id_col[idx] + '.jpg')\n",
        "              if img.ndim!=3:\n",
        "                del img\n",
        "                continue\n",
        "            if idx not in _train_indices and idx not in _eval_indices and idx not in tr_idx and idx not in ev_idx and fname in img_list:\n",
        "                ev_idx.append(idx)\n",
        "                #print(len(ev_idx))\n",
        "\n",
        "        _train_indices = _train_indices + tr_idx\n",
        "        _eval_indices = _eval_indices + ev_idx\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.shuffle(_train_indices)\n",
        "        np.random.shuffle(_eval_indices)\n",
        "\n",
        "    # if sort:\n",
        "    #   _train_indices.sort()\n",
        "    #   _eval_indices.sort()\n",
        "\n",
        "    train_indices.append(_train_indices)\n",
        "    eval_indices.append(_eval_indices)\n",
        "\n",
        "    _wi_y = []\n",
        "    for idx in _train_indices:\n",
        "        la = train_labels[idx]\n",
        "        _wi_y.append(list([l for l in la if l in selected_labels]))\n",
        "    _eval_y = []\n",
        "    for idx in _eval_indices:\n",
        "        la = train_labels[idx]\n",
        "        _eval_y.append(list([l for l in la if l in selected_labels]))\n",
        "\n",
        "    wi_y.append(_wi_y)\n",
        "    eval_y.append(_eval_y)\n",
        "\n",
        "    pbar.update(s+1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:04:30] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA8okp19VQ9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db16c1d-6009-4dbe-eee4-f303d0579921"
      },
      "source": [
        "eval_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  p = generate_masks(eval_indices[i])\n",
        "  eval_emb = []\n",
        "  for j in p:\n",
        "    emb = encode_patch(j)\n",
        "    eval_emb.append(emb)\n",
        "  del p\n",
        "  eval_emb_per_episode.append(np.array(eval_emb))\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:03:05] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLW-8vrbrU5f"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ-tz9Imw8pu"
      },
      "source": [
        "#0 Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KejLoH9sw8p5",
        "outputId": "944ccaa2-1541-48e7-df4e-8fde66ba0309"
      },
      "source": [
        "num_augmentations = 0\n",
        "Trivial = False\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  p = generate_masks(train_indices[i])\n",
        "  emb_per_img = []\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del p\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:03:03] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijMeYeRzw8p7"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YEc_qs7w8p7",
        "outputId": "99fba661-e47a-440e-c925-3530b806524e"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:26:51] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EHycAbVw8p8",
        "outputId": "7a1a57bd-f668-4be0-c270-bae619ead4d1"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsIMaterialist_Patch_Patch_5w5s0a_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Uploaded new_metricsIMaterialist_Patch_Patch_5w5s0a_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSW3LlUl4fm7"
      },
      "source": [
        "#5 Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOmHSEhl4fm-",
        "outputId": "0dd48ec9-6bb0-44f1-dd42-1c0521f1d682"
      },
      "source": [
        "num_augmentations = 5\n",
        "Trivial = False\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "#interacting\n",
        "for i in range(num_episodes):\n",
        "  p = generate_masks(train_indices[i])\n",
        "  emb_per_img = []\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del p\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:03:19] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8lO4jBx4fm_"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XZnEjb54fnA",
        "outputId": "06f4129f-06ed-4bb7-8e85-003d06462e84"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:49:57] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I0VPaiR4fnA",
        "outputId": "db74f3cd-486c-457a-d8a7-fa6809a364be"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsIMaterialist_Patch_Patch_5w5s5a_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Uploaded new_metricsIMaterialist_Patch_Patch_5w5s5a_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV6FE5x64im2"
      },
      "source": [
        "#5 trivial Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzy6R-2E4im2",
        "outputId": "bf1828c8-1dfd-4860-a27f-8e1e44f46b02"
      },
      "source": [
        "num_augmentations = 5\n",
        "Trivial = True\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  p = generate_masks(train_indices[i])\n",
        "  emb_per_img = []\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del p\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:07:21] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcsoBlZy4im3"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvPjeaqz4im3",
        "outputId": "6d0035c9-e88f-4ead-c3b8-6336828a06af"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:38:40] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGMV6Rg44im3",
        "outputId": "2205ebf7-e192-4e44-ab91-3d83469109a0"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsIMaterialist_Patch_Patch_5w5s5a_trivial_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Uploaded new_metricsIMaterialist_Patch_Patch_5w5s5a_trivial_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q7l3o0x4im4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfr5vC9A4sHg"
      },
      "source": [
        "#10 Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6I0d3924sHg",
        "outputId": "c338739d-95e2-44a9-cca3-041b99dddde0"
      },
      "source": [
        "num_augmentations = 10\n",
        "Trivial = False\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  p = generate_masks(train_indices[i])\n",
        "  emb_per_img = []\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del p\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:04:40] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSelHOO94sHh"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvm_X-Uh4sHh",
        "outputId": "aaf4aa90-c05f-4a2f-a27e-85f70cb0e7aa"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:47:35] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7NBYCGV4sHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc8530b-41a2-479b-e65d-6dceaec8d391"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting new_metricsIMaterialist_Patch_Patch_5w5s10a_metrics_with_logits.json from GDrive\n",
            "Uploaded new_metricsIMaterialist_Patch_Patch_5w5s10a_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Deleting new_metricsIMaterialist_Patch_Patch_5w5s10a_metrics_graphs.json from GDrive\n",
            "Uploaded new_metricsIMaterialist_Patch_Patch_5w5s10a_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VIIelzQ4xLY"
      },
      "source": [
        "#10 Trivial Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNCbNbBY4xLY",
        "outputId": "944ccaa2-1541-48e7-df4e-8fde66ba0309"
      },
      "source": [
        "num_augmentations = 10\n",
        "Trivial = True\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  p = generate_masks(train_indices[i])\n",
        "  emb_per_img = []\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del p\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:03:03] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6mFLDFc4xLY"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvVC9wcI4xLZ",
        "outputId": "99fba661-e47a-440e-c925-3530b806524e"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:04:33] |*****                             | (ETA:   0:22:46) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VtSzI2Y4xLa"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYhWZEcg4xLa"
      },
      "source": [
        "max_mean_vals = []\n",
        "threshold_vals = []\n",
        "x_vals = [np.sum(train_epochs_loop[:i+1]) for i in range(len(train_epochs_loop))]\n",
        "for idx_tr_ep in range(len(train_epochs_loop)):\n",
        "  mt = []\n",
        "  for idx_t in range(len(clip_metrics_thresholds)):\n",
        "    mt.append(clip_metrics_thresholds[idx_t][idx_tr_ep])\n",
        "\n",
        "  mmv, t = get_max_mean_jaccard_index_with_threshold(mt)\n",
        "  max_mean_vals.append(mmv)\n",
        "  threshold_vals.append(thresholds[t])\n",
        "\n",
        "plt.plot(x_vals, max_mean_vals)\n",
        "plt.title(\"Jaccard index vs training epochs for {} way {} shot on {} with CLIP\".format(num_ways, num_shot, dataset_name))\n",
        "plt.xlabel(\"No. of training epochs\")\n",
        "plt.ylabel(\"Jaccard Index\")\n",
        "# plt.xticks(x_vals, x_vals)\n",
        "# plt.ylim([0, np.max(max_mean_vals)])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E2EWVzB4xLa"
      },
      "source": [
        "max_mean_vals = []\n",
        "threshold_vals = []\n",
        "x_vals = [np.sum(train_epochs_loop[:i+1]) for i in range(len(train_epochs_loop))]\n",
        "for idx_tr_ep in range(len(train_epochs_loop)):\n",
        "  mt = []\n",
        "  for idx_t in range(len(clip_metrics_thresholds)):\n",
        "    mt.append(clip_metrics_thresholds[idx_t][idx_tr_ep])\n",
        "\n",
        "  mmv, t = get_max_mean_f1_score_with_threshold(mt)\n",
        "  max_mean_vals.append(mmv)\n",
        "  threshold_vals.append(thresholds[t])\n",
        "\n",
        "plt.plot(x_vals, max_mean_vals)\n",
        "plt.title(\"F1 Score vs training epochs with 5 augmentations for {} way {} shot on {} with CLIP\".format(num_ways, num_shot, dataset_name))\n",
        "plt.xlabel(\"No. of training epochs\")\n",
        "plt.ylabel(\"Jaccard Index\")\n",
        "# plt.xticks(x_vals, x_vals)\n",
        "# plt.ylim([0, np.max(max_mean_vals)])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzsgkK0P4xLa"
      },
      "source": [
        "plt.plot(x_vals, threshold_vals)\n",
        "plt.title(\"Threshold vs training epochs for {} way {} shot on {} with CLIP\".format(num_ways, num_shot, dataset_name))\n",
        "plt.xlabel(\"No. of training epochs\")\n",
        "plt.ylabel(\"Threshold\")\n",
        "plt.xticks(x_vals, x_vals)\n",
        "# plt.ylim([0, np.max(max_mean_vals)])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEP6V9c54xLa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}