{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[Edited] WeightImprintingSigmoid_MultiPred_iMat with full img for train and test with augmentation & training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RGlVnbugxFK2",
        "gmgIrfT8hDNE",
        "3rKe3HqM523g",
        "OLU-gp7n8__E",
        "9z1WQnXdLHy2",
        "NzsubsEm72rr",
        "CxBaKCOs7nOR",
        "UxTa8MVsvQCN",
        "F-f4BEcDgeVC",
        "fJIGo_R86GQi",
        "Dd3gA1UyJIIM",
        "Cq-5M9WVnUX6",
        "u7a_Pz5GnaAj",
        "2GNtZL2-0HNh",
        "mHPkp7mgDqkR"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wCVCAfpyE0A"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-7JU3Q7q_XT",
        "outputId": "34fef49b-ae0a-4e81-bafc-2009fd69951c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXAPOzOK4mTl",
        "outputId": "077973d4-a84b-408e-a7e4-9754cd295748"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Cloning PAL_2021 to access modules.\n",
        "# Need password to access private repo.\n",
        "\n",
        "if 'PAL_2021' not in os.listdir():\n",
        "    cmd_string = 'git clone https://github.com/PAL-ML/CLIPPER.git'\n",
        "    os.system(cmd_string)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting httplib2==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/83/5e006e25403871ffbbf587c7aa4650158c947d46e89f2d50dcaf018464de/httplib2-0.15.0-py3-none-any.whl (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 21.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30kB 23.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 40kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 51kB 13.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 61kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 71kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 81kB 12.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 7.4MB/s \n",
            "\u001b[?25hInstalling collected packages: httplib2\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed httplib2-0.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlVnbugxFK2"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmgIrfT8hDNE"
      },
      "source": [
        "## Install multi label metrics dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6xXPAFbe6Gp",
        "outputId": "05150300-d95e-4b25-807f-cbe5b51bacb8"
      },
      "source": [
        "! pip install scikit-learn==0.24"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.24\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/ed/ab51a8da34d2b3f4524b21093081e7f9e2ddf1c9eac9f795dcf68ad0a57d/scikit_learn-0.24.0-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.4.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.0 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKe3HqM523g"
      },
      "source": [
        "## Install CLIP dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poS-WNDixIhY"
      },
      "source": [
        "# import subprocess\n",
        "\n",
        "# CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "# print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "# if CUDA_version == \"10.0\":\n",
        "#     torch_version_suffix = \"+cu100\"\n",
        "# elif CUDA_version == \"10.1\":\n",
        "#     torch_version_suffix = \"+cu101\"\n",
        "# elif CUDA_version == \"10.2\":\n",
        "#     torch_version_suffix = \"\"\n",
        "# else:\n",
        "#     torch_version_suffix = \"+cu110\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-69W8M59nA"
      },
      "source": [
        "# ! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYwBZS1N6A3d"
      },
      "source": [
        "# ! pip install ftfy regex"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oIcNBYB8lz3",
        "outputId": "fbfc5e83-a582-4195-e965-12cbfb608765"
      },
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-jzv46z4z\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-jzv46z4z\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/da/d215a091986e5f01b80f5145cff6f22e2dc57c6b048aab2e882a07018473/ftfy-6.0.3.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Collecting torch~=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 25kB/s \n",
            "\u001b[?25hCollecting torchvision~=0.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 268kB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip, ftfy\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368708 sha256=d1617b5712742adb13454ded07fdbcd08bd8608129fefe43555cf804a4b3d377\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tyaj8iod/wheels/79/51/d7/69f91d37121befe21d9c52332e04f592e17d1cabc7319b3e09\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-cp37-none-any.whl size=41916 sha256=c4551092c4ddbf0d5dd4fc91a655ca6bc6e0c3c5e0532b33ba17602c575de776\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/2c/e6/109c8a28fef7a443f67ba58df21fe1d0067ac3322e75e6b0b7\n",
            "Successfully built clip ftfy\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ftfy, torch, torchvision, clip\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed clip-1.0 ftfy-6.0.3 torch-1.7.1 torchvision-0.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-gp7n8__E"
      },
      "source": [
        "## Install clustering dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLg9ozo9Hvc"
      },
      "source": [
        "!pip -q install umap-learn>=0.3.7"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1WQnXdLHy2"
      },
      "source": [
        "## Install dataset manager dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1vvMx7_LLSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2143c37-dbf3-4795-f16f-a0a935d6e3a5"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=3ecdef9a2aba1c8aae27cb37d8be7c1a59e1824ed6ac99835ba12e1edf40b5f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzsubsEm72rr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZI62a6G74kw"
      },
      "source": [
        "# ML Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import keras\n",
        "\n",
        "# Data processing\n",
        "import PIL\n",
        "import base64\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from matplotlib import cm\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Models\n",
        "import clip\n",
        "\n",
        "# Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Clustering\n",
        "# import umap\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "#from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Misc\n",
        "import progressbar\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.metrics import jaccard_score, hamming_loss, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "# Modules\n",
        "# from PAL_2021.PAL_HILL.ExperimentModules import embedding_models\n",
        "from CLIPPER.code.ExperimentModules.dataset_manager import DatasetManager\n",
        "from CLIPPER.code.ExperimentModules.weight_imprinting_classifier import WeightImprintingClassifier\n",
        "from CLIPPER.code.ExperimentModules import simclr_data_augmentations\n",
        "from CLIPPER.code.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)\n",
        "\n",
        "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxBaKCOs7nOR"
      },
      "source": [
        "# Initialization & Constants\n",
        "\n",
        "**Edited**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHjzWbYU7nOX",
        "outputId": "35eb22bf-2761-402a-a382-e30df39e4536"
      },
      "source": [
        "dataset_name = 'IMaterialist'\n",
        "folder_name = \"FGCVIMaterialist-Embeddings-24-03-21\"\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1bK72W-Um20EQDEyChNhNJthUNbmoSEjD'\n",
        "\n",
        "# Filepaths\n",
        "train_labels_filename = \"train_labels.npz\"\n",
        "val_labels_filename = \"val_labels.npz\"\n",
        "test_labels_filename = \"test_labels.npz\"\n",
        "\n",
        "train_embeddings_filename_suffix = \"_embeddings_train.npz\"\n",
        "val_embeddings_filename_suffix = \"_embeddings_val.npz\"\n",
        "test_embeddings_filename_suffix = \"_embeddings_test.npz\"\n",
        "\n",
        "\n",
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = create_expt_dir(drive, parentid, folder_name)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: FGCVIMaterialist-Embeddings-24-03-21, id: 1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Experiment folder already exists. WARNING: Following with this run might overwrite existing results stored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxTa8MVsvQCN"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI-Sx_zz0-jc"
      },
      "source": [
        "LABEL_PATH = '/content/drive/MyDrive/PAL_HILL_2021/Experiments/FGCVIMaterialist-Embeddings-24-03-21/train_labels.npz'\n",
        "IMG_PATH = '/content/drive/MyDrive/PAL_HILL_2021/Datasets/imaterialist-fashion'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6S124Jfwuu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5385b9-802e-4d1f-9e5d-4e1d84edb40b"
      },
      "source": [
        "def get_ndarray_from_drive(drive, folderid, filename):\n",
        "    download_file_by_name(drive, folderid, filename)\n",
        "    return np.load(filename, allow_pickle=True)['arr_0']\n",
        "\n",
        "train_labels = get_ndarray_from_drive(drive, folderid, train_labels_filename)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train_labels.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlwqmSoomhKb"
      },
      "source": [
        "data_folder = '/content/drive/MyDrive/PAL_HILL_2021/Datasets/imaterialist-fashion/'\n",
        "data_df = pd.read_csv('/content/drive/MyDrive/PAL_HILL_2021/Datasets/imaterialist-fashion/train.csv')\n",
        "split = 'train'\n",
        "image_dir = os.path.join(data_folder, split)\n",
        "class_id_col = data_df['ClassId'].copy().values\n",
        "image_id_col = data_df['ImageId'].copy().values\n",
        "image_fn_col = data_df['ImageId'].copy().apply(lambda x: os.path.join(image_dir, x+'.jpg')).values\n",
        "encoded_pixels_col = data_df['EncodedPixels'].copy().values\n",
        "height_col = data_df['Height'].copy().values\n",
        "width_col = data_df['Width'].copy().values\n",
        "attributes_ids_col = data_df['AttributesIds'].copy().fillna('').values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ-qMXhGrA_l"
      },
      "source": [
        "final_train_labels = train_labels\n",
        "for i in range(len(final_train_labels)):\n",
        "    la = final_train_labels[i]\n",
        "    temp_array = []\n",
        "\n",
        "    for l in la:\n",
        "      if l <= 293:\n",
        "        temp_array.append(l)\n",
        "\n",
        "    fin_array = np.array(temp_array)\n",
        "    train_labels[i] = fin_array"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "222ZNgXkG1i_"
      },
      "source": [
        "labels_per_img = []\n",
        "id_per_img = []\n",
        "j = 1\n",
        "s = set()\n",
        "for l in final_train_labels[0]:\n",
        "  s.add(l)\n",
        "for i in range(1, len(final_train_labels)):\n",
        "  if image_id_col[j] == image_id_col[j-1]:\n",
        "    for l in final_train_labels[i]:\n",
        "      s.add(l)\n",
        "  else:\n",
        "    labels_per_img.append(list(s))\n",
        "    s.clear()\n",
        "    id_per_img.append(image_id_col[j-1])\n",
        "  j+=1\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-f4BEcDgeVC"
      },
      "source": [
        "# Init model (Clip)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3jcG0Bugh9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230470c0-b4e2-44af-aa6a-1f7be911a583"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 354M/354M [00:09<00:00, 37.4MiB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLbRqaYxzbr7"
      },
      "source": [
        "# Create label dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emz85fNX0Vif"
      },
      "source": [
        "unique_labels = []\n",
        "for i in range(294):\n",
        "  unique_labels.append(i)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TubS-RLzeVM"
      },
      "source": [
        "label_dictionary = {la:[] for la in unique_labels}\n",
        "\n",
        "for i in range(25000):\n",
        "    la = final_train_labels[i]\n",
        "\n",
        "    for l in la:\n",
        "        label_dictionary[l].append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqXeJn4izjbd"
      },
      "source": [
        "img_list_len = len(os.listdir(image_dir))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr3YTf2tJyov"
      },
      "source": [
        "label_dictionary_per_img = {la:[] for la in unique_labels}\n",
        "\n",
        "for i in range(img_list_len):\n",
        "    la = labels_per_img[i]\n",
        "\n",
        "    for l in la:\n",
        "        label_dictionary_per_img[l].append(i)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP6ftkDCvKul"
      },
      "source": [
        "# Weight Imprinting models on train data embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJIGo_R86GQi"
      },
      "source": [
        "## Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1rYFOJQNnhd"
      },
      "source": [
        "def generate_patch_list(indices, episode):\n",
        "  patches_res = []\n",
        "  for i in indices:\n",
        "    img = mpimg.imread(IMG_PATH + i.zfill(12) + '.jpg')\n",
        "    # fig, ax = plt.subplots()\n",
        "    # ax.imshow(img)\n",
        "    for j in labels[i]:\n",
        "      if j['category_id'] in selected_labels_per_episode[episode]:\n",
        "        x = int(j['bbox'][0])\n",
        "        x1 = int(j['bbox'][0] + j['bbox'][2])\n",
        "        y = int(j['bbox'][1])\n",
        "        y1 = int(j['bbox'][1] + j['bbox'][3])\n",
        "        # rect = patches.Rectangle((j['bbox'][0], j['bbox'][1]), j['bbox'][2], j['bbox'][3], linewidth=1, edgecolor='r', facecolor='none')\n",
        "        # ax.add_patch(rect)\n",
        "        patches_res.append(img[y:y1, x:x1, :])\n",
        "  return patches_res"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmwNhL0G-MS_"
      },
      "source": [
        "def encode_patch(patches):\n",
        "  embeddings = []\n",
        "  for p in patches:\n",
        "    # print(img.shape)\n",
        "    pil_img = Image.fromarray(p)\n",
        "    preproc_img = preprocess(pil_img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      _emb = model.encode_image(preproc_img)  \n",
        "    embeddings.append(_emb.cpu().detach().numpy()[0])\n",
        "    del _emb\n",
        "    del pil_img\n",
        "    del preproc_img\n",
        "    #embeddings.append(np.array(emb_per_img))\n",
        "    #del emb_per_img\n",
        "  return np.array(embeddings)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeU4N5MBSjj-"
      },
      "source": [
        "# for full images we just need the index of the image eg '34'\n",
        "def encode_full_img(indices):\n",
        "  embeddings = []\n",
        "  for i in indices:\n",
        "    img = mpimg.imread(data_folder + split + '/' + id_per_img[i] + '.jpg')\n",
        "    pil_img = Image.fromarray(img)\n",
        "    preproc_img = preprocess(pil_img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      _emb = model.encode_image(preproc_img)  \n",
        "    embeddings.append(_emb.cpu().detach().numpy()[0])\n",
        "    del _emb\n",
        "    del pil_img\n",
        "    del preproc_img\n",
        "    #embeddings.append(np.array(emb_per_img))\n",
        "    #del emb_per_img\n",
        "  return np.array(embeddings)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A56l3kYbV6XU"
      },
      "source": [
        "def encode_aug_img(images):\n",
        "  images *= 255\n",
        "  images = images.astype('uint8')\n",
        "  embeddings = []\n",
        "  for img in images:\n",
        "    pil_img = Image.fromarray(img.astype('uint8'))\n",
        "    preproc_img = preprocess(pil_img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      _emb = model.encode_image(preproc_img)  \n",
        "    embeddings.append(_emb.cpu().detach().numpy()[0])\n",
        "    del _emb\n",
        "    del pil_img\n",
        "    del preproc_img\n",
        "  #embeddings.append(np.array(emb_per_img))\n",
        "    #del emb_per_img\n",
        "  return np.array(embeddings)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv68q8TH6tvG"
      },
      "source": [
        "def start_progress_bar(bar_len):\n",
        "    widgets = [\n",
        "        ' [', \n",
        "        progressbar.Timer(format= 'elapsed time: %(elapsed)s'), \n",
        "        '] ', \n",
        "        progressbar.Bar('*'),' (', \n",
        "        progressbar.ETA(), ') ', \n",
        "        ]\n",
        "    pbar = progressbar.ProgressBar(\n",
        "        max_value=bar_len, widgets=widgets\n",
        "        ).start()\n",
        "    return pbar"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OjvSlqJHXDZ"
      },
      "source": [
        "def run_train_loop( \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways,\n",
        "    verbose=True,\n",
        "    normalize=True,\n",
        "    train_epochs_loop=[5],\n",
        "    train_batch_size=5,\n",
        "    metrics=['hamming', 'jaccard', 'subset_accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'classwise_accuracy', 'c_accuracy'],\n",
        "    threshold=0.72\n",
        "):\n",
        "    metrics_values = [{m:[] for m in metrics} for _ in range(len(train_epochs_loop)+1)]\n",
        "\n",
        "    if verbose:\n",
        "        pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "    all_logits = []   #cc\n",
        "\n",
        "    for idx_ep in range(num_episodes):\n",
        "        wi_x = train_emb_reshaped[idx_ep]\n",
        "        eval_x = eval_emb_per_episode[idx_ep]\n",
        "\n",
        "        ep_logits = []  #cc\n",
        "\n",
        "        _wi_y = wi_y[idx_ep]\n",
        "        wi_y_ = []\n",
        "        for i in range(len(_wi_y)):\n",
        "          for j in range(num_augmentations+1):\n",
        "            wi_y_.append(_wi_y[i])\n",
        "        \n",
        "        if normalize:\n",
        "            wi_x = WeightImprintingClassifier.preprocess_input(wi_x)\n",
        "            eval_x = WeightImprintingClassifier.preprocess_input(eval_x)\n",
        "\n",
        "        wi_weights, label_mapping = WeightImprintingClassifier.get_imprinting_weights(\n",
        "            wi_x, wi_y_, False, True\n",
        "            )\n",
        "\n",
        "        wi_parameters = {\n",
        "            \"num_classes\": num_ways,\n",
        "            \"input_dims\": wi_x.shape[-1],\n",
        "            \"scale\": False,\n",
        "            \"dense_layer_weights\": wi_weights,\n",
        "            \"multi_label\": True\n",
        "        }\n",
        "\n",
        "        wi_cls = WeightImprintingClassifier(wi_parameters)\n",
        "\n",
        "        met = wi_cls.evaluate_multi_label_metrics(\n",
        "            eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "            )\n",
        "        for m in met:\n",
        "            metrics_values[0][m].append(met[m])\n",
        "        \n",
        "\n",
        "        for idx_tr_ep in range(len(train_epochs_loop)):\n",
        "            ep_y = wi_y_\n",
        "            rev_label_mapping = {label_mapping[val]:val for val in label_mapping}\n",
        "            train_y = np.zeros((len(ep_y), num_ways))\n",
        "            for idx_y, _y in enumerate(ep_y):\n",
        "                for l in _y:\n",
        "                    train_y[idx_y, rev_label_mapping[l]] = 1\n",
        "\n",
        "\n",
        "            wi_cls.train(wi_x, train_y, train_epochs_loop[idx_tr_ep], train_batch_size)\n",
        "\n",
        "            logits = wi_cls.predict_scores(eval_x).tolist()  #cc\n",
        "            ep_logits.append(logits)  #cc\n",
        "\n",
        "            met = wi_cls.evaluate_multi_label_metrics(\n",
        "                eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "                )\n",
        "            for m in met:\n",
        "                metrics_values[idx_tr_ep+1][m].append(met[m])\n",
        "\n",
        "        all_logits.append(ep_logits)  #cc\n",
        "        # _pred_y = wi_cls.predict_multi_label(eval_x, threshold)\n",
        "        # for j in range(len(_eval_y)):\n",
        "        #     print([label_mapping[p] for p in _pred_y[j]], \" vs \", _eval_y[j])\n",
        "\n",
        "        # met = wi_cls.evaluate_multi_label_metrics(\n",
        "        #     eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "        #     )\n",
        "        \n",
        "        # for m in met:\n",
        "        #     metrics_values[m].append(met[m])\n",
        "\n",
        "        del wi_x\n",
        "        del eval_x\n",
        "        del wi_cls\n",
        "\n",
        "        if verbose:\n",
        "            pbar.update(idx_ep+1)\n",
        "\n",
        "    return metrics_values, all_logits #cc"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_p3xln4SB0V"
      },
      "source": [
        "def get_max_mean_jaccard_index_by_threshold(metrics_thresholds):\n",
        "    max_mean_jaccard = np.max([np.mean(mt['jaccard']) for mt in metrics_thresholds])\n",
        "    return max_mean_jaccard"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0QL9HbXSHcN"
      },
      "source": [
        "def get_max_mean_jaccard_index_with_threshold(metrics_thresholds):\n",
        "    max_mean_jaccard = np.max([np.mean(mt['jaccard']) for mt in metrics_thresholds])\n",
        "    threshold = np.argmax([np.mean(mt['jaccard']) for mt in metrics_thresholds])\n",
        "    return max_mean_jaccard, threshold"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhZxggaNt_S3"
      },
      "source": [
        "def get_max_mean_f1_score_with_threshold(metrics_thresholds):\n",
        "    max_mean_jaccard = np.max([np.mean(mt['o_f1']) for mt in metrics_thresholds])\n",
        "    threshold = np.argmax([np.mean(mt['o_f1']) for mt in metrics_thresholds])\n",
        "    return max_mean_jaccard, threshold"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksMueTe9SKwb"
      },
      "source": [
        "def get_mean_max_jaccard_index_by_episode(metrics_thresholds):\n",
        "    mean_max_jaccard = np.mean(np.max(np.array([mt['jaccard'] for mt in metrics_thresholds]), axis=0))\n",
        "    return mean_max_jaccard"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfL4tkTDUyJh"
      },
      "source": [
        "def embed_augmented_imgs(image, num_augmentations, trivial=False):\n",
        "  if np.max(image) > 1:\n",
        "    image = image/255\n",
        "    \n",
        "  def augment_image(image, num_augmentations, trivial=False):\n",
        "      \"\"\" Perform SimCLR augmentations on the image\n",
        "      \"\"\"\n",
        "\n",
        "      augmented_images = [image]\n",
        "\n",
        "      def _run_filters(image):\n",
        "          width = image.shape[1]\n",
        "          height = image.shape[0]\n",
        "          image_aug = simclr_data_augmentations.random_crop_with_resize(\n",
        "              image,\n",
        "              height,\n",
        "              width\n",
        "              )\n",
        "          image_aug = tf.image.random_flip_left_right(image_aug)\n",
        "          image_aug = simclr_data_augmentations.random_color_jitter(image_aug)\n",
        "          image_aug = simclr_data_augmentations.random_blur(\n",
        "              image_aug,\n",
        "              height,\n",
        "              width\n",
        "              )\n",
        "          image_aug = tf.reshape(image_aug, [image.shape[0], image.shape[1], 3])\n",
        "          image_aug = tf.clip_by_value(image_aug, 0., 1.)\n",
        "\n",
        "          return image_aug.numpy()\n",
        "\n",
        "      for _ in range(num_augmentations):\n",
        "          # aug_image = augmentations(image=image)\n",
        "          if trivial:\n",
        "              aug_image = image\n",
        "          else:\n",
        "              try:\n",
        "                aug_image = _run_filters(image)\n",
        "              except:\n",
        "                stacked_img = np.stack((image,)*3, axis=-1)\n",
        "                plt.imshow(stacked_img)\n",
        "                augmented_images = [stacked_img]\n",
        "                aug_image = _run_filters(stacked_img)\n",
        "                print(stacked_img.shape)\n",
        "                print(aug_image.shape)\n",
        "                # for i in aug_image:\n",
        "                #   plt.imshow(i)\n",
        "                #   plt.show()\n",
        "\n",
        "          augmented_images.append(aug_image)\n",
        "\n",
        "      augmented_images = np.stack(augmented_images)\n",
        "      return augmented_images\n",
        "\n",
        "  if num_augmentations > 0:\n",
        "      aug_images = augment_image(image, num_augmentations, trivial)\n",
        "  else:\n",
        "      aug_images = np.array([image])\n",
        "\n",
        "  embeddings = encode_aug_img(aug_images)\n",
        "  return embeddings"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL_uwgcYPvJX"
      },
      "source": [
        " #cc whole block\n",
        "def save_results(num_ways, num_shots, num_aug, trivial, clip_metrics_thresholds, logits_thresholds):\n",
        "  if trivial:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+ \"_Full_Full\" + \"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_metrics_with_logits.json\"\n",
        "  else:\n",
        "    #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+ \"_Full_Full\" + \"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_metrics_with_logits.json\"\n",
        "\n",
        "  with open(results_filename, 'w') as f:\n",
        "    #cc\n",
        "    results = {'metrics': clip_metrics_thresholds,\n",
        "                \"logits\": logits_thresholds,\n",
        "                }\n",
        "    json.dump(results, f)\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  delete_file_by_name(drive, folderid, results_filename)\n",
        "  save_to_drive(drive, folderid, results_filename)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKwjbQQiQZMe"
      },
      "source": [
        "def save_trends(num_ways, num_shot, num_augmentations, trivial, clip_metrics_thresholds, logits_thresholds):\n",
        "  # chenni change whole block\n",
        "  all_metrics = ['hamming', 'jaccard', 'subset_accuracy', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'c_accuracy']\n",
        "\n",
        "  f1_vals = []\n",
        "  f1_t_vals = []\n",
        "  jaccard_vals = []\n",
        "  jaccard_t_vals = []\n",
        "\n",
        "  final_dict = {}\n",
        "  for ind_metric in all_metrics:\n",
        "    vals = []\n",
        "    t_vals = []\n",
        "    final_array = []\n",
        "    for mt in clip_metrics_thresholds:\n",
        "      if ind_metric == \"hamming\":\n",
        "        ret_val, ret_t_val = get_best_metric_and_threshold(mt,ind_metric,thresholds,\"min\")\n",
        "      else:\n",
        "        ret_val, ret_t_val = get_best_metric_and_threshold(mt,ind_metric,thresholds,\"max\")\n",
        "      vals.append(ret_val)\n",
        "      t_vals.append(ret_t_val)\n",
        "\n",
        "    final_array.append(vals)\n",
        "    final_array.append(t_vals)\n",
        "    final_dict[ind_metric] = final_array\n",
        "\n",
        "  if trivial:\n",
        "      graph_filename = \"new_metrics\"+dataset_name+ \"_Full_Full\"+\"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_metrics_graphs.json\"\n",
        "  else:\n",
        "      graph_filename = \"new_metrics\"+dataset_name+ \"_Full_Full\"+\"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_metrics_graphs.json\"\n",
        "\n",
        "  with open(graph_filename, 'w') as f:\n",
        "          json.dump(final_dict, f)\n",
        "\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  delete_file_by_name(drive, folderid, graph_filename)\n",
        "  save_to_drive(drive, folderid, graph_filename)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uetf2PpOmt4"
      },
      "source": [
        "# chenni change whole block\n",
        "def get_best_metric_and_threshold(metrics_thresholds, metric_name, thresholds, optimal='max'):\n",
        "    if optimal=='max':\n",
        "        opt_value = np.max([np.mean(mt[metric_name]) for mt in metrics_thresholds])\n",
        "        opt_threshold = thresholds[np.argmax([np.mean(mt[metric_name]) for mt in metrics_thresholds])]\n",
        "    if optimal=='min':\n",
        "        opt_value = np.min([np.mean(mt[metric_name]) for mt in metrics_thresholds])\n",
        "        opt_threshold = thresholds[np.argmin([np.mean(mt[metric_name]) for mt in metrics_thresholds])]\n",
        "\n",
        "    return opt_value, opt_threshold"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHs46yaOItTW"
      },
      "source": [
        "## Setting multiple thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlo2bBCAIyQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07447eb1-26e4-4be9-fee5-d62e0810a1d0"
      },
      "source": [
        "thresholds = np.arange(0.4, 0.72, 0.01)\n",
        "thresholds"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4 , 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 ,\n",
              "       0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61,\n",
              "       0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7 , 0.71])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1mgLWl5N0hY"
      },
      "source": [
        "def plot_metrics_by_threshold(\n",
        "    metrics_thresholds, \n",
        "    thresholds, \n",
        "    metrics=['hamming', 'jaccard', 'subset_accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'classwise_accuracy', 'c_accuracy'],\n",
        "    title_suffix=\"\"\n",
        "):\n",
        "    legend = []\n",
        "    fig = plt.figure(figsize=(7,7))\n",
        "    plt.grid(True)\n",
        "\n",
        "    if 'jaccard' in metrics:\n",
        "        mean_jaccard_threshold = [np.mean(mt['jaccard']) for mt in metrics_thresholds]\n",
        "        opt_threshold_jaccard = thresholds[np.argmax(mean_jaccard_threshold)]\n",
        "        plt.plot(thresholds, mean_jaccard_threshold, c='blue')\n",
        "        plt.axvline(opt_threshold_jaccard, ls=\"--\", c='blue')\n",
        "        legend.append(\"Jaccard Index\")\n",
        "        legend.append(opt_threshold_jaccard)\n",
        "    if 'hamming' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['hamming']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='green')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='green')\n",
        "        legend.append(\"Hamming Score\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'map' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['map']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='red')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='red')\n",
        "        legend.append(\"mAP Score\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'o_f1' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['o_f1']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='yellow')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='yellow')\n",
        "        legend.append(\"OF1\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'c_f1' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['c_f1']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='orange')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='orange')\n",
        "        legend.append(\"CF1\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'o_precision' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['o_precision']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='purple')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='purple')\n",
        "        legend.append(\"OP\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'c_precision' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['c_precision']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='cyan')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='cyan')\n",
        "        legend.append(\"CP\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'o_recall' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['o_recall']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='brown')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='brown')\n",
        "        legend.append(\"OR\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'c_precision' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['c_precision']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='pink')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='pink')\n",
        "        legend.append(\"CR\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'c_accuracy' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['c_accuracy']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='maroon')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='maroon')\n",
        "        legend.append(\"CACC\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    \n",
        "    \n",
        "    \n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend(legend)\n",
        "    plt.title(title_suffix+\" Multi label metrics by threshold\")\n",
        "    plt.show()\n",
        "   "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8CNr6I4rU5d"
      },
      "source": [
        "# 5 way 5 shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g73bz0lqrU5e"
      },
      "source": [
        "## Picking indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm6j-e0brU5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eac7983-bbda-4ad8-cb63-e964c1677f74"
      },
      "source": [
        "num_ways = 5\n",
        "num_shot = 5\n",
        "num_eval = 10\n",
        "num_episodes = 10\n",
        "\n",
        "\n",
        "eval_indices = []\n",
        "train_indices = []\n",
        "wi_y = []\n",
        "eval_y = []\n",
        "shuffle = False\n",
        "num_episodes = 10\n",
        "selected_labels_per_episode = []\n",
        "\n",
        "_label_dictionary = {la:label_dictionary_per_img[la] for la in label_dictionary_per_img if len(label_dictionary_per_img[la]) >= (num_shot+num_eval)}\n",
        "unique_labels = list(_label_dictionary.keys())\n",
        "print(len(unique_labels))\n",
        "\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "for s in range(num_episodes):\n",
        "  # Setting random seed for replicability\n",
        "  np.random.seed(s)\n",
        "\n",
        "  _train_indices = []\n",
        "  _eval_indices = []\n",
        "\n",
        "  selected_labels = np.random.choice(unique_labels, size=num_ways, replace=False)\n",
        "  selected_labels_per_episode.append(selected_labels)\n",
        "  for la in selected_labels:\n",
        "      la_indices_train = label_dictionary_per_img[la]\n",
        "      la_indices_eval = label_dictionary_per_img[la]\n",
        "      \n",
        "      tr_idx = []\n",
        "      ev_idx = []\n",
        "      while len(tr_idx) < num_shot:\n",
        "          idx = np.random.choice(la_indices_train)\n",
        "          img = mpimg.imread(data_folder + split + '/' + image_id_col[idx] + '.jpg')\n",
        "          if img.ndim!=3:\n",
        "            del img\n",
        "            continue\n",
        "          if idx not in _train_indices and idx not in _eval_indices and idx not in tr_idx and idx not in [2898, 2899, 971]:\n",
        "              tr_idx.append(idx)\n",
        "              del img\n",
        "      while len(ev_idx) < num_eval:\n",
        "          idx = np.random.choice(la_indices_eval)\n",
        "          img = mpimg.imread(data_folder + split + '/' + image_id_col[idx] + '.jpg')\n",
        "          if img.ndim!=3:\n",
        "            del img\n",
        "            continue\n",
        "          if idx not in _train_indices and idx not in _eval_indices and idx not in tr_idx and idx not in ev_idx and idx not in [2898, 2899, 971]:\n",
        "              ev_idx.append(idx)\n",
        "              del img\n",
        "\n",
        "      _train_indices = _train_indices + tr_idx\n",
        "      _eval_indices = _eval_indices + ev_idx\n",
        "\n",
        "  if shuffle:\n",
        "      np.random.shuffle(_train_indices)\n",
        "      np.random.shuffle(_eval_indices)\n",
        "\n",
        "  train_indices.append(_train_indices)\n",
        "  eval_indices.append(_eval_indices)\n",
        "\n",
        "  _wi_y = []\n",
        "  for idx in _train_indices:\n",
        "      la = labels_per_img[idx]\n",
        "      _wi_y.append(list([l for l in la if l in selected_labels]))\n",
        "  _eval_y = []\n",
        "  for idx in _eval_indices:\n",
        "      la = labels_per_img[idx]\n",
        "      _eval_y.append(list([l for l in la if l in selected_labels]))\n",
        "\n",
        "  wi_y.append(_wi_y)\n",
        "  eval_y.append(_eval_y)\n",
        "\n",
        "  pbar.update(s+1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:03:25] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRuwBybGh3Gp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf30491-803b-4651-96db-f685e43bb0c3"
      },
      "source": [
        "eval_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  emb = encode_full_img(eval_indices[i])\n",
        "  eval_emb_per_episode.append(emb)\n",
        "  del emb\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:01:08] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLW-8vrbrU5f"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd3gA1UyJIIM"
      },
      "source": [
        "###0 augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_Z7sa-EefOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7fd2d0-614b-44c6-90e3-55af2f3e3677"
      },
      "source": [
        "num_augmentations = 0\n",
        "Trivial = False\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  emb_per_img = []\n",
        "  for j in train_indices[i]:\n",
        "    img = mpimg.imread(data_folder + split + '/' + image_id_col[j] + '.jpg')\n",
        "    emb = embed_augmented_imgs(img, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "    del img\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del emb_per_img\n",
        "  del emb\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:03:22] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKsng-NSehPV"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctUKmm_eJLYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3a2aac-baed-4b8b-8c3a-005ee61877b2"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:22:22] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4UbuCjDlrgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f688a1-2d35-4901-ee45-bd14109006bf"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting new_metricsIMaterialist_5w5s0a_metrics_with_logits.json from GDrive\n",
            "Uploaded new_metricsIMaterialist_5w5s0a_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Uploaded new_metricsIMaterialist_Full_Full_5w5s0a_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaULa4s6Jijf"
      },
      "source": [
        "# for i in range(0, 21, 5):\n",
        "#   plot_metrics_by_threshold([cmt[i] for cmt in clip_metrics_thresholds], thresholds, title_suffix=dataset_name + \" Clip {} way {} shot Train epochs = {}\\n\".format(num_ways, num_shot, i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq-5M9WVnUX6"
      },
      "source": [
        "###With 5 simclr augmentations trivial=False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXvq1d_bdm4v",
        "outputId": "88d547c9-4615-451b-e40f-a30fffe7d0cd"
      },
      "source": [
        "num_augmentations = 5\n",
        "Trivial = False\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  emb_per_img = []\n",
        "  for j in train_indices[i]:\n",
        "    img = mpimg.imread(data_folder + split + '/' + id_per_img[j] + '.jpg')\n",
        "    img = cv2.resize(img, (0,0), fx=0.7, fy=0.7)\n",
        "    if img.ndim != 3:\n",
        "      print(\"J = {} has few ndim\".format(j))\n",
        "    emb = embed_augmented_imgs(img, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del emb_per_img\n",
        "  del emb\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:04:28] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STg98uYFdv94"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i][0].shape[0], 512))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOU8-d-kNSc9",
        "outputId": "bce91ca3-a99f-42dc-daad-ce3bd2aef6d7"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:37:04] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppWfYHT-lEuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949d1de9-9df8-44b2-ee22-850c8dc73dcd"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsIMaterialist_5w5s5a_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Uploaded new_metricsIMaterialist_Full_Full_5w5s5a_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7a_Pz5GnaAj"
      },
      "source": [
        "###With 5 trivial augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn5_0zJad0gj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7831ae-272a-48f8-9b9e-0aea1fed8159"
      },
      "source": [
        "num_augmentations = 5\n",
        "Trivial = True\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  emb_per_img = []\n",
        "  for j in train_indices[i]:\n",
        "    img = mpimg.imread(data_folder + split + '/' + image_id_col[j] + '.jpg')\n",
        "    img = cv2.resize(img, (0,0), fx=0.8, fy=0.8)\n",
        "    emb = embed_augmented_imgs(img, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del emb_per_img\n",
        "  del emb\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:03:34] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8CjwLozeHDA"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKUFa1N4ndyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120c41e8-55d8-4ba4-8299-52ecc4c40557"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:38:07] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYoUzqjklLIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1383d7-d179-436d-97e2-af14ac375f1c"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsIMaterialist_5w5s5a_trivial_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Uploaded new_metricsIMaterialist_Full_Full_5w5s5a_trivial_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GNtZL2-0HNh"
      },
      "source": [
        "###10 Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAh_NUjIeO8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7a7bbb-78b4-4948-ae56-28cfbfb3f0e7"
      },
      "source": [
        "num_augmentations = 10\n",
        "Trivial = False\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  emb_per_img = []\n",
        "  for j in train_indices[i]:\n",
        "    img = mpimg.imread(data_folder + split + '/' + image_id_col[j] + '.jpg')\n",
        "    img = cv2.resize(img, (0,0), fx=0.6, fy=0.6)\n",
        "    emb = embed_augmented_imgs(img, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "    del img\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del emb_per_img\n",
        "  del emb\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/PAL_2021/PAL_HILL/ExperimentModules/simclr_data_augmentations.py:326: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/PAL_2021/PAL_HILL/ExperimentModules/simclr_data_augmentations.py:328: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:11:05] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8iXKeMkeQdA"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-EGacFa0Kde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eae469a-5438-4e38-ce5c-178eab2bd3cc"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:49:11] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ1vtQvelSUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c62233-cd63-4a3c-b040-46d80b23c0ac"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsIMaterialist_Full_Full_5w5s10a_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Uploaded new_metricsIMaterialist_Full_Full_5w5s10a_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHPkp7mgDqkR"
      },
      "source": [
        "### 10 Trivial augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0A_z8kEeZmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b759af1b-5b7f-46be-ac43-65d6ac94c9c2"
      },
      "source": [
        "num_augmentations = 10\n",
        "Trivial = True\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  emb_per_img = []\n",
        "  for j in train_indices[i]:\n",
        "    img = mpimg.imread(data_folder + split + '/' + id_per_img[j] + '.jpg')\n",
        "    img = cv2.resize(img, (0,0), fx=0.6, fy=0.6)\n",
        "    emb = embed_augmented_imgs(img, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "    del img\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del emb_per_img\n",
        "  del emb\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:04:18] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k52zPryNeamO"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij0Ep-x7DssL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c79a2b-82f9-4073-b76e-3ed0c995b3d8"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:49:29] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyKr5uw-lYd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d0e0812-b706-4b43-c08c-2af8b38744a1"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsIMaterialist_Full_Full_5w5s10a_trivial_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Uploaded new_metricsIMaterialist_Full_Full_5w5s10a_trivial_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}