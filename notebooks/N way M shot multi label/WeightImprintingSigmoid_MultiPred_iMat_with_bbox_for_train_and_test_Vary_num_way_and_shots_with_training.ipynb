{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WeightImprintingSigmoid_MultiPred_iMat with bbox for train and test Vary num_way and shots with training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RGlVnbugxFK2",
        "gmgIrfT8hDNE",
        "3rKe3HqM523g",
        "OLU-gp7n8__E",
        "9z1WQnXdLHy2",
        "NzsubsEm72rr",
        "zU_gxQ0KbwMh",
        "g73bz0lqrU5e"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wCVCAfpyE0A"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-7JU3Q7q_XT",
        "outputId": "4f5e603f-610a-4315-832d-9c0414eaf7e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXAPOzOK4mTl",
        "outputId": "e6f3c0ac-1114-4955-fd0d-09be9ff9213d"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Cloning PAL_2021 to access modules.\n",
        "# Need password to access private repo.\n",
        "\n",
        "if 'PAL_2021' not in os.listdir():\n",
        "    cmd_string = 'git clone https://github.com/PAL-ML/CLIPPER.git'\n",
        "    os.system(cmd_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting httplib2==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/83/5e006e25403871ffbbf587c7aa4650158c947d46e89f2d50dcaf018464de/httplib2-0.15.0-py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.5MB/s \n",
            "\u001b[?25hInstalling collected packages: httplib2\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed httplib2-0.15.0\n",
            "Github User name: ashadhaz\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlVnbugxFK2"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmgIrfT8hDNE"
      },
      "source": [
        "## Install multi label metrics dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6xXPAFbe6Gp",
        "outputId": "a5bf1be7-e94d-463a-9fb4-6cfd7f879ff5"
      },
      "source": [
        "! pip install scikit-learn==0.24"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.24\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/ed/ab51a8da34d2b3f4524b21093081e7f9e2ddf1c9eac9f795dcf68ad0a57d/scikit_learn-0.24.0-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.4.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.19.5)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.0 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKe3HqM523g"
      },
      "source": [
        "## Install CLIP dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poS-WNDixIhY"
      },
      "source": [
        "# import subprocess\n",
        "\n",
        "# CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "# print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "# if CUDA_version == \"10.0\":\n",
        "#     torch_version_suffix = \"+cu100\"\n",
        "# elif CUDA_version == \"10.1\":\n",
        "#     torch_version_suffix = \"+cu101\"\n",
        "# elif CUDA_version == \"10.2\":\n",
        "#     torch_version_suffix = \"\"\n",
        "# else:\n",
        "#     torch_version_suffix = \"+cu110\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-69W8M59nA"
      },
      "source": [
        "# ! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYwBZS1N6A3d"
      },
      "source": [
        "# ! pip install ftfy regex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oIcNBYB8lz3",
        "outputId": "88388acb-685c-42aa-96cb-ef78a540b27f"
      },
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-69p_x8ld\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-69p_x8ld\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/b5/5da463f9c7823e0e575e9908d004e2af4b36efa8d02d3d6dad57094fcb11/ftfy-6.0.1.tar.gz (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Collecting torch~=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 21kB/s \n",
            "\u001b[?25hCollecting torchvision~=0.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/df/969e69a94cff1c8911acb0688117f95e1915becc1e01c73e7960a2c76ec8/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip, ftfy\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368708 sha256=c0ca7647946e327470610b0633bda4f12fe4925827ec85681e4c7b4ec4c6b39f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-71ytrap3/wheels/79/51/d7/69f91d37121befe21d9c52332e04f592e17d1cabc7319b3e09\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.1-cp37-none-any.whl size=41573 sha256=28bd126c7c53a454333e5ad85b4443825b783c72028e9a1764c79e21fe2a81af\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/73/c7/9056e14b04919e5c262fe80b54133b1a88d73683d05d7ac65c\n",
            "Successfully built clip ftfy\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ftfy, torch, torchvision, clip\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed clip-1.0 ftfy-6.0.1 torch-1.7.1 torchvision-0.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-gp7n8__E"
      },
      "source": [
        "## Install clustering dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLg9ozo9Hvc"
      },
      "source": [
        "!pip -q install umap-learn>=0.3.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1WQnXdLHy2"
      },
      "source": [
        "## Install dataset manager dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1vvMx7_LLSp",
        "outputId": "d601ac6d-4ae6-4166-cdd4-6fca0a406a8c"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=d6bbbe5c4f5ee20947593a2fd72cdbd69d1ab0194b8e6858c3c81177971484b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzsubsEm72rr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZI62a6G74kw"
      },
      "source": [
        "# ML Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import keras\n",
        "\n",
        "# Data processing\n",
        "import PIL\n",
        "import base64\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from matplotlib import cm\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Models\n",
        "import clip\n",
        "\n",
        "# Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Clustering\n",
        "# import umap\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "#from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Misc\n",
        "import progressbar\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.metrics import jaccard_score, hamming_loss, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "# Modules\n",
        "# from PAL_2021.PAL_HILL.ExperimentModules import embedding_models\n",
        "from CLIPPER.code.ExperimentModules.dataset_manager import DatasetManager\n",
        "from CLIPPER.code.ExperimentModules.weight_imprinting_classifier import WeightImprintingClassifier\n",
        "from CLIPPER.code.ExperimentModules import simclr_data_augmentations\n",
        "from CLIPPER.code.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)\n",
        "\n",
        "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_gxQ0KbwMh"
      },
      "source": [
        "# Initialization & Constants\n",
        "\n",
        "**Edited**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bih5tBPdbx3u",
        "outputId": "dcec42b3-331e-4cf5-a59e-f38eb90a6408"
      },
      "source": [
        "dataset_name = 'IMaterialist'\n",
        "folder_name = \"FGCVIMaterialist-Embeddings-24-03-21\"\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1bK72W-Um20EQDEyChNhNJthUNbmoSEjD'\n",
        "\n",
        "# Filepaths\n",
        "train_labels_filename = \"train_labels.npz\"\n",
        "val_labels_filename = \"val_labels.npz\"\n",
        "test_labels_filename = \"test_labels.npz\"\n",
        "\n",
        "train_embeddings_filename_suffix = \"_embeddings_train.npz\"\n",
        "val_embeddings_filename_suffix = \"_embeddings_val.npz\"\n",
        "test_embeddings_filename_suffix = \"_embeddings_test.npz\"\n",
        "\n",
        "\n",
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = create_expt_dir(drive, parentid, folder_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: FGCVIMaterialist-Embeddings-24-03-21, id: 1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Experiment folder already exists. WARNING: Following with this run might overwrite existing results stored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxTa8MVsvQCN"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI-Sx_zz0-jc"
      },
      "source": [
        "LABEL_PATH = '/content/drive/MyDrive/PAL_HILL_2021/Experiments/FGCVIMaterialist-Embeddings-24-03-21/train_labels.npz'\n",
        "IMG_PATH = '/content/drive/MyDrive/PAL_HILL_2021/Datasets/imaterialist-fashion'\n",
        "# IMG_LIST_PATH = '/content/drive/MyDrive/PAL_HILL_2021/Datasets/Coco2017Train/img_list.npz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6S124Jfwuu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8443a444-8295-4e90-9750-791681b7d3b1"
      },
      "source": [
        "def get_ndarray_from_drive(drive, folderid, filename):\n",
        "    download_file_by_name(drive, folderid, filename)\n",
        "    return np.load(filename, allow_pickle=True)['arr_0']\n",
        "\n",
        "train_labels = get_ndarray_from_drive(drive, folderid, train_labels_filename)\n",
        "# val_labels = get_ndarray_from_drive(drive, folderid, val_labels_filename)\n",
        "# test_labels = get_ndarray_from_drive(drive, folderid, test_labels_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train_labels.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlwqmSoomhKb"
      },
      "source": [
        "data_folder = '/content/gdrive/MyDrive/PAL_HILL_2021/Datasets/imaterialist-fashion/'\n",
        "data_df = pd.read_csv('/content/gdrive/MyDrive/PAL_HILL_2021/Datasets/imaterialist-fashion/train.csv')\n",
        "split = 'train'\n",
        "image_dir = os.path.join(data_folder, split)\n",
        "class_id_col = data_df['ClassId'].copy().values\n",
        "image_id_col = data_df['ImageId'].copy().values\n",
        "image_fn_col = data_df['ImageId'].copy().apply(lambda x: os.path.join(image_dir, x+'.jpg')).values\n",
        "encoded_pixels_col = data_df['EncodedPixels'].copy().values\n",
        "height_col = data_df['Height'].copy().values\n",
        "width_col = data_df['Width'].copy().values\n",
        "attributes_ids_col = data_df['AttributesIds'].copy().fillna('').values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ-qMXhGrA_l"
      },
      "source": [
        "final_train_labels = train_labels\n",
        "for i in range(len(final_train_labels)):\n",
        "    la = final_train_labels[i]\n",
        "    temp_array = []\n",
        "\n",
        "    for l in la:\n",
        "      if l <= 293:\n",
        "        temp_array.append(l)\n",
        "\n",
        "    fin_array = np.array(temp_array)\n",
        "    train_labels[i] = fin_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "222ZNgXkG1i_"
      },
      "source": [
        "labels_per_img = []\n",
        "id_per_img = []\n",
        "j = 1\n",
        "s = set()\n",
        "for l in final_train_labels[0]:\n",
        "  s.add(l)\n",
        "for i in range(1, len(final_train_labels)):\n",
        "  if image_id_col[j] == image_id_col[j-1]:\n",
        "    for l in final_train_labels[i]:\n",
        "      s.add(l)\n",
        "  else:\n",
        "    labels_per_img.append(list(s))\n",
        "    s.clear()\n",
        "    id_per_img.append(image_id_col[j-1])\n",
        "  j+=1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-f4BEcDgeVC"
      },
      "source": [
        "# Init model (Clip)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3jcG0Bugh9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05b1f30-c086-425f-e24c-58823df54dcb"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 354M/354M [00:06<00:00, 54.4MiB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLbRqaYxzbr7"
      },
      "source": [
        "# Create label dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emz85fNX0Vif"
      },
      "source": [
        "unique_labels = []\n",
        "for i in range(294):\n",
        "  unique_labels.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TubS-RLzeVM"
      },
      "source": [
        "label_dictionary = {la:[] for la in unique_labels}\n",
        "\n",
        "for i in range(35000):\n",
        "    la = final_train_labels[i]\n",
        "\n",
        "    for l in la:\n",
        "        label_dictionary[l].append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr3YTf2tJyov"
      },
      "source": [
        "label_dictionary_per_img = {la:[] for la in unique_labels}\n",
        "\n",
        "for i in range(8700):\n",
        "    la = labels_per_img[i]\n",
        "\n",
        "    for l in la:\n",
        "        label_dictionary_per_img[l].append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP6ftkDCvKul"
      },
      "source": [
        "# Weight Imprinting models on train data embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJIGo_R86GQi"
      },
      "source": [
        "## Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1rYFOJQNnhd"
      },
      "source": [
        "def generate_patch_list(indices, episode):\n",
        "  patches_res = []\n",
        "  for i in indices:\n",
        "    img = mpimg.imread(IMG_PATH + i.zfill(12) + '.jpg')\n",
        "    # fig, ax = plt.subplots()\n",
        "    # ax.imshow(img)\n",
        "    for j in labels[i]:\n",
        "      if j['category_id'] in selected_labels_per_episode[episode]:\n",
        "        x = int(j['bbox'][0])\n",
        "        x1 = int(j['bbox'][0] + j['bbox'][2])\n",
        "        y = int(j['bbox'][1])\n",
        "        y1 = int(j['bbox'][1] + j['bbox'][3])\n",
        "        # rect = patches.Rectangle((j['bbox'][0], j['bbox'][1]), j['bbox'][2], j['bbox'][3], linewidth=1, edgecolor='r', facecolor='none')\n",
        "        # ax.add_patch(rect)\n",
        "        patches_res.append(img[y:y1, x:x1, :])\n",
        "  return patches_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUlWnGDYdsw8"
      },
      "source": [
        "def _process_encoded_pixels(row):\n",
        "\t\tdef get_pixel_loc(value):\n",
        "\t\t    x = value%height\n",
        "\t\t    y = value//height\n",
        "\n",
        "\t\t    return x, y\n",
        "\n",
        "\t\tdef process_encoded_pixels_string(encoded_pixels):\n",
        "\t\t    mask_pixels = []\n",
        "\t\t    ep_list = [int(ep_item) for ep_item in encoded_pixels.split(' ')]\n",
        "\n",
        "\t\t    idx = 0\n",
        "\t\t    while idx < len(ep_list):\n",
        "\t\t        pixel = ep_list[idx]\n",
        "\t\t        num_pixels = ep_list[idx+1]\n",
        "\n",
        "\t\t        for np in range(num_pixels):\n",
        "\t\t            mask_pixels.append(pixel+np)\n",
        "\t\t        \n",
        "\t\t        idx += 2\n",
        "\n",
        "\t\t    return mask_pixels\n",
        "\n",
        "\t\tdef get_mask(mask_pixels, height, width):\n",
        "\t\t    mask = np.zeros((height, width))\n",
        "\t\t    for mp in mask_pixels:\n",
        "\t\t        x, y = get_pixel_loc(mp)\n",
        "\t\t        mask[x, y] = 1\n",
        "\t\t    \n",
        "\t\t    return mask\n",
        "\n",
        "\t\tencoded_pixels = row[0]# .numpy().decode('utf=8')\n",
        "\t\theight = int(row[1])\n",
        "\t\twidth = int(row[2])\n",
        "\t\tmask_pixels = process_encoded_pixels_string(encoded_pixels)\n",
        "\t\tmask = get_mask(mask_pixels, height, width)\n",
        "\n",
        "\t\treturn mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS3Cn8i_dwMO"
      },
      "source": [
        "def generate_masks(indices):\n",
        "  masks_for_index = []\n",
        "  for i in indices:\n",
        "    img = mpimg.imread(data_folder + split + '/' + image_id_col[i] + '.jpg')\n",
        "    # print(\"index i = {} has shape = {}\".format(i, img.shape))\n",
        "    mask = _process_encoded_pixels((encoded_pixels_col[i], height_col[i], width_col[i]))\n",
        "    props = regionprops(mask.astype(int))\n",
        "    for prop in props:\n",
        "      if img.ndim == 2:\n",
        "        masks_for_index.append(img[prop.bbox[0]: prop.bbox[2], prop.bbox[1]:prop.bbox[3]])\n",
        "      else:\n",
        "        masks_for_index.append(img[prop.bbox[0]: prop.bbox[2], prop.bbox[1]:prop.bbox[3], :])\n",
        "      break\n",
        "  return masks_for_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmwNhL0G-MS_"
      },
      "source": [
        "def encode_patch(patches):\n",
        "  embeddings = []\n",
        "  for p in patches:\n",
        "    # print(img.shape)\n",
        "    pil_img = Image.fromarray(p)\n",
        "    preproc_img = preprocess(pil_img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      _emb = model.encode_image(preproc_img)  \n",
        "    embeddings.append(_emb.cpu().detach().numpy()[0])\n",
        "    del _emb\n",
        "    del pil_img\n",
        "    del preproc_img\n",
        "    #embeddings.append(np.array(emb_per_img))\n",
        "    #del emb_per_img\n",
        "  return np.array(embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeU4N5MBSjj-"
      },
      "source": [
        "# for full images we just need the index of the image eg '34'\n",
        "def encode_full_img(indices):\n",
        "  embeddings = []\n",
        "  for i in indices:\n",
        "    img = mpimg.imread(data_folder + split + '/' + id_per_img[i] + '.jpg')\n",
        "    pil_img = Image.fromarray(img)\n",
        "    preproc_img = preprocess(pil_img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      _emb = model.encode_image(preproc_img)  \n",
        "    embeddings.append(_emb.cpu().detach().numpy()[0])\n",
        "    del _emb\n",
        "    del pil_img\n",
        "    del preproc_img\n",
        "    #embeddings.append(np.array(emb_per_img))\n",
        "    #del emb_per_img\n",
        "  return np.array(embeddings)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A56l3kYbV6XU"
      },
      "source": [
        "def encode_aug_img(images):\n",
        "  images *= 255\n",
        "  images = images.astype('uint8')\n",
        "  embeddings = []\n",
        "  for img in images:\n",
        "    pil_img = Image.fromarray(img.astype('uint8'))\n",
        "    preproc_img = preprocess(pil_img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "      _emb = model.encode_image(preproc_img)  \n",
        "    embeddings.append(_emb.cpu().detach().numpy()[0])\n",
        "    del _emb\n",
        "    del pil_img\n",
        "    del preproc_img\n",
        "  #embeddings.append(np.array(emb_per_img))\n",
        "    #del emb_per_img\n",
        "  return np.array(embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv68q8TH6tvG"
      },
      "source": [
        "def start_progress_bar(bar_len):\n",
        "    widgets = [\n",
        "        ' [', \n",
        "        progressbar.Timer(format= 'elapsed time: %(elapsed)s'), \n",
        "        '] ', \n",
        "        progressbar.Bar('*'),' (', \n",
        "        progressbar.ETA(), ') ', \n",
        "        ]\n",
        "    pbar = progressbar.ProgressBar(\n",
        "        max_value=bar_len, widgets=widgets\n",
        "        ).start()\n",
        "    return pbar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OjvSlqJHXDZ"
      },
      "source": [
        "def run_train_loop( \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways,\n",
        "    verbose=True,\n",
        "    normalize=True,\n",
        "    train_epochs_loop=[5],\n",
        "    train_batch_size=5,\n",
        "    metrics=['hamming', 'jaccard', 'subset_accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'classwise_accuracy', 'c_accuracy'],\n",
        "    threshold=0.72\n",
        "):\n",
        "    metrics_values = [{m:[] for m in metrics} for _ in range(len(train_epochs_loop)+1)]\n",
        "\n",
        "    if verbose:\n",
        "        pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "    all_logits = []   #cc\n",
        "\n",
        "    for idx_ep in range(num_episodes):\n",
        "        wi_x = train_emb_reshaped[idx_ep]\n",
        "        eval_x = eval_emb_reshaped[idx_ep]\n",
        "\n",
        "        ep_logits = []  #cc\n",
        "\n",
        "        _wi_y = wi_y[idx_ep]\n",
        "        wi_y_ = []\n",
        "        for i in range(len(_wi_y)):\n",
        "          for j in range(num_augmentations+1):\n",
        "            wi_y_.append(_wi_y[i])\n",
        "        \n",
        "        if normalize:\n",
        "            wi_x = WeightImprintingClassifier.preprocess_input(wi_x)\n",
        "            eval_x = WeightImprintingClassifier.preprocess_input(eval_x)\n",
        "\n",
        "        wi_weights, label_mapping = WeightImprintingClassifier.get_imprinting_weights(\n",
        "            wi_x, wi_y_, False, True\n",
        "            )\n",
        "\n",
        "        wi_parameters = {\n",
        "            \"num_classes\": num_ways,\n",
        "            \"input_dims\": wi_x.shape[-1],\n",
        "            \"scale\": False,\n",
        "            \"dense_layer_weights\": wi_weights,\n",
        "            \"multi_label\": True\n",
        "        }\n",
        "\n",
        "        wi_cls = WeightImprintingClassifier(wi_parameters)\n",
        "\n",
        "        met = wi_cls.evaluate_multi_label_metrics(\n",
        "            eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "            )\n",
        "        for m in met:\n",
        "            metrics_values[0][m].append(met[m])\n",
        "        \n",
        "\n",
        "        for idx_tr_ep in range(len(train_epochs_loop)):\n",
        "            ep_y = wi_y_\n",
        "            rev_label_mapping = {label_mapping[val]:val for val in label_mapping}\n",
        "            train_y = np.zeros((len(ep_y), num_ways))\n",
        "            for idx_y, _y in enumerate(ep_y):\n",
        "                for l in _y:\n",
        "                    train_y[idx_y, rev_label_mapping[l]] = 1\n",
        "\n",
        "\n",
        "            wi_cls.train(wi_x, train_y, train_epochs_loop[idx_tr_ep], train_batch_size)\n",
        "\n",
        "            logits = wi_cls.predict_scores(eval_x).tolist()  #cc\n",
        "            ep_logits.append(logits)  #cc\n",
        "\n",
        "            met = wi_cls.evaluate_multi_label_metrics(\n",
        "                eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "                )\n",
        "            for m in met:\n",
        "                metrics_values[idx_tr_ep+1][m].append(met[m])\n",
        "\n",
        "        all_logits.append(ep_logits)  #cc\n",
        "        # _pred_y = wi_cls.predict_multi_label(eval_x, threshold)\n",
        "        # for j in range(len(_eval_y)):\n",
        "        #     print([label_mapping[p] for p in _pred_y[j]], \" vs \", _eval_y[j])\n",
        "\n",
        "        # met = wi_cls.evaluate_multi_label_metrics(\n",
        "        #     eval_x, eval_y[idx_ep], label_mapping, threshold, metrics\n",
        "        #     )\n",
        "        \n",
        "        # for m in met:\n",
        "        #     metrics_values[m].append(met[m])\n",
        "\n",
        "        del wi_x\n",
        "        del eval_x\n",
        "        del wi_cls\n",
        "\n",
        "        if verbose:\n",
        "            pbar.update(idx_ep+1)\n",
        "\n",
        "    return metrics_values, all_logits #cc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_p3xln4SB0V"
      },
      "source": [
        "def get_max_mean_jaccard_index_by_threshold(metrics_thresholds):\n",
        "    max_mean_jaccard = np.max([np.mean(mt['jaccard']) for mt in metrics_thresholds])\n",
        "    return max_mean_jaccard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0QL9HbXSHcN"
      },
      "source": [
        "def get_max_mean_jaccard_index_with_threshold(metrics_thresholds):\n",
        "    max_mean_jaccard = np.max([np.mean(mt['jaccard']) for mt in metrics_thresholds])\n",
        "    threshold = np.argmax([np.mean(mt['jaccard']) for mt in metrics_thresholds])\n",
        "    return max_mean_jaccard, threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhZxggaNt_S3"
      },
      "source": [
        "def get_max_mean_f1_score_with_threshold(metrics_thresholds):\n",
        "    max_mean_jaccard = np.max([np.mean(mt['o_f1']) for mt in metrics_thresholds])\n",
        "    threshold = np.argmax([np.mean(mt['o_f1']) for mt in metrics_thresholds])\n",
        "    return max_mean_jaccard, threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksMueTe9SKwb"
      },
      "source": [
        "def get_mean_max_jaccard_index_by_episode(metrics_thresholds):\n",
        "    mean_max_jaccard = np.mean(np.max(np.array([mt['jaccard'] for mt in metrics_thresholds]), axis=0))\n",
        "    return mean_max_jaccard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfL4tkTDUyJh"
      },
      "source": [
        "def embed_augmented_imgs(image, num_augmentations, trivial=False):\n",
        "  if np.max(image) > 1:\n",
        "    image = image/255\n",
        "    \n",
        "  def augment_image(image, num_augmentations, trivial=False):\n",
        "      \"\"\" Perform SimCLR augmentations on the image\n",
        "      \"\"\"\n",
        "\n",
        "      augmented_images = [image]\n",
        "\n",
        "      def _run_filters(image):\n",
        "          width = image.shape[1]\n",
        "          height = image.shape[0]\n",
        "          image_aug = simclr_data_augmentations.random_crop_with_resize(\n",
        "              image,\n",
        "              height,\n",
        "              width\n",
        "              )\n",
        "          image_aug = tf.image.random_flip_left_right(image_aug)\n",
        "          image_aug = simclr_data_augmentations.random_color_jitter(image_aug)\n",
        "          image_aug = simclr_data_augmentations.random_blur(\n",
        "              image_aug,\n",
        "              height,\n",
        "              width\n",
        "              )\n",
        "          image_aug = tf.reshape(image_aug, [image.shape[0], image.shape[1], 3])\n",
        "          image_aug = tf.clip_by_value(image_aug, 0., 1.)\n",
        "\n",
        "          return image_aug.numpy()\n",
        "\n",
        "      for _ in range(num_augmentations):\n",
        "          # aug_image = augmentations(image=image)\n",
        "          if trivial:\n",
        "              aug_image = image\n",
        "          else:\n",
        "              try:\n",
        "                aug_image = _run_filters(image)\n",
        "              except:\n",
        "                stacked_img = np.stack((image,)*3, axis=-1)\n",
        "                plt.imshow(stacked_img)\n",
        "                augmented_images = [stacked_img]\n",
        "                aug_image = _run_filters(stacked_img)\n",
        "                print(stacked_img.shape)\n",
        "                print(aug_image.shape)\n",
        "                # for i in aug_image:\n",
        "                #   plt.imshow(i)\n",
        "                #   plt.show()\n",
        "\n",
        "          augmented_images.append(aug_image)\n",
        "\n",
        "      augmented_images = np.stack(augmented_images)\n",
        "      return augmented_images\n",
        "\n",
        "  if num_augmentations > 0:\n",
        "      aug_images = augment_image(image, num_augmentations, trivial)\n",
        "  else:\n",
        "      aug_images = np.array([image])\n",
        "\n",
        "  embeddings = encode_aug_img(aug_images)\n",
        "  return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL_uwgcYPvJX"
      },
      "source": [
        " #cc whole block\n",
        "def save_results(num_ways, num_shots, num_aug, trivial, clip_metrics_thresholds, logits_thresholds):\n",
        "  if trivial:\n",
        "  #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+ \"_Patch_Patch\" + \"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_metrics_with_logits.json\"\n",
        "  else:\n",
        "    #cc\n",
        "    results_filename = \"new_metrics\"+dataset_name+ \"_Patch_Patch\" + \"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_metrics_with_logits.json\"\n",
        "\n",
        "  with open(results_filename, 'w') as f:\n",
        "    #cc\n",
        "    results = {'metrics': clip_metrics_thresholds,\n",
        "                \"logits\": logits_thresholds,\n",
        "                }\n",
        "    json.dump(results, f)\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  delete_file_by_name(drive, folderid, results_filename)\n",
        "  save_to_drive(drive, folderid, results_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKwjbQQiQZMe"
      },
      "source": [
        "def save_trends(num_ways, num_shot, num_augmentations, trivial, clip_metrics_thresholds, logits_thresholds):\n",
        "  # chenni change whole block\n",
        "  all_metrics = ['hamming', 'jaccard', 'subset_accuracy', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'c_accuracy']\n",
        "\n",
        "  f1_vals = []\n",
        "  f1_t_vals = []\n",
        "  jaccard_vals = []\n",
        "  jaccard_t_vals = []\n",
        "\n",
        "  final_dict = {}\n",
        "  for ind_metric in all_metrics:\n",
        "    vals = []\n",
        "    t_vals = []\n",
        "    final_array = []\n",
        "    for mt in clip_metrics_thresholds:\n",
        "      if ind_metric == \"hamming\":\n",
        "        ret_val, ret_t_val = get_best_metric_and_threshold(mt,ind_metric,thresholds,\"min\")\n",
        "      else:\n",
        "        ret_val, ret_t_val = get_best_metric_and_threshold(mt,ind_metric,thresholds,\"max\")\n",
        "      vals.append(ret_val)\n",
        "      t_vals.append(ret_t_val)\n",
        "\n",
        "    final_array.append(vals)\n",
        "    final_array.append(t_vals)\n",
        "    final_dict[ind_metric] = final_array\n",
        "\n",
        "  if trivial:\n",
        "      graph_filename = \"new_metrics\"+dataset_name+ \"_Patch_Patch\"+\"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_trivial_metrics_graphs.json\"\n",
        "  else:\n",
        "      graph_filename = \"new_metrics\"+dataset_name+ \"_Patch_Patch\"+\"_\"+str(num_ways)+\"w\"+str(num_shot)+\"s\"+str(num_augmentations)+\"a_metrics_graphs.json\"\n",
        "\n",
        "  with open(graph_filename, 'w') as f:\n",
        "          json.dump(final_dict, f)\n",
        "\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  delete_file_by_name(drive, folderid, graph_filename)\n",
        "  save_to_drive(drive, folderid, graph_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mehg_2IzReK4"
      },
      "source": [
        "# chenni change whole block\n",
        "def get_best_metric_and_threshold(metrics_thresholds, metric_name, thresholds, optimal='max'):\n",
        "    if optimal=='max':\n",
        "        opt_value = np.max([np.mean(mt[metric_name]) for mt in metrics_thresholds])\n",
        "        opt_threshold = thresholds[np.argmax([np.mean(mt[metric_name]) for mt in metrics_thresholds])]\n",
        "    if optimal=='min':\n",
        "        opt_value = np.min([np.mean(mt[metric_name]) for mt in metrics_thresholds])\n",
        "        opt_threshold = thresholds[np.argmin([np.mean(mt[metric_name]) for mt in metrics_thresholds])]\n",
        "\n",
        "    return opt_value, opt_threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHs46yaOItTW"
      },
      "source": [
        "## Setting multiple thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlo2bBCAIyQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec9e4cb-bb3c-4198-84ac-d232cf6cc2be"
      },
      "source": [
        "thresholds = np.arange(0.4, 0.72, 0.01)\n",
        "thresholds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4 , 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 ,\n",
              "       0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61,\n",
              "       0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7 , 0.71])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1mgLWl5N0hY"
      },
      "source": [
        "def plot_metrics_by_threshold(\n",
        "    metrics_thresholds, \n",
        "    thresholds, \n",
        "    metrics=['hamming', 'jaccard', 'subset_accuracy', 'ap', 'map', 'c_f1', 'o_f1', 'c_precision', 'o_precision', 'c_recall', 'o_recall', 'classwise_accuracy', 'c_accuracy'],\n",
        "    title_suffix=\"\"\n",
        "):\n",
        "    legend = []\n",
        "    fig = plt.figure(figsize=(7,7))\n",
        "    plt.grid(True)\n",
        "\n",
        "    if 'jaccard' in metrics:\n",
        "        mean_jaccard_threshold = [np.mean(mt['jaccard']) for mt in metrics_thresholds]\n",
        "        opt_threshold_jaccard = thresholds[np.argmax(mean_jaccard_threshold)]\n",
        "        plt.plot(thresholds, mean_jaccard_threshold, c='blue')\n",
        "        plt.axvline(opt_threshold_jaccard, ls=\"--\", c='blue')\n",
        "        legend.append(\"Jaccard Index\")\n",
        "        legend.append(opt_threshold_jaccard)\n",
        "    if 'hamming' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['hamming']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='green')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='green')\n",
        "        legend.append(\"Hamming Score\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'map' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['map']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='red')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='red')\n",
        "        legend.append(\"mAP Score\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'o_f1' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['o_f1']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='yellow')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='yellow')\n",
        "        legend.append(\"OF1\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'c_f1' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['c_f1']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='orange')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='orange')\n",
        "        legend.append(\"CF1\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'o_precision' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['o_precision']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='purple')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='purple')\n",
        "        legend.append(\"OP\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'c_precision' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['c_precision']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='cyan')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='cyan')\n",
        "        legend.append(\"CP\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'o_recall' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['o_recall']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='brown')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='brown')\n",
        "        legend.append(\"OR\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'c_precision' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['c_precision']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='pink')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='pink')\n",
        "        legend.append(\"CR\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    if 'c_accuracy' in metrics:\n",
        "        mean_hamming_threshold = [np.mean(mt['c_accuracy']) for mt in metrics_thresholds]\n",
        "        opt_threshold_hamming = thresholds[np.argmin(mean_hamming_threshold)]\n",
        "        plt.plot(thresholds, mean_hamming_threshold, c='maroon')\n",
        "        plt.axvline(opt_threshold_hamming, ls=\"--\", c='maroon')\n",
        "        legend.append(\"CACC\")\n",
        "        legend.append(opt_threshold_hamming)\n",
        "    \n",
        "    \n",
        "    \n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend(legend)\n",
        "    plt.title(title_suffix+\" Multi label metrics by threshold\")\n",
        "    plt.show()\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8CNr6I4rU5d"
      },
      "source": [
        "# 5 way 5 shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g73bz0lqrU5e"
      },
      "source": [
        "## Picking indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgvLIs448tVj"
      },
      "source": [
        "img_list = os.listdir(data_folder + split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm6j-e0brU5f"
      },
      "source": [
        "def prepare_indices(num_ways, num_shot, label_dictionary, num_eval= 10):\n",
        "  eval_indices = []\n",
        "  train_indices = []\n",
        "  wi_y = []\n",
        "  eval_y = []\n",
        "  shuffle = False\n",
        "  sort = True\n",
        "  num_episodes = 10\n",
        "  selected_labels_per_episode = []\n",
        "\n",
        "  _label_dictionary = {la:label_dictionary[la] for la in label_dictionary if len(label_dictionary[la]) >= (num_shot+num_eval)}\n",
        "  unique_labels = list(_label_dictionary.keys())\n",
        "\n",
        "  pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "  for s in range(num_episodes):\n",
        "    # Setting random seed for replicability\n",
        "    np.random.seed(s)\n",
        "    #print(s)\n",
        "\n",
        "    _train_indices = []\n",
        "    _eval_indices = []\n",
        "\n",
        "    selected_labels = np.random.choice(unique_labels, size=num_ways, replace=False)\n",
        "    selected_labels_per_episode.append(selected_labels)\n",
        "    for la in selected_labels:\n",
        "        la_indices_train = label_dictionary[la]\n",
        "        la_indices_eval = label_dictionary[la]\n",
        "        tr_idx = []\n",
        "        ev_idx = []\n",
        "        while len(tr_idx) < num_shot:\n",
        "            idx = np.random.choice(la_indices_train)\n",
        "            fname = image_id_col[idx] + '.jpg'\n",
        "            if fname in img_list:\n",
        "              img = mpimg.imread(data_folder + split + '/' + image_id_col[idx] + '.jpg')\n",
        "              if img.ndim!=3:\n",
        "                del img\n",
        "                continue\n",
        "            \n",
        "            if idx not in _train_indices and idx not in _eval_indices and idx not in tr_idx and fname in img_list:\n",
        "                tr_idx.append(idx)\n",
        "        while len(ev_idx) < num_eval:\n",
        "            idx = np.random.choice(la_indices_eval)\n",
        "            fname = image_id_col[idx] + '.jpg'\n",
        "            if fname in img_list:\n",
        "              img = mpimg.imread(data_folder + split + '/' + image_id_col[idx] + '.jpg')\n",
        "              if img.ndim!=3:\n",
        "                del img\n",
        "                continue\n",
        "            if idx not in _train_indices and idx not in _eval_indices and idx not in tr_idx and idx not in ev_idx and fname in img_list:\n",
        "                ev_idx.append(idx)\n",
        "                #print(len(ev_idx))\n",
        "\n",
        "\n",
        "        _train_indices = _train_indices + tr_idx\n",
        "        _eval_indices = _eval_indices + ev_idx\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.shuffle(_train_indices)\n",
        "        np.random.shuffle(_eval_indices)\n",
        "\n",
        "    # if sort:\n",
        "    #   _train_indices.sort()\n",
        "    #   _eval_indices.sort()\n",
        "\n",
        "    train_indices.append(_train_indices)\n",
        "    eval_indices.append(_eval_indices)\n",
        "\n",
        "    _wi_y = []\n",
        "    for idx in _train_indices:\n",
        "        la = train_labels[idx]\n",
        "        _wi_y.append(list([l for l in la if l in selected_labels]))\n",
        "    _eval_y = []\n",
        "    for idx in _eval_indices:\n",
        "        la = train_labels[idx]\n",
        "        _eval_y.append(list([l for l in la if l in selected_labels]))\n",
        "\n",
        "    wi_y.append(_wi_y)\n",
        "    eval_y.append(_eval_y)\n",
        "\n",
        "    pbar.update(s+1)\n",
        "    \n",
        "  return train_indices, eval_indices, wi_y, eval_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLW-8vrbrU5f"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcBzzmWqP20K"
      },
      "source": [
        "num_episodes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd3gA1UyJIIM"
      },
      "source": [
        "###5w5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1G8QjnhQKWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8891e892-5eec-45b4-9f86-de57ace62bb9"
      },
      "source": [
        "num_ways = 5\n",
        "num_shot = 5\n",
        "train_indices, eval_indices, wi_y, eval_y = prepare_indices(num_ways, num_shot, label_dictionary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_Z7sa-EefOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a67a1e-f2fd-4e97-fb5e-6df11daa91be"
      },
      "source": [
        "num_augmentations = 0\n",
        "Trivial = False\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  emb_per_img = []\n",
        "  p = generate_masks(train_indices[i])\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "    del emb\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del emb_per_img\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:02:17] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKsng-NSehPV"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx2phF0DRLrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a24504-4a40-4c05-e0ca-c715c664531a"
      },
      "source": [
        "eval_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  p = generate_masks(eval_indices[i])\n",
        "  emb_per_img = []\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  eval_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del p\n",
        "  del emb\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:06:28] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyVoYUXoFnoR",
        "outputId": "939bfeac-85e7-4c82-f067-7998dfc5129d"
      },
      "source": [
        "eval_emb_per_episode[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 1, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq3hdMrkF2vM"
      },
      "source": [
        "eval_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  eval_emb_reshaped.append(eval_emb_per_episode[i].reshape(eval_emb_per_episode[i].shape[0]*eval_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctUKmm_eJLYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df35267-fa6d-4446-c240-0ad50a31cf87"
      },
      "source": [
        "train_epochs_loop = []\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:48] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4UbuCjDlrgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cdb817f-ea00-4fc3-c629-54a61f32c4c3"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsIMaterialist_0t_Patch_Patch_5w5s0a_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Uploaded new_metricsIMaterialist_0t_Patch_Patch_5w5s0a_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92sVaqMGQDF"
      },
      "source": [
        "###5w1s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4JvlzoVGQDF",
        "outputId": "fd02c015-0040-47f7-ad87-15c241c674ce"
      },
      "source": [
        "num_ways = 5\n",
        "num_shot = 1\n",
        "train_indices, eval_indices, wi_y, eval_y = prepare_indices(num_ways, num_shot, label_dictionary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRoyGSnHGQDG",
        "outputId": "379c41ef-0194-49d9-c44c-f110d2b095f2"
      },
      "source": [
        "num_augmentations = 10\n",
        "Trivial = True\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  emb_per_img = []\n",
        "  p = generate_masks(train_indices[i])\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "    del emb\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del emb_per_img\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:03:04] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2r0ONhjGQDG"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szJTVUulGQDG",
        "outputId": "d23406e1-8193-4865-e774-d3a010651707"
      },
      "source": [
        "eval_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  p = generate_masks(eval_indices[i])\n",
        "  emb_per_img = []\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, 0, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  eval_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del p\n",
        "  del emb\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:09:20] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_SgQ88VGQDH"
      },
      "source": [
        "eval_emb_per_episode[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8kKANhYGQDH"
      },
      "source": [
        "eval_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  eval_emb_reshaped.append(eval_emb_per_episode[i].reshape(eval_emb_per_episode[i].shape[0]*eval_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyO4FX2VGQDH",
        "outputId": "549b4e36-9739-40d9-ad73-27b56b9b0d5f"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:23:04] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I17RYsVaGQDI",
        "outputId": "0200bdae-83c3-4ea5-cd87-febe3dc5554d"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded new_metricsIMaterialist_Patch_Patch_5w1s10a_trivial_metrics_with_logits.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n",
            "Uploaded new_metricsIMaterialist_Patch_Patch_5w1s10a_trivial_metrics_graphs.json to https://drive.google.com/drive/u/1/folders/1RbtNKWRThbY6ArnqsYCYp2EFi13kP7dN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-6RbWonGQX8"
      },
      "source": [
        "###20w5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6RNNTbaGQX8"
      },
      "source": [
        "num_ways = 20\n",
        "num_shot = 5\n",
        "train_indices, eval_indices, wi_y, eval_y = prepare_indices(num_ways, num_shot, label_dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZGCGvuIGQX9"
      },
      "source": [
        "num_augmentations = 10\n",
        "Trivial = True\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  emb_per_img = []\n",
        "  p = generate_masks(train_indices[i])\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "    del emb\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del emb_per_img\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2DkbCyjGQX9"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv1CAsckGQX9"
      },
      "source": [
        "eval_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  p = generate_masks(eval_indices[i])\n",
        "  emb_per_img = []\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  eval_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del p\n",
        "  del emb\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ell2wzoZGQX9"
      },
      "source": [
        "eval_emb_per_episode[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxBgtdKXGQX-"
      },
      "source": [
        "eval_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  eval_emb_reshaped.append(eval_emb_per_episode[i].reshape(eval_emb_per_episode[i].shape[0]*eval_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj3gfD5CGQX-"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acCM4KT1GQX-"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAq6qWOtGQpM"
      },
      "source": [
        "###20w1s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alp6xdh4GQpM"
      },
      "source": [
        "num_ways = 20\n",
        "num_shot = 1\n",
        "train_indices, eval_indices, wi_y, eval_y = prepare_indices(num_ways, num_shot, label_dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5e8EhdZGQpN"
      },
      "source": [
        "num_augmentations = 10\n",
        "Trivial = True\n",
        "train_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  emb_per_img = []\n",
        "  p = generate_masks(train_indices[i])\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "    del emb\n",
        "  train_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del emb_per_img\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPAkhLYVGQpN"
      },
      "source": [
        "train_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  train_emb_reshaped.append(train_emb_per_episode[i].reshape(train_emb_per_episode[i].shape[0]*train_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3kTA9RoGQpN"
      },
      "source": [
        "eval_emb_per_episode = []\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "for i in range(num_episodes):\n",
        "  p = generate_masks(eval_indices[i])\n",
        "  emb_per_img = []\n",
        "  for j in p:\n",
        "    emb = embed_augmented_imgs(j, num_augmentations, trivial=Trivial)\n",
        "    emb_per_img.append(emb)\n",
        "  eval_emb_per_episode.append(np.array(emb_per_img))\n",
        "  del p\n",
        "  del emb\n",
        "  pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPaz2Hu2GQpN"
      },
      "source": [
        "eval_emb_per_episode[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD2lGRiMGQpO"
      },
      "source": [
        "eval_emb_reshaped = []\n",
        "for i in range(num_episodes):\n",
        "  eval_emb_reshaped.append(eval_emb_per_episode[i].reshape(eval_emb_per_episode[i].shape[0]*eval_emb_per_episode[i].shape[1], 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glh9Pjo4GQpO"
      },
      "source": [
        "train_epochs_loop = [5 for _ in range(16)]\n",
        "logits_thresholds = []    #cc\n",
        "clip_metrics_thresholds = []\n",
        "\n",
        "pbar = start_progress_bar(len(thresholds))\n",
        "for i, t in enumerate(thresholds):\n",
        "    clip_metrics_t,all_logits = run_train_loop(#cc\n",
        "        train_indices,\n",
        "        eval_indices,\n",
        "        wi_y,\n",
        "        eval_y,\n",
        "        num_episodes,\n",
        "        num_ways,\n",
        "        threshold=t,\n",
        "        verbose=False,\n",
        "        train_epochs_loop=train_epochs_loop\n",
        "    )\n",
        "    clip_metrics_thresholds.append(clip_metrics_t)\n",
        "    logits_thresholds.append(all_logits)#cc\n",
        "    pbar.update(i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCWcdhEAGQpO"
      },
      "source": [
        "save_results(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)\n",
        "save_trends(num_ways, num_shot, num_augmentations, Trivial, clip_metrics_thresholds, logits_thresholds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7U304nlUduX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}