{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SaveEmbeddings_IndoorSceneRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RGlVnbugxFK2",
        "3rKe3HqM523g",
        "OLU-gp7n8__E",
        "NzsubsEm72rr",
        "2Sdn6HMixMH9",
        "Exp4Y7jLGyp7",
        "KC66qPddG2gG",
        "yCn3CW3w_G3W",
        "-k7FFrtU_GgO",
        "Dy41hBsj_Hbr",
        "MpvNJt3T_ymv",
        "hpwXmr3i_yXt",
        "tlkRqm7vgAnP",
        "GLR8Zid5gAnT",
        "xXH_D1PjgAnU",
        "dPTf0dZWgAnV",
        "BvB5aemdgAnW",
        "JgFEIwtngAnX",
        "pgQGc62agAnY",
        "a68tj7FRgAnZ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0087f872d9643129dfc03b75f5837cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb04fd95a318492aaa7a4c267cd19f0b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d638733be1ac4629bf0b44412a508432",
              "IPY_MODEL_af01374e592b440a959f86e544634e35"
            ]
          }
        },
        "fb04fd95a318492aaa7a4c267cd19f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d638733be1ac4629bf0b44412a508432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b1826fb0d91a4f41b57d9ff3ab4eef42",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_626797cc8ec34f6a99f8cb29aea4ff6c"
          }
        },
        "af01374e592b440a959f86e544634e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0147df41ccce46518e43d66e913750fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [06:31&lt;00:00, 262kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a19be8dd71d848aeb50307be3d9bfad4"
          }
        },
        "b1826fb0d91a4f41b57d9ff3ab4eef42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "626797cc8ec34f6a99f8cb29aea4ff6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0147df41ccce46518e43d66e913750fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a19be8dd71d848aeb50307be3d9bfad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTY7kA7DOzpV"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-7JU3Q7q_XT",
        "outputId": "3f001744-30f1-421a-b822-ca96a265b354"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqqXI7Izk65p",
        "outputId": "5e3659f1-eba6-4377-9828-54df8db5a139"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Cloning PAL_2021 to access modules.\n",
        "# Need password to access private repo.\n",
        "\n",
        "if 'CLIPPER' not in os.listdir():\n",
        "    cmd_string = 'git clone https://github.com/PAL-ML/CLIPPER.git'\n",
        "    os.system(cmd_string)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: httplib2==0.15.0 in /usr/local/lib/python3.7/dist-packages (0.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlVnbugxFK2"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmgIrfT8hDNE"
      },
      "source": [
        "## Install multi label metrics dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6xXPAFbe6Gp",
        "outputId": "65f5040a-950e-43aa-cee9-0e8443bb6908"
      },
      "source": [
        "! pip install scikit-learn==0.24"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.24\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/ed/ab51a8da34d2b3f4524b21093081e7f9e2ddf1c9eac9f795dcf68ad0a57d/scikit_learn-0.24.0-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.4.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.0 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKe3HqM523g"
      },
      "source": [
        "## Install CLIP dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poS-WNDixIhY",
        "outputId": "4c046923-210f-482d-8ea6-4ba6cf9c2adb"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA version: 11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA-69W8M59nA",
        "outputId": "f69e3b27-19aa-4c6f-962e-4edc5dc17f58"
      },
      "source": [
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8MB)\n",
            "\u001b[K     |███████████████████████         | 834.1MB 1.3MB/s eta 0:04:03tcmalloc: large alloc 1147494400 bytes == 0x55fe930ec000 @  0x7f48cc959615 0x55fe594c6cdc 0x55fe595a652a 0x55fe594c9afd 0x55fe595bafed 0x55fe5953d988 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953d7f0 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953a32a 0x55fe595bbe36 0x55fe59539853 0x55fe595bbe36 0x55fe59539853 0x55fe595bbe36 0x55fe59539853 0x55fe595bbe36 0x55fe5963e3e1 0x55fe5959e6a9 0x55fe59509cc4 0x55fe594ca559 0x55fe5953e4f8 0x55fe594cb30a 0x55fe595393b5 0x55fe595387ad 0x55fe594cb3ea 0x55fe595393b5 0x55fe594cb30a 0x55fe595393b5\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7MB 1.2MB/s eta 0:01:26tcmalloc: large alloc 1434370048 bytes == 0x55fed7742000 @  0x7f48cc959615 0x55fe594c6cdc 0x55fe595a652a 0x55fe594c9afd 0x55fe595bafed 0x55fe5953d988 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953d7f0 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953a32a 0x55fe595bbe36 0x55fe59539853 0x55fe595bbe36 0x55fe59539853 0x55fe595bbe36 0x55fe59539853 0x55fe595bbe36 0x55fe5963e3e1 0x55fe5959e6a9 0x55fe59509cc4 0x55fe594ca559 0x55fe5953e4f8 0x55fe594cb30a 0x55fe595393b5 0x55fe595387ad 0x55fe594cb3ea 0x55fe595393b5 0x55fe594cb30a 0x55fe595393b5\n",
            "\u001b[K     |████████████████████████████████| 1156.7MB 1.2MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55ff2cf2e000 @  0x7f48cc959615 0x55fe594c6cdc 0x55fe595a652a 0x55fe594c9afd 0x55fe595bafed 0x55fe5953d988 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953960e 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953960e 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953960e 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953960e 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953960e 0x55fe594cb30a 0x55fe5953960e 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953a32a 0x55fe595384ae 0x55fe594cb3ea 0x55fe5953a32a 0x55fe595384ae 0x55fe594cba81\n",
            "\u001b[K     |████████████████████████████████| 1156.8MB 16kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 233kB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/da/d215a091986e5f01b80f5145cff6f22e2dc57c6b048aab2e882a07018473/ftfy-6.0.3.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-cp37-none-any.whl size=41916 sha256=1f6fede565ec28dca58472088b2b4e4cf8b66ccab75e3c2ba224468225eba186\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/2c/e6/109c8a28fef7a443f67ba58df21fe1d0067ac3322e75e6b0b7\n",
            "Successfully built ftfy\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision, ftfy\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed ftfy-6.0.3 torch-1.7.1+cu110 torchvision-0.8.2+cu110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYwBZS1N6A3d",
        "outputId": "e06eb1bf-c9ab-46d6-bbf1-61425d49e56a"
      },
      "source": [
        "! pip install ftfy regex\n",
        "! wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "--2021-06-01 19:25:38--  https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.69, 13.107.213.69, 2620:1ec:bdf::69, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘bpe_simple_vocab_16e6.txt.gz’\n",
            "\n",
            "bpe_simple_vocab_16 100%[===================>]   1.29M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-06-01 19:25:38 (24.4 MB/s) - ‘bpe_simple_vocab_16e6.txt.gz’ saved [1356917/1356917]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oIcNBYB8lz3",
        "outputId": "2bea3cf8-84a1-4032-d70f-7cd06111db1d"
      },
      "source": [
        "!pip install git+https://github.com/Sri-vatsa/CLIP # using this fork because of visualization capabilities"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Sri-vatsa/CLIP\n",
            "  Cloning https://github.com/Sri-vatsa/CLIP to /tmp/pip-req-build-4vygj1qf\n",
            "  Running command git clone -q https://github.com/Sri-vatsa/CLIP /tmp/pip-req-build-4vygj1qf\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Requirement already satisfied: torch~=1.7.1 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision~=0.8.2 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.8.2+cu110)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368623 sha256=9387a71e174a57d732566c2640daf9a3376343e29397b216ce878a25e47d0ecf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-osrjfoax/wheels/cc/55/69/0d411dabbd5009fd069d47b47cf7839c54e595dc61725b307b\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-gp7n8__E"
      },
      "source": [
        "## Install clustering dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLg9ozo9Hvc"
      },
      "source": [
        "!pip -q install umap-learn>=0.3.7"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1WQnXdLHy2"
      },
      "source": [
        "## Install dataset manager dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1vvMx7_LLSp",
        "outputId": "00c5fe7a-3b9a-46d8-a7a3-f4ab3e277f69"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=b52a8fbacc283d39e5278f9735da209a2aea189e5177d76135d74b53b23c3a9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzsubsEm72rr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZI62a6G74kw"
      },
      "source": [
        "# ML Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# Data processing\n",
        "import PIL\n",
        "import base64\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from matplotlib import cm\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Models\n",
        "import clip\n",
        "\n",
        "# Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Clustering\n",
        "# import umap\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "#from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Misc\n",
        "import progressbar\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.metrics import jaccard_score, hamming_loss, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "# Modules\n",
        "from CLIPPER.code.ExperimentModules import embedding_models\n",
        "from CLIPPER.code.ExperimentModules.dataset_manager import DatasetManager\n",
        "from CLIPPER.code.ExperimentModules.weight_imprinting_classifier import WeightImprintingClassifier\n",
        "from CLIPPER.code.ExperimentModules import simclr_data_augmentations\n",
        "from CLIPPER.code.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)\n",
        "\n",
        "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_gxQ0KbwMh"
      },
      "source": [
        "# Initialization & Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND-Q6dDoYmDu"
      },
      "source": [
        "## Dataset details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bih5tBPdbx3u"
      },
      "source": [
        "IMG_HEIGHT = 112\n",
        "IMG_WIDTH = 112\n",
        "\n",
        "experiment_id = \"IndoorSceneRecognition-Embeddings\"\n",
        "\n",
        "folder_name = experiment_id+\"-28-02-21\"\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1bK72W-Um20EQDEyChNhNJthUNbmoSEjD'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBOFLDPL0RNK",
        "outputId": "b5ceb2a8-a389-4e67-c0fc-089549db6445"
      },
      "source": [
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = create_expt_dir(drive, parentid, folder_name)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: IndoorSceneRecognition-Embeddings-28-02-21, id: 1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "Experiment folder already exists. WARNING: Following with this run might overwrite existing results stored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JCHA5Q8eiOo"
      },
      "source": [
        "# Embedding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYmYbX2D8Mux"
      },
      "source": [
        "def run_data_through_model(\n",
        "    data, \n",
        "    embedder, \n",
        "    filename, \n",
        "    drive,\n",
        "    folderid,\n",
        "    total_num_images,\n",
        "    max_num_samples=5000,\n",
        "):\n",
        "    embedder.load_model()\n",
        "\n",
        "    embeddings = None\n",
        "    num_images_done = 0\n",
        "\n",
        "    while embeddings is None or num_images_done < total_num_images:\n",
        "        download_file_by_name(drive, folderid, filename)\n",
        "\n",
        "        if filename in os.listdir():\n",
        "            embeddings = np.load(filename)['data']\n",
        "            num_images_done = embeddings.shape[0]\n",
        "            if num_images_done == total_num_images:\n",
        "                print(\"All images done already.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"{}/{} images done already\".format(\n",
        "                    num_images_done, total_num_images)\n",
        "                )\n",
        "\n",
        "        print(\"Running for image indices {}-{}.\".format(\n",
        "            num_images_done, num_images_done+max_num_samples\n",
        "            )\n",
        "        )\n",
        "        if (num_images_done+max_num_samples) <= total_num_images:\n",
        "            batch = data[num_images_done:num_images_done+max_num_samples]\n",
        "        else:\n",
        "            batch = data[num_images_done:]\n",
        "\n",
        "        processed_batch = embedder.preprocess_data(batch)\n",
        "        embeddings_batch = embedder.embed_images(\n",
        "            processed_batch, batch_size=50\n",
        "            )\n",
        "        \n",
        "        if embeddings is None:\n",
        "            embeddings = embeddings_batch\n",
        "        else:\n",
        "            embeddings = np.concatenate(\n",
        "                [embeddings, embeddings_batch]\n",
        "                )\n",
        "            \n",
        "        delete_file_by_name(drive, folderid, filename)\n",
        "        embedder.save_embeddings_to_drive(\n",
        "            embeddings, \n",
        "            filename,\n",
        "            drive,\n",
        "            folderid\n",
        "            )\n",
        "        num_images_done = embeddings.shape[0]\n",
        "        print(\"{}/{} images done\".format(num_images_done, total_num_images))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l7FJ-0PfFSp"
      },
      "source": [
        "# Train data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sdn6HMixMH9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcP9Ir-IxQoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a70098b-f6ed-4227-9ad0-dc16b761d290"
      },
      "source": [
        "dm = DatasetManager()\n",
        "train_data_generator = dm.load_dataset('indoor_scene_recognition', split=\"train\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 15620 files belonging to 67 classes.\n",
            "Using 12496 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhahWSBBXvqz",
        "outputId": "ce6b7e9f-824f-439a-cbc7-bf1a22363b4d"
      },
      "source": [
        "_data = []\n",
        "_labels = []\n",
        "\n",
        "data_gen = iter(train_data_generator)\n",
        "\n",
        "while True:\n",
        "  try:\n",
        "    image, label = next(data_gen)\n",
        "    resized_image = cv2.resize(image[0], (IMG_WIDTH, IMG_HEIGHT)).astype(np.uint8)\n",
        "    _data.append(resized_image)\n",
        "    _labels.append(label[0])\n",
        "  except StopIteration:\n",
        "    break\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "train_data = np.stack(_data)\n",
        "train_labels = np.array(_labels)\n",
        "\n",
        "del _data\n",
        "del _labels\n",
        "\n",
        "print('Images shape: ', train_data.shape)\n",
        "print('Labels length: ', len(train_labels))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images shape:  (9198, 112, 112, 3)\n",
            "Labels length:  9198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvoopWgYgQQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2e1d26-c47d-4535-f72f-1b2b082e7320"
      },
      "source": [
        "# Save train labels\n",
        "train_labels_filename = 'train_labels.npz'\n",
        "\n",
        "if train_labels_filename not in os.listdir():\n",
        "    save_npy(train_labels_filename, train_labels)\n",
        "    save_to_drive(drive, folderid, train_labels_filename)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data saved to train_labels.npz\n",
            "Uploaded train_labels.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOZL8Rz_e-Rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8635f6c-2371-4195-8c67-8646ca1d4ea6"
      },
      "source": [
        "total_train_images = len(train_data)\n",
        "total_train_images"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exp4Y7jLGyp7"
      },
      "source": [
        "## Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NSK-prS5Q_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94598ed-a9c2-43c5-e0ce-39652441758c"
      },
      "source": [
        "max_num_samples = 4000 # Colab crashes with too many images\n",
        "inceptionv3_train_filename = 'inceptionv3_embeddings_train.npz'\n",
        "\n",
        "inceptionv3_train_embedder = embedding_models.InceptionV3EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    inceptionv3_train_embedder, \n",
        "    inceptionv3_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Running for image indices 0-4000.\n",
            "Data saved to x_inceptionv3_embeddings_train.npz\n",
            "Uploaded x_inceptionv3_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "4000/9198 images done\n",
            "Downloading x_inceptionv3_embeddings_train.npz from GDrive\n",
            "4000/9198 images done already\n",
            "Running for image indices 4000-8000.\n",
            "Deleting x_inceptionv3_embeddings_train.npz from GDrive\n",
            "Data saved to x_inceptionv3_embeddings_train.npz\n",
            "Uploaded x_inceptionv3_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "8000/9198 images done\n",
            "Downloading x_inceptionv3_embeddings_train.npz from GDrive\n",
            "8000/9198 images done already\n",
            "Running for image indices 8000-12000.\n",
            "Deleting x_inceptionv3_embeddings_train.npz from GDrive\n",
            "Data saved to x_inceptionv3_embeddings_train.npz\n",
            "Uploaded x_inceptionv3_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "9198/9198 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC66qPddG2gG"
      },
      "source": [
        "## Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svIjGLD8BS_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647,
          "referenced_widgets": [
            "f0087f872d9643129dfc03b75f5837cd",
            "fb04fd95a318492aaa7a4c267cd19f0b",
            "d638733be1ac4629bf0b44412a508432",
            "af01374e592b440a959f86e544634e35",
            "b1826fb0d91a4f41b57d9ff3ab4eef42",
            "626797cc8ec34f6a99f8cb29aea4ff6c",
            "0147df41ccce46518e43d66e913750fd",
            "a19be8dd71d848aeb50307be3d9bfad4"
          ]
        },
        "outputId": "ed921bc4-f3b2-4608-8c2b-597bd6041d9e"
      },
      "source": [
        "max_num_samples = 2000\n",
        "resnet50_train_filename = 'resnet50_embeddings_train.npz'\n",
        "\n",
        "resnet50_train_embedder = embedding_models.Resnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    resnet50_train_embedder, \n",
        "    resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0087f872d9643129dfc03b75f5837cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running for image indices 0-2000.\n",
            "Data saved to x_resnet50_embeddings_train.npz\n",
            "Uploaded x_resnet50_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "2000/9198 images done\n",
            "Downloading x_resnet50_embeddings_train.npz from GDrive\n",
            "2000/9198 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Deleting x_resnet50_embeddings_train.npz from GDrive\n",
            "Data saved to x_resnet50_embeddings_train.npz\n",
            "Uploaded x_resnet50_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "4000/9198 images done\n",
            "Downloading x_resnet50_embeddings_train.npz from GDrive\n",
            "4000/9198 images done already\n",
            "Running for image indices 4000-6000.\n",
            "Deleting x_resnet50_embeddings_train.npz from GDrive\n",
            "Data saved to x_resnet50_embeddings_train.npz\n",
            "Uploaded x_resnet50_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "6000/9198 images done\n",
            "Downloading x_resnet50_embeddings_train.npz from GDrive\n",
            "6000/9198 images done already\n",
            "Running for image indices 6000-8000.\n",
            "Deleting x_resnet50_embeddings_train.npz from GDrive\n",
            "Data saved to x_resnet50_embeddings_train.npz\n",
            "Uploaded x_resnet50_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "8000/9198 images done\n",
            "Downloading x_resnet50_embeddings_train.npz from GDrive\n",
            "8000/9198 images done already\n",
            "Running for image indices 8000-10000.\n",
            "Deleting x_resnet50_embeddings_train.npz from GDrive\n",
            "Data saved to x_resnet50_embeddings_train.npz\n",
            "Uploaded x_resnet50_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "9198/9198 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCn3CW3w_G3W"
      },
      "source": [
        "## MoCo Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmQeAyek_G3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f4b1f3-799c-4504-fc95-52a713779846"
      },
      "source": [
        "max_num_samples = 2000\n",
        "moco_resnet50_train_filename = 'moco_resnet50_embeddings_train.npz'\n",
        "\n",
        "moco_resnet50_train_embedder = embedding_models.MoCoResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    moco_resnet50_train_embedder, \n",
        "    moco_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading x_moco_resnet50_embeddings_train.npz from GDrive\n",
            "6000/9198 images done already\n",
            "Running for image indices 6000-8000.\n",
            "Deleting x_moco_resnet50_embeddings_train.npz from GDrive\n",
            "Data saved to x_moco_resnet50_embeddings_train.npz\n",
            "Uploaded x_moco_resnet50_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "8000/9198 images done\n",
            "Downloading x_moco_resnet50_embeddings_train.npz from GDrive\n",
            "8000/9198 images done already\n",
            "Running for image indices 8000-10000.\n",
            "Deleting x_moco_resnet50_embeddings_train.npz from GDrive\n",
            "Data saved to x_moco_resnet50_embeddings_train.npz\n",
            "Uploaded x_moco_resnet50_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "9198/9198 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k7FFrtU_GgO"
      },
      "source": [
        "## PCL Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FppJPYz1_GgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a2b42a3-7c66-49f4-9946-e28f8a307b2d"
      },
      "source": [
        "max_num_samples = 2000\n",
        "pcl_resnet50_train_filename = 'pcl_resnet50_embeddings_train.npz'\n",
        "\n",
        "pcl_resnet50_train_embedder = embedding_models.PCLResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    pcl_resnet50_train_embedder, \n",
        "    pcl_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pcl_resnet50_embeddings_train.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy41hBsj_Hbr"
      },
      "source": [
        "## SwAV Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ncOHlr_Hb2"
      },
      "source": [
        "max_num_samples = 2000\n",
        "swav_resnet50_train_filename = 'swav_resnet50_embeddings_train.npz'\n",
        "\n",
        "swav_resnet50_train_embedder = embedding_models.SwAVResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    swav_resnet50_train_embedder, \n",
        "    swav_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpvNJt3T_ymv"
      },
      "source": [
        "## SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkMkP19T_ymx"
      },
      "source": [
        "max_num_samples = 3000\n",
        "simclr_train_filename = 'simclr_embeddings_train.npz'\n",
        "\n",
        "simclr_train_embedder = embedding_models.SimCLREmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    simclr_train_embedder, \n",
        "    simclr_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpwXmr3i_yXt"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdVItqYB_yX0"
      },
      "source": [
        "max_num_samples = 3000\n",
        "vgg16_train_filename = 'vgg16_embeddings_train.npz'\n",
        "\n",
        "vgg16_train_embedder = embedding_models.VGG16EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    vgg16_train_embedder, \n",
        "    vgg16_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeOqwRRnAPQm"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7NTLqP8APQu"
      },
      "source": [
        "max_num_samples = 3000\n",
        "clip_train_filename = 'clip_embeddings_train.npz'\n",
        "\n",
        "clip_train_embedder = embedding_models.CLIPEmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    clip_train_embedder, \n",
        "    clip_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWQiLtKkgAnM"
      },
      "source": [
        "# Val data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlkRqm7vgAnP"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVi22lKIgAnQ",
        "outputId": "ef71db8e-6441-47db-9f1a-27da94480b61"
      },
      "source": [
        "dm = DatasetManager()\n",
        "val_data_generator = dm.load_dataset('indoor_scene_recognition', split=\"val\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1340 files belonging to 67 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSGYDCfFgAnR",
        "outputId": "bf270d5c-a997-42a1-97fe-b4a6f9aa0d8d"
      },
      "source": [
        "_data = []\n",
        "_labels = []\n",
        "\n",
        "data_gen = iter(val_data_generator)\n",
        "\n",
        "while True:\n",
        "  try:\n",
        "    image, label = next(data_gen)\n",
        "    resized_image = cv2.resize(image[0], (IMG_WIDTH, IMG_HEIGHT)).astype(np.uint8)\n",
        "    _data.append(resized_image)\n",
        "    _labels.append(label[0])\n",
        "  except StopIteration:\n",
        "    break\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "#for i, (image, label) in enumerate(val_data_generator):\n",
        "#    resized_image = cv2.resize(image[0], (IMG_WIDTH, IMG_HEIGHT)).astype(np.uint8)\n",
        "#    _data.append(resized_image)\n",
        "#    _labels.append(label[0])\n",
        "\n",
        "val_data = np.stack(_data)\n",
        "val_labels = np.array(_labels)\n",
        "\n",
        "del _data\n",
        "del _labels\n",
        "\n",
        "print('Images shape: ', val_data.shape)\n",
        "print('Labels length: ', len(val_labels))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images shape:  (1340, 112, 112, 3)\n",
            "Labels length:  1340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLWti1ucgX1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782a10b2-5be8-4603-ee36-128f78c453fb"
      },
      "source": [
        "# Save val labels\n",
        "val_labels_filename = 'val_labels.npz'\n",
        "\n",
        "if val_labels_filename not in os.listdir():\n",
        "    save_npy(val_labels_filename, val_labels)\n",
        "    save_to_drive(drive, folderid, val_labels_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data saved to val_labels.npz\n",
            "Uploaded val_labels.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOacFeKBgAnT",
        "outputId": "a7814fa7-7c89-4830-8392-5f694c921c80"
      },
      "source": [
        "total_val_images = len(val_data)\n",
        "total_val_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1340"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLR8Zid5gAnT"
      },
      "source": [
        "## Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdiSPRXBgAnU",
        "outputId": "156aed16-82d0-46ca-a773-a8a070c39c43"
      },
      "source": [
        "max_num_samples = 4000 # Colab crashes with too many images\n",
        "inceptionv3_val_filename = 'inceptionv3_embeddings_val.npz'\n",
        "\n",
        "inceptionv3_val_embedder = embedding_models.InceptionV3EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    inceptionv3_val_embedder, \n",
        "    inceptionv3_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading inceptionv3_embeddings_val.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXH_D1PjgAnU"
      },
      "source": [
        "## Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnjwn5jugAnV",
        "outputId": "49d867e5-0890-4b0d-f01f-5fd3f3ccfdd8"
      },
      "source": [
        "max_num_samples = 2000\n",
        "resnet50_val_filename = 'resnet50_embeddings_val.npz'\n",
        "\n",
        "resnet50_val_embedder = embedding_models.Resnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    resnet50_val_embedder, \n",
        "    resnet50_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading resnet50_embeddings_val.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPTf0dZWgAnV"
      },
      "source": [
        "## MoCo Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8MmypOCgAnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a5517cc-b8fb-47b9-c4d6-fd31de7d983f"
      },
      "source": [
        "max_num_samples = 2000\n",
        "moco_resnet50_val_filename = 'moco_resnet50_embeddings_val.npz'\n",
        "\n",
        "moco_resnet50_val_embedder = embedding_models.MoCoResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    moco_resnet50_val_embedder, \n",
        "    moco_resnet50_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading moco_resnet50_embeddings_val.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvB5aemdgAnW"
      },
      "source": [
        "## PCL Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ3C8NPMgAnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f4c8e0-d2af-47c9-d85e-2174b4d03a93"
      },
      "source": [
        "max_num_samples = 2000\n",
        "pcl_resnet50_val_filename = 'pcl_resnet50_embeddings_val.npz'\n",
        "\n",
        "pcl_resnet50_val_embedder = embedding_models.PCLResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    pcl_resnet50_val_embedder, \n",
        "    pcl_resnet50_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pcl_resnet50_embeddings_val.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgFEIwtngAnX"
      },
      "source": [
        "## SwAV Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGNGhKd8gAnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f0ea9b-2ee0-4159-8ea9-28bfcf5a1efd"
      },
      "source": [
        "max_num_samples = 3000\n",
        "swav_resnet50_val_filename = 'swav_resnet50_embeddings_val.npz'\n",
        "\n",
        "swav_resnet50_val_embedder = embedding_models.SwAVResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    swav_resnet50_val_embedder, \n",
        "    swav_resnet50_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_swav_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading swav_resnet50_embeddings_val.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgQGc62agAnY"
      },
      "source": [
        "## SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX48gy4DgAnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7677bd50-ed3e-4e59-92d1-e678703e3691"
      },
      "source": [
        "max_num_samples = 3000\n",
        "simclr_val_filename = 'simclr_embeddings_val.npz'\n",
        "\n",
        "simclr_val_embedder = embedding_models.SimCLREmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    simclr_val_embedder, \n",
        "    simclr_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_16240) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_23562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_22288) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_30442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_30802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_35122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_22072) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_35242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_33322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_29962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_15808) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_33922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_32122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_21640) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_34762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_29842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_33802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_23944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_20560) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_19912) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_32242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_30202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_35602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_34282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_19480) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_14080) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_35962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_29512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_29728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_22720) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_16888) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_33202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_34882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_12784) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_32482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_35002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_17536) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_15160) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_21208) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_33082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_23152) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_12124) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_20776) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_19696) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_34642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_16024) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_17104) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_30682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_30082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_31162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_32962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_13432) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_14512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_29403) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_21856) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_34402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_32002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_18400) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_13000) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_12352) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_23756) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_20992) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_16456) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_34522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_33562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_14944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_33682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_18616) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_31762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_30562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_35482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_14728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_30322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_31282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_15376) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_31882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_16672) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_29621) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_22504) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_18832) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_33442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_31642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_14296) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_32602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_13216) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_15592) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_32842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_18184) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_32362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_35362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_20344) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_32722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_35842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_35722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_12568) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_13864) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_23368) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_17968) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_19264) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_17752) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_13648) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_31042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_31522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_30922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_20128) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_34162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_21424) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_31402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_17320) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_34042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_19048) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_22936) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading simclr_embeddings_val.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a68tj7FRgAnZ"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kStKRyuHgAnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e78d2ab4-23d0-4ce1-fb78-21c0eae3bbdd"
      },
      "source": [
        "max_num_samples = 3000\n",
        "vgg16_val_filename = 'vgg16_embeddings_val.npz'\n",
        "\n",
        "vgg16_val_embedder = embedding_models.VGG16EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    vgg16_val_embedder, \n",
        "    vgg16_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading vgg16_embeddings_val.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t100n-LNgAnZ"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW2Ll3eegAna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ff87c3-5519-4894-dd8b-889c59db7377"
      },
      "source": [
        "max_num_samples = 100\n",
        "clip_val_filename = 'clip_embeddings_val.npz'\n",
        "\n",
        "clip_val_embedder = embedding_models.CLIPEmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    clip_val_embedder, \n",
        "    clip_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-2000.\n",
            "Data saved to clip_embeddings_val.npz\n",
            "Uploaded clip_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1byZ1iLbfdF3Hr6EZNsTubgMys9IDy8gZ\n",
            "1340/1340 images done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}