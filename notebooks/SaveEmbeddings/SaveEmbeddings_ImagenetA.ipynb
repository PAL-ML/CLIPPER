{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SaveEmbeddings_ImagenetA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RGlVnbugxFK2",
        "3rKe3HqM523g",
        "OLU-gp7n8__E",
        "KC66qPddG2gG",
        "yCn3CW3w_G3W",
        "Dy41hBsj_Hbr",
        "MpvNJt3T_ymv",
        "hpwXmr3i_yXt",
        "CeOqwRRnAPQm"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "beb77b6bb3144c96b9a2cec1fb9c7d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78eccdb74d604fcd9a5f6f7a78fb7b20",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2169934814d5441eaa52f9b4313eb756",
              "IPY_MODEL_3c9d2f0a2e794fc892923fa89e13d0c3"
            ]
          }
        },
        "78eccdb74d604fcd9a5f6f7a78fb7b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2169934814d5441eaa52f9b4313eb756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a57dacaf3b04a958210b8cc217d37c5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb3c0c30171c4b54a1061461256c3aad"
          }
        },
        "3c9d2f0a2e794fc892923fa89e13d0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f31113d5ad14eb5a7da774f006462ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [18:36&lt;00:00, 91.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b44fb372289c4449a100178cfde442c2"
          }
        },
        "1a57dacaf3b04a958210b8cc217d37c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb3c0c30171c4b54a1061461256c3aad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f31113d5ad14eb5a7da774f006462ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b44fb372289c4449a100178cfde442c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d94cb72fced34c2487f9e5736c58a269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_06e85f3541b54b489603e89fca8cc213",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_21dbb5f1bfba41029676fa9ee577fb8a",
              "IPY_MODEL_36588743da6441dc97c49bfa25fd9e38"
            ]
          }
        },
        "06e85f3541b54b489603e89fca8cc213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21dbb5f1bfba41029676fa9ee577fb8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc115a32683a48569440bbf17e44eb34",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 113703565,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 113703565,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba36a096f07e47af9bccd4b8df9a6a0d"
          }
        },
        "36588743da6441dc97c49bfa25fd9e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d7531c38f5d044be8c8afe02954b508b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 108M/108M [00:30&lt;00:00, 3.77MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4f02c12e9a24bafb8e8489c74f9f988"
          }
        },
        "cc115a32683a48569440bbf17e44eb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba36a096f07e47af9bccd4b8df9a6a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7531c38f5d044be8c8afe02954b508b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4f02c12e9a24bafb8e8489c74f9f988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTY7kA7DOzpV"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-7JU3Q7q_XT",
        "outputId": "60bb4e31-b049-4589-d567-afba5f8e6438"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqqXI7Izk65p",
        "outputId": "fe2d68ec-e08e-4ca5-d631-2bce26a01dfe"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Cloning PAL_2021 to access modules.\n",
        "# Need password to access private repo.\n",
        "\n",
        "if 'CLIPPER' not in os.listdir():\n",
        "    cmd_string = 'git clone https://github.com/PAL-ML/CLIPPER.git'\n",
        "    os.system(cmd_string)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: httplib2==0.15.0 in /usr/local/lib/python3.7/dist-packages (0.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlVnbugxFK2"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmgIrfT8hDNE"
      },
      "source": [
        "## Install multi label metrics dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6xXPAFbe6Gp",
        "outputId": "b4081709-9ed1-40d4-cd73-b2ea5c0156d9"
      },
      "source": [
        "! pip install scikit-learn==0.24"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==0.24 in /usr/local/lib/python3.7/dist-packages (0.24.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKe3HqM523g"
      },
      "source": [
        "## Install CLIP dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poS-WNDixIhY",
        "outputId": "bf9db403-b781-4fcd-8b8e-de771d8f508f"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA version: 11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA-69W8M59nA",
        "outputId": "5ea8b1b7-f008-49d7-9ef1-d2b7185d286b"
      },
      "source": [
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.7.1+cu110 in /usr/local/lib/python3.7/dist-packages (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision==0.8.2+cu110 in /usr/local/lib/python3.7/dist-packages (0.8.2+cu110)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYwBZS1N6A3d",
        "outputId": "61483346-2afc-42ea-d0da-f43c634f1c93"
      },
      "source": [
        "! pip install ftfy regex\n",
        "! wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "--2021-06-01 19:03:38--  https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.39, 13.107.213.39, 2620:1ec:bdf::39, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.39|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘bpe_simple_vocab_16e6.txt.gz’\n",
            "\n",
            "bpe_simple_vocab_16 100%[===================>]   1.29M  7.30MB/s    in 0.2s    \n",
            "\n",
            "2021-06-01 19:03:38 (7.30 MB/s) - ‘bpe_simple_vocab_16e6.txt.gz’ saved [1356917/1356917]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oIcNBYB8lz3",
        "outputId": "3c27b864-ddd1-44e8-db28-666ea895cf04"
      },
      "source": [
        "!pip install git+https://github.com/Sri-vatsa/CLIP # using this fork because of visualization capabilities"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Sri-vatsa/CLIP\n",
            "  Cloning https://github.com/Sri-vatsa/CLIP to /tmp/pip-req-build-5dbp0sri\n",
            "  Running command git clone -q https://github.com/Sri-vatsa/CLIP /tmp/pip-req-build-5dbp0sri\n",
            "Requirement already satisfied (use --upgrade to upgrade): clip==1.0 from git+https://github.com/Sri-vatsa/CLIP in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Requirement already satisfied: torch~=1.7.1 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision~=0.8.2 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.8.2+cu110)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368623 sha256=564f735f1a6d8ec015b46beb4e2c25c4c04302ba6b8f5147d557dee4409a7128\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nhlpx4fi/wheels/cc/55/69/0d411dabbd5009fd069d47b47cf7839c54e595dc61725b307b\n",
            "Successfully built clip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-gp7n8__E"
      },
      "source": [
        "## Install clustering dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLg9ozo9Hvc"
      },
      "source": [
        "!pip -q install umap-learn>=0.3.7"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1WQnXdLHy2"
      },
      "source": [
        "## Install dataset manager dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1vvMx7_LLSp",
        "outputId": "103bd468-1c9a-425a-ae55-dc1a0bead254"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzsubsEm72rr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZI62a6G74kw"
      },
      "source": [
        "# ML Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# Data processing\n",
        "import PIL\n",
        "import base64\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from matplotlib import cm\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Models\n",
        "import clip\n",
        "\n",
        "# Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Clustering\n",
        "# import umap\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "#from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Misc\n",
        "import progressbar\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.metrics import jaccard_score, hamming_loss, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "# Modules\n",
        "from CLIPPER.code.ExperimentModules import embedding_models\n",
        "from CLIPPER.code.ExperimentModules.dataset_manager import DatasetManager\n",
        "from CLIPPER.code.ExperimentModules.weight_imprinting_classifier import WeightImprintingClassifier\n",
        "from CLIPPER.code.ExperimentModules import simclr_data_augmentations\n",
        "from CLIPPER.code.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)\n",
        "\n",
        "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_gxQ0KbwMh"
      },
      "source": [
        "# Initialization & Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND-Q6dDoYmDu"
      },
      "source": [
        "## Dataset details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bih5tBPdbx3u"
      },
      "source": [
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "\n",
        "experiment_id = \"ImagenetA-Embeddings\"\n",
        "\n",
        "folder_name = experiment_id+\"-28-02-21\"\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1bK72W-Um20EQDEyChNhNJthUNbmoSEjD'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBOFLDPL0RNK",
        "outputId": "fe5f9a05-c2a0-4e93-a046-f678d0ab24a4"
      },
      "source": [
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = create_expt_dir(drive, parentid, folder_name)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: ImagenetA-Embeddings-28-02-21, id: 13IXmLLCxY96gh9FQMR6Il_dXDB2LsYcR\n",
            "Experiment folder already exists. WARNING: Following with this run might overwrite existing results stored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JCHA5Q8eiOo"
      },
      "source": [
        "## Embedding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYmYbX2D8Mux"
      },
      "source": [
        "def run_data_through_model(\n",
        "    data, \n",
        "    embedder, \n",
        "    filename, \n",
        "    drive,\n",
        "    folderid,\n",
        "    total_num_images,\n",
        "    max_num_samples=5000,\n",
        "):\n",
        "    embedder.load_model()\n",
        "\n",
        "    embeddings = None\n",
        "    num_images_done = 0\n",
        "\n",
        "    while embeddings is None or num_images_done < total_num_images:\n",
        "        download_file_by_name(drive, folderid, filename)\n",
        "\n",
        "        if filename in os.listdir():\n",
        "            embeddings = np.load(filename)['data']\n",
        "            num_images_done = embeddings.shape[0]\n",
        "            if num_images_done == total_num_images:\n",
        "                print(\"All images done already.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"{}/{} images done already\".format(\n",
        "                    num_images_done, total_num_images)\n",
        "                )\n",
        "\n",
        "        print(\"Running for image indices {}-{}.\".format(\n",
        "            num_images_done, num_images_done+max_num_samples\n",
        "            )\n",
        "        )\n",
        "        if (num_images_done+max_num_samples) <= total_num_images:\n",
        "            batch = data[num_images_done:num_images_done+max_num_samples]\n",
        "        else:\n",
        "            batch = data[num_images_done:]\n",
        "\n",
        "        processed_batch = embedder.preprocess_data(batch)\n",
        "        embeddings_batch = embedder.embed_images(\n",
        "            processed_batch, batch_size=50\n",
        "            )\n",
        "        \n",
        "        if embeddings is None:\n",
        "            embeddings = embeddings_batch\n",
        "        else:\n",
        "            embeddings = np.concatenate(\n",
        "                [embeddings, embeddings_batch]\n",
        "                )\n",
        "            \n",
        "        delete_file_by_name(drive, folderid, filename)\n",
        "        embedder.save_embeddings_to_drive(\n",
        "            embeddings, \n",
        "            filename,\n",
        "            drive,\n",
        "            folderid\n",
        "            )\n",
        "        num_images_done = embeddings.shape[0]\n",
        "        print(\"{}/{} images done\".format(num_images_done, total_num_images))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsg-AC07SZzZ"
      },
      "source": [
        "# Test data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sdn6HMixMH9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcP9Ir-IxQoX"
      },
      "source": [
        "dm = DatasetManager()\n",
        "test_data_generator = dm.load_dataset('imagenet_a', split=\"test\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhahWSBBXvqz",
        "outputId": "45767b87-e433-41e5-c901-7db3e3af0529"
      },
      "source": [
        "_data = []\n",
        "_labels = []\n",
        "for i, example in enumerate(test_data_generator):\n",
        "    resized_image = cv2.resize(example['image'], (IMG_WIDTH, IMG_HEIGHT)).astype(np.uint8)\n",
        "    _data.append(resized_image)\n",
        "    _labels.append(example['label'])\n",
        "\n",
        "    del resized_image\n",
        "\n",
        "test_data = np.stack(_data)\n",
        "test_labels = np.array(_labels)\n",
        "\n",
        "del _data\n",
        "del _labels\n",
        "\n",
        "print('Images shape: ', test_data.shape)\n",
        "print('Alphabet labels length: ', len(test_labels))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images shape:  (7500, 224, 224, 3)\n",
            "Alphabet labels length:  7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilWIFlMmSpz7"
      },
      "source": [
        "# Save test labels\n",
        "test_labels_filename = 'test_labels.npz'\n",
        "\n",
        "if test_labels_filename not in os.listdir():\n",
        "    save_npy(test_labels_filename, test_labels)\n",
        "    save_to_drive(drive, folderid, test_labels_filename)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krw25rTlSTTx",
        "outputId": "e0bdcc33-797b-4ec0-9fa4-659f6471d15a"
      },
      "source": [
        "total_test_images = len(test_data)\n",
        "total_test_images"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exp4Y7jLGyp7"
      },
      "source": [
        "## Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NSK-prS5Q_2",
        "outputId": "5c4d9587-f7d0-4e0b-8bc5-3bd7eaf698db"
      },
      "source": [
        "max_num_samples = 5000 # Colab crashes with too many images\n",
        "inceptionv3_test_filename = 'rerun_inceptionv3_embeddings_test.npz'\n",
        "\n",
        "inceptionv3_test_embedder = embedding_models.InceptionV3EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    test_data, \n",
        "    inceptionv3_test_embedder, \n",
        "    inceptionv3_test_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_test_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-5000.\n",
            "Data saved to xrerun_inceptionv3_embeddings_test.npz\n",
            "Uploaded xrerun_inceptionv3_embeddings_test.npz to https://drive.google.com/drive/u/1/folders/13IXmLLCxY96gh9FQMR6Il_dXDB2LsYcR\n",
            "5000/7500 images done\n",
            "Downloading xrerun_inceptionv3_embeddings_test.npz from GDrive\n",
            "5000/7500 images done already\n",
            "Running for image indices 5000-10000.\n",
            "Deleting xrerun_inceptionv3_embeddings_test.npz from GDrive\n",
            "Data saved to xrerun_inceptionv3_embeddings_test.npz\n",
            "Uploaded xrerun_inceptionv3_embeddings_test.npz to https://drive.google.com/drive/u/1/folders/13IXmLLCxY96gh9FQMR6Il_dXDB2LsYcR\n",
            "7500/7500 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC66qPddG2gG"
      },
      "source": [
        "## Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409,
          "referenced_widgets": [
            "beb77b6bb3144c96b9a2cec1fb9c7d5b",
            "78eccdb74d604fcd9a5f6f7a78fb7b20",
            "2169934814d5441eaa52f9b4313eb756",
            "3c9d2f0a2e794fc892923fa89e13d0c3",
            "1a57dacaf3b04a958210b8cc217d37c5",
            "bb3c0c30171c4b54a1061461256c3aad",
            "8f31113d5ad14eb5a7da774f006462ee",
            "b44fb372289c4449a100178cfde442c2"
          ]
        },
        "id": "svIjGLD8BS_O",
        "outputId": "c867a46a-cb4d-4d0c-d885-d869b427b745"
      },
      "source": [
        "max_num_samples = 3000\n",
        "resnet50_test_filename = 'resnet50_embeddings_test.npz'\n",
        "\n",
        "resnet50_test_embedder = embedding_models.Resnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    test_data, \n",
        "    resnet50_test_embedder, \n",
        "    resnet50_test_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_test_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "beb77b6bb3144c96b9a2cec1fb9c7d5b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running for image indices 0-3000.\n",
            "Data saved to xrerun_resnet50_embeddings_test.npz\n",
            "Uploaded xrerun_resnet50_embeddings_test.npz to https://drive.google.com/drive/u/1/folders/13IXmLLCxY96gh9FQMR6Il_dXDB2LsYcR\n",
            "3000/7500 images done\n",
            "Downloading xrerun_resnet50_embeddings_test.npz from GDrive\n",
            "3000/7500 images done already\n",
            "Running for image indices 3000-6000.\n",
            "Deleting xrerun_resnet50_embeddings_test.npz from GDrive\n",
            "Data saved to xrerun_resnet50_embeddings_test.npz\n",
            "Uploaded xrerun_resnet50_embeddings_test.npz to https://drive.google.com/drive/u/1/folders/13IXmLLCxY96gh9FQMR6Il_dXDB2LsYcR\n",
            "6000/7500 images done\n",
            "Downloading xrerun_resnet50_embeddings_test.npz from GDrive\n",
            "6000/7500 images done already\n",
            "Running for image indices 6000-9000.\n",
            "Deleting xrerun_resnet50_embeddings_test.npz from GDrive\n",
            "Data saved to xrerun_resnet50_embeddings_test.npz\n",
            "Uploaded xrerun_resnet50_embeddings_test.npz to https://drive.google.com/drive/u/1/folders/13IXmLLCxY96gh9FQMR6Il_dXDB2LsYcR\n",
            "7500/7500 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCn3CW3w_G3W"
      },
      "source": [
        "## MoCo Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmQeAyek_G3X",
        "outputId": "d86d5be3-871a-43cb-b9cc-9b86dbda3179"
      },
      "source": [
        "max_num_samples = 2000\n",
        "moco_resnet50_test_filename = 'moco_resnet50_embeddings_test.npz'\n",
        "\n",
        "moco_resnet50_test_embedder = embedding_models.MoCoResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    test_data, \n",
        "    moco_resnet50_test_embedder, \n",
        "    moco_resnet50_test_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_test_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-2000.\n",
            "Data saved to xrerun_moco_resnet50_embeddings_test.npz\n",
            "Uploaded xrerun_moco_resnet50_embeddings_test.npz to https://drive.google.com/drive/u/1/folders/13IXmLLCxY96gh9FQMR6Il_dXDB2LsYcR\n",
            "2000/7500 images done\n",
            "Downloading xrerun_moco_resnet50_embeddings_test.npz from GDrive\n",
            "2000/7500 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Deleting xrerun_moco_resnet50_embeddings_test.npz from GDrive\n",
            "Data saved to xrerun_moco_resnet50_embeddings_test.npz\n",
            "Uploaded xrerun_moco_resnet50_embeddings_test.npz to https://drive.google.com/drive/u/1/folders/13IXmLLCxY96gh9FQMR6Il_dXDB2LsYcR\n",
            "4000/7500 images done\n",
            "Downloading xrerun_moco_resnet50_embeddings_test.npz from GDrive\n",
            "4000/7500 images done already\n",
            "Running for image indices 4000-6000.\n",
            "Deleting xrerun_moco_resnet50_embeddings_test.npz from GDrive\n",
            "Data saved to xrerun_moco_resnet50_embeddings_test.npz\n",
            "Uploaded xrerun_moco_resnet50_embeddings_test.npz to https://drive.google.com/drive/u/1/folders/13IXmLLCxY96gh9FQMR6Il_dXDB2LsYcR\n",
            "6000/7500 images done\n",
            "Downloading xrerun_moco_resnet50_embeddings_test.npz from GDrive\n",
            "6000/7500 images done already\n",
            "Running for image indices 6000-8000.\n",
            "Deleting xrerun_moco_resnet50_embeddings_test.npz from GDrive\n",
            "Data saved to xrerun_moco_resnet50_embeddings_test.npz\n",
            "Uploaded xrerun_moco_resnet50_embeddings_test.npz to https://drive.google.com/drive/u/1/folders/13IXmLLCxY96gh9FQMR6Il_dXDB2LsYcR\n",
            "7500/7500 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k7FFrtU_GgO"
      },
      "source": [
        "## PCL Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FppJPYz1_GgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e06017-7c55-4192-a807-1de634613236"
      },
      "source": [
        "max_num_samples = 2000\n",
        "pcl_resnet50_test_filename = 'pcl_resnet50_embeddings_test.npz'\n",
        "\n",
        "pcl_resnet50_test_embedder = embedding_models.PCLResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    test_data, \n",
        "    pcl_resnet50_test_embedder, \n",
        "    pcl_resnet50_test_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_test_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading pcl_resnet50_embeddings_test.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy41hBsj_Hbr"
      },
      "source": [
        "## SwAV Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ncOHlr_Hb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "d94cb72fced34c2487f9e5736c58a269",
            "06e85f3541b54b489603e89fca8cc213",
            "21dbb5f1bfba41029676fa9ee577fb8a",
            "36588743da6441dc97c49bfa25fd9e38",
            "cc115a32683a48569440bbf17e44eb34",
            "ba36a096f07e47af9bccd4b8df9a6a0d",
            "d7531c38f5d044be8c8afe02954b508b",
            "d4f02c12e9a24bafb8e8489c74f9f988"
          ]
        },
        "outputId": "db2d21b1-51f5-4f7c-b26c-7ad8a6cf05b7"
      },
      "source": [
        "max_num_samples = 3000\n",
        "swav_resnet50_test_filename = 'swav_resnet50_embeddings_test.npz'\n",
        "\n",
        "swav_resnet50_test_embedder = embedding_models.SwAVResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    test_data, \n",
        "    swav_resnet50_test_embedder, \n",
        "    swav_resnet50_test_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_test_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/swav/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deepcluster/swav_800ep_pretrain.pth.tar\" to /root/.cache/torch/hub/checkpoints/swav_800ep_pretrain.pth.tar\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d94cb72fced34c2487f9e5736c58a269",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=113703565.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading swav_resnet50_embeddings_test.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpvNJt3T_ymv"
      },
      "source": [
        "## SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkMkP19T_ymx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4049816-4004-4a4f-f3c3-902a91b1951f"
      },
      "source": [
        "max_num_samples = 3000\n",
        "simclr_test_filename = 'simclr_embeddings_test.npz'\n",
        "\n",
        "simclr_test_embedder = embedding_models.SimCLREmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    test_data, \n",
        "    simclr_test_embedder, \n",
        "    simclr_test_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_test_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_16240) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_23562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_22288) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_30442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_30802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_35122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_22072) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_35242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_33322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_29962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_15808) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_33922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_32122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_21640) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_34762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_29842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_33802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_23944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_20560) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_19912) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_32242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_30202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_35602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_34282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_19480) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_14080) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_35962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_29512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_29728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_22720) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_16888) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_33202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_34882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_12784) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_32482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_35002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_17536) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_15160) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_21208) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_33082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_23152) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_12124) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_20776) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_19696) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_34642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_16024) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_17104) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_30682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_30082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_31162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_32962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_13432) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_14512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_29403) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_21856) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_34402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_32002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_18400) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_13000) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_12352) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_23756) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_20992) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_16456) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_34522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_33562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_14944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_33682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_18616) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_31762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_30562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_35482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_14728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_30322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_31282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_15376) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_31882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_16672) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_29621) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_22504) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_18832) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_33442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_31642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_14296) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_32602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_13216) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_15592) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_32842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_18184) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_32362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_35362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_20344) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_32722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_35842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_35722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_12568) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_13864) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_23368) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_17968) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_19264) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_17752) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_13648) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_31042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_31522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_30922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_20128) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_34162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_21424) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_31402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_17320) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_34042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_19048) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_22936) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading simclr_embeddings_test.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpwXmr3i_yXt"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdVItqYB_yX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b5cd92-57b2-4009-a6be-5055148eaf61"
      },
      "source": [
        "max_num_samples = 3000\n",
        "vgg16_test_filename = 'vgg16_embeddings_test.npz'\n",
        "\n",
        "vgg16_test_embedder = embedding_models.VGG16EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    test_data, \n",
        "    vgg16_test_embedder, \n",
        "    vgg16_test_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_test_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 12s 0us/step\n",
            "Downloading vgg16_embeddings_test.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeOqwRRnAPQm"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7NTLqP8APQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a69139-2e07-453d-e188-47f215ec2965"
      },
      "source": [
        "max_num_samples = 500\n",
        "clip_test_filename = 'clip_embeddings_test.npz'\n",
        "\n",
        "clip_test_embedder = embedding_models.CLIPEmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    test_data, \n",
        "    clip_test_embedder, \n",
        "    clip_test_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_test_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 354M/354M [00:03<00:00, 100MiB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading clip_embeddings_test.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}