{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SaveEmbeddings_UCF101.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RGlVnbugxFK2",
        "3rKe3HqM523g",
        "OLU-gp7n8__E",
        "NzsubsEm72rr",
        "zU_gxQ0KbwMh",
        "KPj-b5kWxRVi",
        "HZuStZQ4Ryep",
        "J7ppzB0jR3-P",
        "Exp4Y7jLGyp7",
        "yCn3CW3w_G3W",
        "-k7FFrtU_GgO",
        "Dy41hBsj_Hbr",
        "MpvNJt3T_ymv",
        "hpwXmr3i_yXt",
        "CeOqwRRnAPQm"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTY7kA7DOzpV"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-7JU3Q7q_XT",
        "outputId": "860ac614-a235-4462-99a1-6d4be967b5dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqqXI7Izk65p",
        "outputId": "7239aa28-2345-44be-9c4d-27ba168b051d"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Cloning PAL_2021 to access modules.\n",
        "# Need password to access private repo.\n",
        "\n",
        "if 'CLIPPER' not in os.listdir():\n",
        "    cmd_string = 'git clone https://github.com/PAL-ML/CLIPPER.git'\n",
        "    os.system(cmd_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: httplib2==0.15.0 in /usr/local/lib/python3.7/dist-packages (0.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlVnbugxFK2"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmgIrfT8hDNE"
      },
      "source": [
        "## Install multi label metrics dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6xXPAFbe6Gp",
        "outputId": "3f31e599-01df-46ed-d67b-743f544fef23"
      },
      "source": [
        "! pip install scikit-learn==0.24"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==0.24 in /usr/local/lib/python3.7/dist-packages (0.24.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKe3HqM523g"
      },
      "source": [
        "## Install CLIP dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poS-WNDixIhY",
        "outputId": "0f9350fa-106a-49c9-ee18-c640308fc963"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA version: 10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA-69W8M59nA",
        "outputId": "39ffbccf-4a98-42c1-9843-cf79475fda14"
      },
      "source": [
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.7.1+cu101 in /usr/local/lib/python3.7/dist-packages (1.7.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.8.2+cu101 in /usr/local/lib/python3.7/dist-packages (0.8.2+cu101)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (5.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu101) (7.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYwBZS1N6A3d",
        "outputId": "4f7b26ae-cb0c-4fc1-f110-951ab153c2f1"
      },
      "source": [
        "! pip install ftfy regex\n",
        "! wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (5.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "--2021-02-28 10:18:22--  https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.19, 13.107.213.19, 2620:1ec:bdf::19, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘bpe_simple_vocab_16e6.txt.gz’\n",
            "\n",
            "bpe_simple_vocab_16 100%[===================>]   1.29M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-02-28 10:18:22 (26.9 MB/s) - ‘bpe_simple_vocab_16e6.txt.gz’ saved [1356917/1356917]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oIcNBYB8lz3",
        "outputId": "69e7101d-a706-4b60-e1ce-f35f0b86f21c"
      },
      "source": [
        "!pip install git+https://github.com/Sri-vatsa/CLIP # using this fork because of visualization capabilities"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Sri-vatsa/CLIP\n",
            "  Cloning https://github.com/Sri-vatsa/CLIP to /tmp/pip-req-build-nusku9om\n",
            "  Running command git clone -q https://github.com/Sri-vatsa/CLIP /tmp/pip-req-build-nusku9om\n",
            "Requirement already satisfied (use --upgrade to upgrade): clip==1.0 from git+https://github.com/Sri-vatsa/CLIP in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (5.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Requirement already satisfied: torch~=1.7.1 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.7.1+cu101)\n",
            "Requirement already satisfied: torchvision~=0.8.2 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.8.2+cu101)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.0.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368623 sha256=79c6bcfe0f287577a15e22601283596d86f334dca4e014d3c84fe6c76b99e035\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-khiutq_s/wheels/cc/55/69/0d411dabbd5009fd069d47b47cf7839c54e595dc61725b307b\n",
            "Successfully built clip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-gp7n8__E"
      },
      "source": [
        "## Install clustering dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLg9ozo9Hvc"
      },
      "source": [
        "!pip -q install umap-learn>=0.3.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1WQnXdLHy2"
      },
      "source": [
        "## Install dataset manager dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1vvMx7_LLSp",
        "outputId": "d593ca62-7732-4bb6-c6f4-a9ee39f0ca2f"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzsubsEm72rr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZI62a6G74kw",
        "outputId": "b4e8c38d-2f2b-44db-c6ed-0d1a438966ae"
      },
      "source": [
        "# ML Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# Data processing\n",
        "import PIL\n",
        "import base64\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from matplotlib import cm\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Models\n",
        "import clip\n",
        "\n",
        "# Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Clustering\n",
        "# import umap\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "#from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Misc\n",
        "import progressbar\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.metrics import jaccard_score, hamming_loss, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "# Modules\n",
        "from CLIPPER.code.ExperimentModules import embedding_models\n",
        "from CLIPPER.code.ExperimentModules.dataset_manager import DatasetManager\n",
        "from CLIPPER.code.ExperimentModules.weight_imprinting_classifier import WeightImprintingClassifier\n",
        "from CLIPPER.code.ExperimentModules import simclr_data_augmentations\n",
        "from CLIPPER.code.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)\n",
        "\n",
        "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_gxQ0KbwMh"
      },
      "source": [
        "# Initialization & Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND-Q6dDoYmDu"
      },
      "source": [
        "## Dataset details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bih5tBPdbx3u"
      },
      "source": [
        "IMG_HEIGHT = 112\n",
        "IMG_WIDTH = 112\n",
        "\n",
        "experiment_id = \"UCF101-Embeddings\"\n",
        "\n",
        "folder_name = experiment_id+\"-28-02-21\"\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1bK72W-Um20EQDEyChNhNJthUNbmoSEjD'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBOFLDPL0RNK",
        "outputId": "35c78d1f-98a4-4ac7-91dd-511cc4c0b099"
      },
      "source": [
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = create_expt_dir(drive, parentid, folder_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: UCF101-Embeddings-28-02-21, id: 1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "Experiment folder already exists. WARNING: Following with this run might overwrite existing results stored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JCHA5Q8eiOo"
      },
      "source": [
        "# Embedding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYmYbX2D8Mux"
      },
      "source": [
        "def run_data_through_model(\n",
        "    data, \n",
        "    embedder, \n",
        "    filename, \n",
        "    drive,\n",
        "    folderid,\n",
        "    total_num_images,\n",
        "    max_num_samples=5000,\n",
        "):\n",
        "    embedder.load_model()\n",
        "\n",
        "    embeddings = None\n",
        "    num_images_done = 0\n",
        "\n",
        "    while embeddings is None or num_images_done < total_num_images:\n",
        "        download_file_by_name(drive, folderid, filename)\n",
        "\n",
        "        if filename in os.listdir():\n",
        "            embeddings = np.load(filename)['data']\n",
        "            num_images_done = embeddings.shape[0]\n",
        "            if num_images_done == total_num_images:\n",
        "                print(\"All images done already.\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"{}/{} images done already\".format(\n",
        "                    num_images_done, total_num_images)\n",
        "                )\n",
        "\n",
        "        print(\"Running for image indices {}-{}.\".format(\n",
        "            num_images_done, num_images_done+max_num_samples\n",
        "            )\n",
        "        )\n",
        "        if (num_images_done+max_num_samples) <= total_num_images:\n",
        "            batch = data[num_images_done:num_images_done+max_num_samples]\n",
        "        else:\n",
        "            batch = data[num_images_done:]\n",
        "\n",
        "        processed_batch = embedder.preprocess_data(batch)\n",
        "        embeddings_batch = embedder.embed_images(\n",
        "            processed_batch, batch_size=50\n",
        "            )\n",
        "        \n",
        "        if embeddings is None:\n",
        "            embeddings = embeddings_batch\n",
        "        else:\n",
        "            embeddings = np.concatenate(\n",
        "                [embeddings, embeddings_batch]\n",
        "                )\n",
        "            \n",
        "        delete_file_by_name(drive, folderid, filename)\n",
        "        embedder.save_embeddings_to_drive(\n",
        "            embeddings, \n",
        "            filename,\n",
        "            drive,\n",
        "            folderid\n",
        "            )\n",
        "        num_images_done = embeddings.shape[0]\n",
        "        print(\"{}/{} images done\".format(num_images_done, total_num_images))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l7FJ-0PfFSp"
      },
      "source": [
        "# Train data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sdn6HMixMH9"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcP9Ir-IxQoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421769d3-5c98-4c4a-a29c-4edda528024a"
      },
      "source": [
        "dm = DatasetManager()\n",
        "train_data_generator = dm.load_dataset('ucf_101', split=\"train\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13320 files belonging to 101 classes.\n",
            "Using 10656 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhahWSBBXvqz",
        "outputId": "f813a50c-fd5a-4533-f3f2-f997ef0c0bdd"
      },
      "source": [
        "_data = []\n",
        "_labels = []\n",
        "for i, (image, label) in enumerate(train_data_generator):\n",
        "    resized_image = cv2.resize(image[0], (IMG_WIDTH, IMG_HEIGHT)).astype(np.uint8)\n",
        "    _data.append(resized_image)\n",
        "    _labels.append(label[0])\n",
        "\n",
        "train_data = np.stack(_data)\n",
        "train_labels = np.array(_labels)\n",
        "\n",
        "del _data\n",
        "del _labels\n",
        "\n",
        "print('Images shape: ', train_data.shape)\n",
        "print('Labels length: ', len(train_labels))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images shape:  (10656, 112, 112, 3)\n",
            "Labels length:  10656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvoopWgYgQQJ"
      },
      "source": [
        "# Save train labels\n",
        "train_labels_filename = 'train_labels.npz'\n",
        "\n",
        "if train_labels_filename not in os.listdir():\n",
        "    save_npy(train_labels_filename, train_labels)\n",
        "    save_to_drive(drive, folderid, train_labels_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOZL8Rz_e-Rt",
        "outputId": "2c44738c-c5da-4c89-fd23-8daa894b5c87"
      },
      "source": [
        "total_train_images = len(train_data)\n",
        "total_train_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exp4Y7jLGyp7"
      },
      "source": [
        "## Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NSK-prS5Q_2",
        "outputId": "1e601ae1-27bb-466f-daf0-9a531befcb05"
      },
      "source": [
        "max_num_samples = 4000 # Colab crashes with too many images\n",
        "inceptionv3_train_filename = 'inceptionv3_embeddings_train.npz'\n",
        "\n",
        "inceptionv3_train_embedder = embedding_models.InceptionV3EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    inceptionv3_train_embedder, \n",
        "    inceptionv3_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading inceptionv3_embeddings_train.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC66qPddG2gG"
      },
      "source": [
        "## Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svIjGLD8BS_O",
        "outputId": "3c2326ff-7df5-490f-fb97-d3dcdfed5049"
      },
      "source": [
        "max_num_samples = 2000\n",
        "resnet50_train_filename = 'resnet50_embeddings_train.npz'\n",
        "\n",
        "resnet50_train_embedder = embedding_models.Resnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    resnet50_train_embedder, \n",
        "    resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading resnet50_embeddings_train.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCn3CW3w_G3W"
      },
      "source": [
        "## MoCo Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmQeAyek_G3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5ddd2d-4ab2-44e4-8433-084214c75ba5"
      },
      "source": [
        "max_num_samples = 2000\n",
        "moco_resnet50_train_filename = 'moco_resnet50_embeddings_train.npz'\n",
        "\n",
        "moco_resnet50_train_embedder = embedding_models.MoCoResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    moco_resnet50_train_embedder, \n",
        "    moco_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading moco_resnet50_embeddings_train.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k7FFrtU_GgO"
      },
      "source": [
        "## PCL Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FppJPYz1_GgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c902a8-3ac4-4bf4-c51b-19c09ac0987b"
      },
      "source": [
        "max_num_samples = 2000\n",
        "pcl_resnet50_train_filename = 'pcl_resnet50_embeddings_train.npz'\n",
        "\n",
        "pcl_resnet50_train_embedder = embedding_models.PCLResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    pcl_resnet50_train_embedder, \n",
        "    pcl_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pcl_resnet50_embeddings_train.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy41hBsj_Hbr"
      },
      "source": [
        "## SwAV Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ncOHlr_Hb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9882a096-cf1d-459a-b852-cace4c0b9337"
      },
      "source": [
        "max_num_samples = 1000\n",
        "swav_resnet50_train_filename = 'swav_resnet50_embeddings_train.npz'\n",
        "\n",
        "swav_resnet50_train_embedder = embedding_models.SwAVResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    swav_resnet50_train_embedder, \n",
        "    swav_resnet50_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_swav_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading swav_resnet50_embeddings_train.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpvNJt3T_ymv"
      },
      "source": [
        "## SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkMkP19T_ymx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c567c3a4-5486-41a8-ffa6-5f48bc1d1653"
      },
      "source": [
        "max_num_samples = 1000\n",
        "simclr_train_filename = 'simclr_embeddings_train.npz'\n",
        "\n",
        "simclr_train_embedder = embedding_models.SimCLREmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    simclr_train_embedder, \n",
        "    simclr_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_16240) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_23562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_22288) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_30442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_30802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_35122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_22072) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_35242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_33322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_29962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_15808) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_33922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_32122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_21640) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_34762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_29842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_33802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_23944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_20560) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_19912) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_32242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_30202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_35602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_34282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_19480) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_14080) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_35962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_29512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_29728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_22720) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_16888) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_33202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_34882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_12784) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_32482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_35002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_17536) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_15160) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_21208) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_33082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_23152) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_12124) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_20776) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_19696) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_34642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_16024) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_17104) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_30682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_30082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_31162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_32962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_13432) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_14512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_29403) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_21856) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_34402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_32002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_18400) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_13000) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_12352) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_23756) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_20992) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_16456) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_34522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_33562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_14944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_33682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_18616) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_31762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_30562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_35482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_14728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_30322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_31282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_15376) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_31882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_16672) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_29621) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_22504) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_18832) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_33442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_31642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_14296) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_32602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_13216) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_15592) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_32842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_18184) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_32362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_35362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_20344) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_32722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_35842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_35722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_12568) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_13864) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_23368) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_17968) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_19264) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_17752) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_13648) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_31042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_31522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_30922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_20128) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_34162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_21424) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_31402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_17320) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_34042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_19048) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_22936) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading simclr_embeddings_train.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpwXmr3i_yXt"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdVItqYB_yX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edda8c00-db6f-463a-97a9-732e3571cc9e"
      },
      "source": [
        "max_num_samples = 1000\n",
        "vgg16_train_filename = 'vgg16_embeddings_train.npz'\n",
        "\n",
        "vgg16_train_embedder = embedding_models.VGG16EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    vgg16_train_embedder, \n",
        "    vgg16_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading vgg16_embeddings_train.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeOqwRRnAPQm"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7NTLqP8APQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1d4ad7-de2a-4978-d0bb-7af3ecc96799"
      },
      "source": [
        "max_num_samples = 1000\n",
        "clip_train_filename = 'clip_embeddings_train.npz'\n",
        "\n",
        "clip_train_embedder = embedding_models.CLIPEmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    train_data, \n",
        "    clip_train_embedder, \n",
        "    clip_train_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_train_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-1000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:05] |********************************  | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "1000/10656 images done\n",
            "Downloading clip_embeddings_train.npz from GDrive\n",
            "1000/10656 images done already\n",
            "Running for image indices 1000-2000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***                               | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:01] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_train.npz from GDrive\n",
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2000/10656 images done\n",
            "Downloading clip_embeddings_train.npz from GDrive\n",
            "2000/10656 images done already\n",
            "Running for image indices 2000-3000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***                               | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:01] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_train.npz from GDrive\n",
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "3000/10656 images done\n",
            "Downloading clip_embeddings_train.npz from GDrive\n",
            "3000/10656 images done already\n",
            "Running for image indices 3000-4000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***                               | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:01] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_train.npz from GDrive\n",
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "4000/10656 images done\n",
            "Downloading clip_embeddings_train.npz from GDrive\n",
            "4000/10656 images done already\n",
            "Running for image indices 4000-5000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***                               | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:01] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_train.npz from GDrive\n",
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "5000/10656 images done\n",
            "Downloading clip_embeddings_train.npz from GDrive\n",
            "5000/10656 images done already\n",
            "Running for image indices 5000-6000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***                               | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:01] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_train.npz from GDrive\n",
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "6000/10656 images done\n",
            "Downloading clip_embeddings_train.npz from GDrive\n",
            "6000/10656 images done already\n",
            "Running for image indices 6000-7000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***                               | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:01] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_train.npz from GDrive\n",
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "7000/10656 images done\n",
            "Downloading clip_embeddings_train.npz from GDrive\n",
            "7000/10656 images done already\n",
            "Running for image indices 7000-8000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***                               | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:01] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_train.npz from GDrive\n",
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "8000/10656 images done\n",
            "Downloading clip_embeddings_train.npz from GDrive\n",
            "8000/10656 images done already\n",
            "Running for image indices 8000-9000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***                               | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:01] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_train.npz from GDrive\n",
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "9000/10656 images done\n",
            "Downloading clip_embeddings_train.npz from GDrive\n",
            "9000/10656 images done already\n",
            "Running for image indices 9000-10000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***                               | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:01] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_train.npz from GDrive\n",
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "10000/10656 images done\n",
            "Downloading clip_embeddings_train.npz from GDrive\n",
            "10000/10656 images done already\n",
            "Running for image indices 10000-11000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |****                              | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |*******************************   | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_train.npz from GDrive\n",
            "Data saved to clip_embeddings_train.npz\n",
            "Uploaded clip_embeddings_train.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "10656/10656 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWQiLtKkgAnM"
      },
      "source": [
        "# Val data split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlkRqm7vgAnP"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVi22lKIgAnQ",
        "outputId": "7da220f5-3cf6-4619-b065-33f7974c14fa"
      },
      "source": [
        "val_data_generator = dm.load_dataset('ucf_101', split=\"val\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13320 files belonging to 101 classes.\n",
            "Using 2664 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSGYDCfFgAnR",
        "outputId": "030479f8-31fb-4ff4-b8cc-35c22950950b"
      },
      "source": [
        "_data = []\n",
        "_labels = []\n",
        "for i, (image, label) in enumerate(val_data_generator):\n",
        "    resized_image = cv2.resize(image[0], (IMG_WIDTH, IMG_HEIGHT)).astype(np.uint8)\n",
        "    _data.append(resized_image)\n",
        "    _labels.append(label[0])\n",
        "\n",
        "val_data = np.stack(_data)\n",
        "val_labels = np.array(_labels)\n",
        "\n",
        "del _data\n",
        "del _labels\n",
        "\n",
        "print('Images shape: ', val_data.shape)\n",
        "print('Alphabet labels length: ', len(val_labels))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images shape:  (2664, 112, 112, 3)\n",
            "Alphabet labels length:  2664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLWti1ucgX1z",
        "outputId": "cee576ec-1c63-4f80-a146-9a7175cb6bea"
      },
      "source": [
        "# Save val labels\n",
        "val_labels_filename = 'val_labels.npz'\n",
        "\n",
        "if val_labels_filename not in os.listdir():\n",
        "    save_npy(val_labels_filename, val_labels)\n",
        "    save_to_drive(drive, folderid, val_labels_filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data saved to val_labels.npz\n",
            "Uploaded val_labels.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOacFeKBgAnT",
        "outputId": "afcbb882-6bb2-4080-fb9d-015ecab0adba"
      },
      "source": [
        "total_val_images = len(val_data)\n",
        "total_val_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLR8Zid5gAnT"
      },
      "source": [
        "## Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdiSPRXBgAnU",
        "outputId": "63601994-8344-4354-bb55-9a34b4613637"
      },
      "source": [
        "max_num_samples = 2000 # Colab crashes with too many images\n",
        "inceptionv3_val_filename = 'inceptionv3_embeddings_val.npz'\n",
        "\n",
        "inceptionv3_val_embedder = embedding_models.InceptionV3EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    inceptionv3_val_embedder, \n",
        "    inceptionv3_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading inceptionv3_embeddings_val.npz from GDrive\n",
            "All images done already.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXH_D1PjgAnU"
      },
      "source": [
        "## Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnjwn5jugAnV",
        "outputId": "935f1a0d-6451-49f9-e584-2c99b721fd54"
      },
      "source": [
        "max_num_samples = 2000\n",
        "resnet50_val_filename = 'resnet50_embeddings_val.npz'\n",
        "\n",
        "resnet50_val_embedder = embedding_models.Resnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    resnet50_val_embedder, \n",
        "    resnet50_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-2000.\n",
            "Preprocessing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:06:18] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data saved to resnet50_embeddings_val.npz\n",
            "Uploaded resnet50_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2000/2664 images done\n",
            "Downloading resnet50_embeddings_val.npz from GDrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |****                              | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2664 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Preprocessing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:02:05] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting resnet50_embeddings_val.npz from GDrive\n",
            "Data saved to resnet50_embeddings_val.npz\n",
            "Uploaded resnet50_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2664/2664 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPTf0dZWgAnV"
      },
      "source": [
        "## MoCo Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8MmypOCgAnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8782f6e-c6ea-4d1d-f918-bd2f6972fc9d"
      },
      "source": [
        "max_num_samples = 2000\n",
        "moco_resnet50_val_filename = 'moco_resnet50_embeddings_val.npz'\n",
        "\n",
        "moco_resnet50_val_embedder = embedding_models.MoCoResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    moco_resnet50_val_embedder, \n",
        "    moco_resnet50_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:   0:00:04) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-2000.\n",
            "Preprocessing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:06:46] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data saved to moco_resnet50_embeddings_val.npz\n",
            "Uploaded moco_resnet50_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2000/2664 images done\n",
            "Downloading moco_resnet50_embeddings_val.npz from GDrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |****                              | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2664 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Preprocessing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:02:13] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting moco_resnet50_embeddings_val.npz from GDrive\n",
            "Data saved to moco_resnet50_embeddings_val.npz\n",
            "Uploaded moco_resnet50_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2664/2664 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvB5aemdgAnW"
      },
      "source": [
        "## PCL Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ3C8NPMgAnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6563501a-120b-4d9e-f488-a8168f3efd2c"
      },
      "source": [
        "max_num_samples = 2000\n",
        "pcl_resnet50_val_filename = 'pcl_resnet50_embeddings_val.npz'\n",
        "\n",
        "pcl_resnet50_val_embedder = embedding_models.PCLResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    pcl_resnet50_val_embedder, \n",
        "    pcl_resnet50_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:   0:00:03) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-2000.\n",
            "Preprocessing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:06:11] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data saved to pcl_resnet50_embeddings_val.npz\n",
            "Uploaded pcl_resnet50_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2000/2664 images done\n",
            "Downloading pcl_resnet50_embeddings_val.npz from GDrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |**                                | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2664 images done already\n",
            "Running for image indices 2000-4000.\n",
            "Preprocessing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:02:02] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting pcl_resnet50_embeddings_val.npz from GDrive\n",
            "Data saved to pcl_resnet50_embeddings_val.npz\n",
            "Uploaded pcl_resnet50_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2664/2664 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgFEIwtngAnX"
      },
      "source": [
        "## SwAV Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGNGhKd8gAnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca460d9a-76a0-43e0-bb64-2162f3f93e79"
      },
      "source": [
        "max_num_samples = 1000\n",
        "swav_resnet50_val_filename = 'swav_resnet50_embeddings_val.npz'\n",
        "\n",
        "swav_resnet50_val_embedder = embedding_models.SwAVResnet50EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    swav_resnet50_val_embedder, \n",
        "    swav_resnet50_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_swav_master\n",
            " [elapsed time: 0:00:00] |*                                 | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-1000.\n",
            "Preprocessing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:03:16] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data saved to swav_resnet50_embeddings_val.npz\n",
            "Uploaded swav_resnet50_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "1000/2664 images done\n",
            "Downloading swav_resnet50_embeddings_val.npz from GDrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |*                                 | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/2664 images done already\n",
            "Running for image indices 1000-2000.\n",
            "Preprocessing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:03:15] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting swav_resnet50_embeddings_val.npz from GDrive\n",
            "Data saved to swav_resnet50_embeddings_val.npz\n",
            "Uploaded swav_resnet50_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2000/2664 images done\n",
            "Downloading swav_resnet50_embeddings_val.npz from GDrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |****                              | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2664 images done already\n",
            "Running for image indices 2000-3000.\n",
            "Preprocessing data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:02:06] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting swav_resnet50_embeddings_val.npz from GDrive\n",
            "Data saved to swav_resnet50_embeddings_val.npz\n",
            "Uploaded swav_resnet50_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2664/2664 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgQGc62agAnY"
      },
      "source": [
        "## SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX48gy4DgAnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23b7670-accc-4f97-c04a-393d830d08bd"
      },
      "source": [
        "max_num_samples = 1000\n",
        "simclr_val_filename = 'simclr_embeddings_val.npz'\n",
        "\n",
        "simclr_val_embedder = embedding_models.SimCLREmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    simclr_val_embedder, \n",
        "    simclr_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_16240) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_23562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_22288) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_30442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_30802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___28151) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_35122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_22072) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_46_layer_call_and_return_conditional_losses_35242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_33322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_29962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_15808) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_33922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_32122) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_21640) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_34762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_29842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_33802) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_23944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_20560) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_19912) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_32242) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_30202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_35602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_34282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_34_layer_call_and_return_conditional_losses_19480) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_9_layer_call_and_return_conditional_losses_14080) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_35962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_53_layer_call_and_return_conditional_losses_29512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_55_layer_call_and_return_conditional_losses_29728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_49_layer_call_and_return_conditional_losses_22720) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_16888) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_33202) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_34882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_12784) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_32482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_44_layer_call_and_return_conditional_losses_35002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_17536) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_15160) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_42_layer_call_and_return_conditional_losses_21208) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_33082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_23152) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_12124) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_20776) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_35_layer_call_and_return_conditional_losses_19696) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_34642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_16024) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_23_layer_call_and_return_conditional_losses_17104) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_30682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_3_layer_call_and_return_conditional_losses_30082) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_31162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_32962) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_6_layer_call_and_return_conditional_losses_13432) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_14512) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_layer_call_and_return_conditional_losses_29403) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_45_layer_call_and_return_conditional_losses_21856) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_39_layer_call_and_return_conditional_losses_34402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_19_layer_call_and_return_conditional_losses_32002) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_29_layer_call_and_return_conditional_losses_18400) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_4_layer_call_and_return_conditional_losses_13000) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_1_layer_call_and_return_conditional_losses_12352) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_23756) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_41_layer_call_and_return_conditional_losses_20992) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_20_layer_call_and_return_conditional_losses_16456) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_40_layer_call_and_return_conditional_losses_34522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_33562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_14944) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_33682) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_30_layer_call_and_return_conditional_losses_18616) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_17_layer_call_and_return_conditional_losses_31762) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_30562) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_35482) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_12_layer_call_and_return_conditional_losses_14728) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_30322) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_13_layer_call_and_return_conditional_losses_31282) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_15376) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_18_layer_call_and_return_conditional_losses_31882) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_21_layer_call_and_return_conditional_losses_16672) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_54_layer_call_and_return_conditional_losses_29621) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_48_layer_call_and_return_conditional_losses_22504) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_18832) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_31_layer_call_and_return_conditional_losses_33442) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_31642) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_14296) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_32602) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_5_layer_call_and_return_conditional_losses_13216) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_16_layer_call_and_return_conditional_losses_15592) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_32842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_28_layer_call_and_return_conditional_losses_18184) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_22_layer_call_and_return_conditional_losses_32362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_47_layer_call_and_return_conditional_losses_35362) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_38_layer_call_and_return_conditional_losses_20344) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_25_layer_call_and_return_conditional_losses_32722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_51_layer_call_and_return_conditional_losses_35842) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_35722) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_2_layer_call_and_return_conditional_losses_12568) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_8_layer_call_and_return_conditional_losses_13864) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_52_layer_call_and_return_conditional_losses_23368) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_27_layer_call_and_return_conditional_losses_17968) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_33_layer_call_and_return_conditional_losses_19264) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_26_layer_call_and_return_conditional_losses_17752) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_7_layer_call_and_return_conditional_losses_13648) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_11_layer_call_and_return_conditional_losses_31042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_15_layer_call_and_return_conditional_losses_31522) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_10_layer_call_and_return_conditional_losses_30922) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_20128) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_37_layer_call_and_return_conditional_losses_34162) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_43_layer_call_and_return_conditional_losses_21424) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_14_layer_call_and_return_conditional_losses_31402) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_24_layer_call_and_return_conditional_losses_17320) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_36_layer_call_and_return_conditional_losses_34042) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_32_layer_call_and_return_conditional_losses_19048) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_sync_batch_normalization_50_layer_call_and_return_conditional_losses_22936) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-1000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:11] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data saved to simclr_embeddings_val.npz\n",
            "Uploaded simclr_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "1000/2664 images done\n",
            "Downloading simclr_embeddings_val.npz from GDrive\n",
            "1000/2664 images done already\n",
            "Running for image indices 1000-2000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:03] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting simclr_embeddings_val.npz from GDrive\n",
            "Data saved to simclr_embeddings_val.npz\n",
            "Uploaded simclr_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2000/2664 images done\n",
            "Downloading simclr_embeddings_val.npz from GDrive\n",
            "2000/2664 images done already\n",
            "Running for image indices 2000-3000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |**                                | (ETA:   0:00:02) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:02] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting simclr_embeddings_val.npz from GDrive\n",
            "Data saved to simclr_embeddings_val.npz\n",
            "Uploaded simclr_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2664/2664 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a68tj7FRgAnZ"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kStKRyuHgAnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802f6bac-27b4-4d10-e633-6617563cfb09"
      },
      "source": [
        "max_num_samples = 1000\n",
        "vgg16_val_filename = 'vgg16_embeddings_val.npz'\n",
        "\n",
        "vgg16_val_embedder = embedding_models.VGG16EmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    vgg16_val_embedder, \n",
        "    vgg16_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-1000.\n",
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:08] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data saved to vgg16_embeddings_val.npz\n",
            "Uploaded vgg16_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "1000/2664 images done\n",
            "Downloading vgg16_embeddings_val.npz from GDrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/2664 images done already\n",
            "Running for image indices 1000-2000.\n",
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:06] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting vgg16_embeddings_val.npz from GDrive\n",
            "Data saved to vgg16_embeddings_val.npz\n",
            "Uploaded vgg16_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2000/2664 images done\n",
            "Downloading vgg16_embeddings_val.npz from GDrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2000/2664 images done already\n",
            "Running for image indices 2000-3000.\n",
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:05] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting vgg16_embeddings_val.npz from GDrive\n",
            "Data saved to vgg16_embeddings_val.npz\n",
            "Uploaded vgg16_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2664/2664 images done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t100n-LNgAnZ"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW2Ll3eegAna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c20b399-597e-4029-a8a4-c4c6b8978f3b"
      },
      "source": [
        "max_num_samples = 1000\n",
        "clip_val_filename = 'clip_embeddings_val.npz'\n",
        "\n",
        "clip_val_embedder = embedding_models.CLIPEmbeddingWrapper()\n",
        "\n",
        "run_data_through_model(\n",
        "    val_data, \n",
        "    clip_val_embedder, \n",
        "    clip_val_filename,\n",
        "    drive,\n",
        "    folderid,\n",
        "    total_val_images,\n",
        "    max_num_samples\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running for image indices 0-1000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |*                                 | (ETA:   0:00:03) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:05] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data saved to clip_embeddings_val.npz\n",
            "Uploaded clip_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "1000/2664 images done\n",
            "Downloading clip_embeddings_val.npz from GDrive\n",
            "1000/2664 images done already\n",
            "Running for image indices 1000-2000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***                               | (ETA:   0:00:01) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:01] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_val.npz from GDrive\n",
            "Data saved to clip_embeddings_val.npz\n",
            "Uploaded clip_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2000/2664 images done\n",
            "Downloading clip_embeddings_val.npz from GDrive\n",
            "2000/2664 images done already\n",
            "Running for image indices 2000-3000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |****                              | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |*******************************   | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Deleting clip_embeddings_val.npz from GDrive\n",
            "Data saved to clip_embeddings_val.npz\n",
            "Uploaded clip_embeddings_val.npz to https://drive.google.com/drive/u/1/folders/1AR8qp1QPFv0M3jCIQKK8VA2xsNilo_pi\n",
            "2664/2664 images done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}