{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WeightImprintingSoftmax_AllModels_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RGlVnbugxFK2",
        "3rKe3HqM523g",
        "9z1WQnXdLHy2",
        "zU_gxQ0KbwMh",
        "UxTa8MVsvQCN",
        "iLbRqaYxzbr7",
        "xP6ftkDCvKul"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTY7kA7DOzpV"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-7JU3Q7q_XT",
        "outputId": "c891d022-abee-4fe6-afe2-40666eecf39f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqqXI7Izk65p",
        "outputId": "d6ee93ee-85bc-43c0-9b0c-fc63ac8ec30f"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install httplib2==0.15.0\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.files import GoogleDriveFileList\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Cloning PAL_2021 to access modules.\n",
        "# Need password to access private repo.\n",
        "\n",
        "if 'CLIPPER' not in os.listdir():\n",
        "    cmd_string = 'git clone https://github.com/PAL-ML/CLIPPER.git'\n",
        "    os.system(cmd_string)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting httplib2==0.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/83/5e006e25403871ffbbf587c7aa4650158c947d46e89f2d50dcaf018464de/httplib2-0.15.0-py3-none-any.whl (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30kB 11.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 51kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 61kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 71kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 81kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 4.1MB/s \n",
            "\u001b[?25hInstalling collected packages: httplib2\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed httplib2-0.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlVnbugxFK2"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmgIrfT8hDNE"
      },
      "source": [
        "## Install multi label metrics dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6xXPAFbe6Gp",
        "outputId": "344d051a-bbd5-4810-ff85-10780e128fef"
      },
      "source": [
        "! pip install scikit-learn==0.24"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.24\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/ed/ab51a8da34d2b3f4524b21093081e7f9e2ddf1c9eac9f795dcf68ad0a57d/scikit_learn-0.24.0-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.4.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.0.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.0 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKe3HqM523g"
      },
      "source": [
        "## Install CLIP dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poS-WNDixIhY"
      },
      "source": [
        "# import subprocess\n",
        "\n",
        "# CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "# print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "# if CUDA_version == \"10.0\":\n",
        "#     torch_version_suffix = \"+cu100\"\n",
        "# elif CUDA_version == \"10.1\":\n",
        "#     torch_version_suffix = \"+cu101\"\n",
        "# elif CUDA_version == \"10.2\":\n",
        "#     torch_version_suffix = \"\"\n",
        "# else:\n",
        "#     torch_version_suffix = \"+cu110\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-69W8M59nA"
      },
      "source": [
        "# ! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYwBZS1N6A3d"
      },
      "source": [
        "# ! pip install ftfy regex\n",
        "# ! wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oIcNBYB8lz3"
      },
      "source": [
        "# !pip install git+https://github.com/Sri-vatsa/CLIP # using this fork because of visualization capabilities"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-gp7n8__E"
      },
      "source": [
        "## Install clustering dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLg9ozo9Hvc"
      },
      "source": [
        "!pip -q install umap-learn>=0.3.7"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1WQnXdLHy2"
      },
      "source": [
        "## Install dataset manager dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1vvMx7_LLSp",
        "outputId": "d6e40527-0a08-4811-f874-f1ad7762e79b"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=b86576e537eac8448d6b0a6e7271da794350710fa62e395512bc0a92a7fd137e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzsubsEm72rr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZI62a6G74kw"
      },
      "source": [
        "# ML Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import keras\n",
        "\n",
        "# Data processing\n",
        "import PIL\n",
        "import base64\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from matplotlib import cm\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Models\n",
        "# import clip\n",
        "\n",
        "# Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Clustering\n",
        "# import umap\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "#from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Misc\n",
        "import progressbar\n",
        "import logging\n",
        "from abc import ABC, abstractmethod\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.metrics import jaccard_score, hamming_loss, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "# Modules\n",
        "# from CLIPPER.code.ExperimentModules import embedding_models\n",
        "from CLIPPER.code.ExperimentModules.dataset_manager import DatasetManager\n",
        "from CLIPPER.code.ExperimentModules.weight_imprinting_classifier import WeightImprintingClassifier\n",
        "from CLIPPER.code.ExperimentModules import simclr_data_augmentations\n",
        "from CLIPPER.code.ExperimentModules.utils import (save_npy, load_npy, \n",
        "                                                       get_folder_id, \n",
        "                                                       create_expt_dir, \n",
        "                                                       save_to_drive, \n",
        "                                                       load_all_from_drive_folder, \n",
        "                                                       download_file_by_name, \n",
        "                                                       delete_file_by_name)\n",
        "\n",
        "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_gxQ0KbwMh"
      },
      "source": [
        "# Initialization & Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND-Q6dDoYmDu"
      },
      "source": [
        "## Dataset details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bih5tBPdbx3u",
        "outputId": "1ff4a2ff-27ac-4072-d375-ca92115bd775"
      },
      "source": [
        "folder_name = \"CIFAR10-Embeddings-28-02-21\"\n",
        "\n",
        "# Change parentid to match that of experiments root folder in gdrive\n",
        "parentid = '1bK72W-Um20EQDEyChNhNJthUNbmoSEjD'\n",
        "\n",
        "# Filepaths\n",
        "test_labels_filename = \"test_labels.npz\"\n",
        "\n",
        "test_embeddings_filename_suffix = \"_embeddings_test.npz\"\n",
        "\n",
        "# Initialize sepcific experiment folder in drive\n",
        "folderid = create_expt_dir(drive, parentid, folder_name)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: CIFAR10-Embeddings-28-02-21, id: 1GKPlpMFB9DilMM4201GQAHVokIL94d_N\n",
            "Experiment folder already exists. WARNING: Following with this run might overwrite existing results stored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTHwQiOvljNU"
      },
      "source": [
        "## Few shot learning parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbRNiKZKlmQP"
      },
      "source": [
        "num_ways = 5 # [5, 10]\n",
        "num_shot = 5 # [5, 1]\n",
        "num_eval = 15 # [5, 10, 15, 19]\n",
        "num_episodes = 100\n",
        "shuffle = False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxTa8MVsvQCN"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6S124Jfwuu5",
        "outputId": "002069b2-973c-425b-ea0d-ef6ec1680916"
      },
      "source": [
        "def get_ndarray_from_drive(drive, folderid, filename):\n",
        "    download_file_by_name(drive, folderid, filename)\n",
        "    return np.load(filename)['data']\n",
        "\n",
        "test_labels = get_ndarray_from_drive(drive, folderid, test_labels_filename)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading test_labels.npz from GDrive\n",
            "Downloading test_labels.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLbRqaYxzbr7"
      },
      "source": [
        "# Create label dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emz85fNX0Vif",
        "outputId": "02401e5c-776b-4a89-cfd0-43915c1d0c95"
      },
      "source": [
        "unique_labels = np.unique(test_labels)\n",
        "print(len(unique_labels))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TubS-RLzeVM"
      },
      "source": [
        "label_dictionary = {la:[] for la in unique_labels}\n",
        "\n",
        "for i in range(len(test_labels)):\n",
        "    la = test_labels[i]\n",
        "\n",
        "    label_dictionary[la].append(i)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP6ftkDCvKul"
      },
      "source": [
        "# Weight Imprinting models on train data embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJIGo_R86GQi"
      },
      "source": [
        "## Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ-BvKBH6LuI"
      },
      "source": [
        "def calculate_single_label_accuracy(pred, y, label_mapping):\n",
        "    x = 0\n",
        "    for i, p in enumerate(pred):\n",
        "        pred_label = label_mapping[p]\n",
        "        if pred_label == y[i]:\n",
        "            x += 1\n",
        "    x = x/(i+1)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv68q8TH6tvG"
      },
      "source": [
        "def start_progress_bar(bar_len):\n",
        "    widgets = [\n",
        "        ' [', \n",
        "        progressbar.Timer(format= 'elapsed time: %(elapsed)s'), \n",
        "        '] ', \n",
        "        progressbar.Bar('*'),' (', \n",
        "        progressbar.ETA(), ') ', \n",
        "        ]\n",
        "    pbar = progressbar.ProgressBar(\n",
        "        max_value=bar_len, widgets=widgets\n",
        "        ).start()\n",
        "    return pbar"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUpPZ6ti6IEp"
      },
      "source": [
        "def run_evaluations(\n",
        "    embeddings, \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways,\n",
        "    verbose=True,\n",
        "    metrics=[\"accuracy\", \"c_f1\"]\n",
        "):\n",
        "    accuracies = []\n",
        "    f1_scores = []\n",
        "\n",
        "    if verbose:\n",
        "        pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "    for i in range(num_episodes):\n",
        "        wi_x = embeddings[train_indices[i]]\n",
        "        wi_x = WeightImprintingClassifier.preprocess_input(wi_x)\n",
        "        eval_x = embeddings[eval_indices[i]]\n",
        "        eval_x = WeightImprintingClassifier.preprocess_input(eval_x)\n",
        "\n",
        "        wi_weights, label_mapping = WeightImprintingClassifier.get_imprinting_weights(\n",
        "            wi_x, wi_y[i], False\n",
        "            )\n",
        "\n",
        "        wi_parameters = {\n",
        "            \"num_classes\": num_ways,\n",
        "            \"input_dims\": wi_x.shape[-1],\n",
        "            \"scale\": False,\n",
        "            \"dense_layer_weights\": wi_weights\n",
        "        }\n",
        "\n",
        "        wi_cls = WeightImprintingClassifier(wi_parameters)\n",
        "\n",
        "        # Evaluate the weight imprinting model\n",
        "        metric_vals = wi_cls.evaluate_single_label_metrics(eval_x, eval_y[i], label_mapping, metrics=metrics)\n",
        "        if \"accuracy\" in metrics:\n",
        "            accuracies.append(metric_vals[\"accuracy\"])  \n",
        "        if \"c_f1\" in metrics:\n",
        "            f1_scores.append(metric_vals[\"c_f1\"])\n",
        "\n",
        "        del wi_x\n",
        "        del eval_x\n",
        "        del wi_cls\n",
        "\n",
        "        if verbose:\n",
        "            pbar.update(i+1)\n",
        "\n",
        "    metric_arrays = []\n",
        "    if \"accuracy\" in metrics:\n",
        "        metric_arrays.append(accuracies)\n",
        "    if \"c_f1\" in metrics:\n",
        "        metric_arrays.append(f1_scores)\n",
        "\n",
        "    return metric_arrays"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2XrPKY9EJeG"
      },
      "source": [
        "## Picking indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_S_4DanEJeH",
        "outputId": "99c43eea-3820-4b44-c964-8e3228487686"
      },
      "source": [
        "eval_indices = []\n",
        "train_indices = []\n",
        "wi_y = []\n",
        "eval_y = []\n",
        "\n",
        "label_dictionary = {la:label_dictionary[la] for la in label_dictionary if len(label_dictionary[la]) >= (num_shot+num_eval)}\n",
        "unique_labels = list(label_dictionary.keys())\n",
        "\n",
        "pbar = start_progress_bar(num_episodes)\n",
        "\n",
        "for s in range(num_episodes):\n",
        "    # Setting random seed for replicability\n",
        "    np.random.seed(s)\n",
        "\n",
        "    _train_indices = []\n",
        "    _eval_indices = []\n",
        "\n",
        "    selected_labels = np.random.choice(unique_labels, size=num_ways, replace=False)\n",
        "    for la in selected_labels:\n",
        "        la_indices = label_dictionary[la]\n",
        "        select = np.random.choice(la_indices, size = num_shot+num_eval, replace=False)\n",
        "        tr_idx = list(select[:num_shot])\n",
        "        ev_idx = list(select[num_shot:])\n",
        "\n",
        "        _train_indices = _train_indices + tr_idx\n",
        "        _eval_indices = _eval_indices + ev_idx\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.shuffle(_train_indices)\n",
        "        np.random.shuffle(_eval_indices)\n",
        "\n",
        "    train_indices.append(_train_indices)\n",
        "    eval_indices.append(_eval_indices)\n",
        "\n",
        "    _wi_y = test_labels[_train_indices]\n",
        "    _eval_y = test_labels[_eval_indices]\n",
        "\n",
        "    wi_y.append(_wi_y)\n",
        "    eval_y.append(_eval_y)\n",
        "\n",
        "    pbar.update(s+1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |***************************       | (ETA:   0:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOdSfodivGga"
      },
      "source": [
        "## Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO5MzYeWzKBr",
        "outputId": "2118ddfb-4e5e-41a0-de3b-78b4571633cf"
      },
      "source": [
        "# Load numpy data from drive\n",
        "inceptionv3_embeddings_test_fn = \"inceptionv3\" + test_embeddings_filename_suffix\n",
        "\n",
        "inceptionv3_embeddings_test = get_ndarray_from_drive(drive, folderid, inceptionv3_embeddings_test_fn)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading inceptionv3_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM6-e3gtxJX-",
        "outputId": "55b98817-6e08-4b50-ec0d-918a2c6acd37"
      },
      "source": [
        "inceptionv3_accuracies, inceptionv3_f1_scores = run_evaluations(\n",
        "    inceptionv3_embeddings_test, \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:23] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MEo_xCIwo7U",
        "outputId": "4a56c682-2e4f-4eb5-e4ab-b3969ff8c450"
      },
      "source": [
        "inceptionv3_mean_accuracy = np.mean(inceptionv3_accuracies)\n",
        "print(\"Inceptionv3 Mean accuracy: \", inceptionv3_mean_accuracy)\n",
        "inceptionv3_mean_f1_score = np.mean(inceptionv3_f1_scores)\n",
        "print(\"Inceptionv3 Mean f1 score: \", inceptionv3_mean_f1_score)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inceptionv3 Mean accuracy:  0.4593333333333332\n",
            "Inceptionv3 Mean f1 score:  0.45041905569303997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kKBQlF6C2pM"
      },
      "source": [
        "## Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exo-5cHDC2pO",
        "outputId": "0d93af28-a26e-4634-ce84-297da69f8ef7"
      },
      "source": [
        "resnet50_embeddings_test_fn = \"resnet50\" + test_embeddings_filename_suffix\n",
        "resnet50_embeddings_test = get_ndarray_from_drive(drive, folderid, resnet50_embeddings_test_fn)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading resnet50_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PVqyaYfxnwv",
        "outputId": "42b83ccf-7488-4b89-9e87-70a14e91962b"
      },
      "source": [
        "resnet50_accuracies, resnet50_f1_scores = run_evaluations(\n",
        "    resnet50_embeddings_test, \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:17] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQcPvZEK3vS2",
        "outputId": "74f6af94-e636-4a6e-f2fd-bcd0bbb2af76"
      },
      "source": [
        "resnet50_mean_accuracy = np.mean(resnet50_accuracies)\n",
        "print(\"Resnet 50 Mean accuracy: \", resnet50_mean_accuracy)\n",
        "resnet50_mean_f1_score = np.mean(resnet50_f1_scores)\n",
        "print(\"Resnet 50 Mean f1 score: \", resnet50_mean_f1_score)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resnet 50 Mean accuracy:  0.6666666666666665\n",
            "Resnet 50 Mean f1 score:  0.6616931358869378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WfqxT8TC3sN"
      },
      "source": [
        "## MoCo Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf9XU2CUC3sN",
        "outputId": "6289b408-9d80-47b1-bfd7-0852ab4a7682"
      },
      "source": [
        "moco_resnet50_embeddings_test_fn = \"moco_resnet50\" + test_embeddings_filename_suffix\n",
        "\n",
        "moco_resnet50_embeddings_test = get_ndarray_from_drive(drive, folderid, moco_resnet50_embeddings_test_fn)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading moco_resnet50_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZENU8nJxuP5",
        "outputId": "acfa0cb0-8a80-4e87-fdec-ada2609e35c1"
      },
      "source": [
        "moco_resnet50_accuracies, moco_resnet50_f1_scores = run_evaluations(\n",
        "    moco_resnet50_embeddings_test, \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:17] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep29BAUw4Ry4",
        "outputId": "1e7db0f2-1e98-4da5-dd85-6565811ae5a0"
      },
      "source": [
        "moco_resnet50_mean_accuracy = np.mean(moco_resnet50_accuracies)\n",
        "print(\"Moco Resnet Mean accuracy: \", moco_resnet50_mean_accuracy)\n",
        "moco_resnet50_mean_f1_score = np.mean(moco_resnet50_f1_scores)\n",
        "print(\"Moco Resnet Mean f1 score: \", moco_resnet50_mean_f1_score)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Moco Resnet Mean accuracy:  0.6413333333333334\n",
            "Moco Resnet Mean f1 score:  0.6361027522421296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpDsLlZgC4ZS"
      },
      "source": [
        "## PCL Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV9b5GHVC4ZS",
        "outputId": "84b38807-3e9d-4f8b-a531-94fae842d3d9"
      },
      "source": [
        "pcl_resnet50_embeddings_test_fn = \"pcl_resnet50\" + test_embeddings_filename_suffix\n",
        "\n",
        "pcl_resnet50_embeddings_test = get_ndarray_from_drive(drive, folderid, pcl_resnet50_embeddings_test_fn)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pcl_resnet50_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0NGfcwQxy48",
        "outputId": "03e27227-8bb6-4854-8c08-aed9dc063544"
      },
      "source": [
        "pcl_resnet50_accuracies, pcl_resnet50_f1_scores = run_evaluations(\n",
        "    pcl_resnet50_embeddings_test, \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:18] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q_fXQ864lik",
        "outputId": "88e49d98-4332-4ee3-ed5e-6ef0f854b075"
      },
      "source": [
        "pcl_resnet50_mean_accuracy = np.mean(pcl_resnet50_accuracies)\n",
        "print(\"PCL Resnet Mean accuracy: \", pcl_resnet50_mean_accuracy)\n",
        "pcl_resnet50_mean_f1_score = np.mean(pcl_resnet50_f1_scores)\n",
        "print(\"PCL Resnet Mean f1 score: \", pcl_resnet50_mean_f1_score)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PCL Resnet Mean accuracy:  0.6429333333333332\n",
            "PCL Resnet Mean f1 score:  0.6360187649762978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRktKMM1FBQj"
      },
      "source": [
        "## SwAV Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PVlxnZ_FBQl",
        "outputId": "d87748a3-cc02-470b-a167-1471e653d24b"
      },
      "source": [
        "swav_resnet50_embeddings_test_fn = \"swav_resnet50\" + test_embeddings_filename_suffix\n",
        "\n",
        "swav_resnet50_embeddings_test = get_ndarray_from_drive(drive, folderid, swav_resnet50_embeddings_test_fn)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading swav_resnet50_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee0t6Hunx3TV",
        "outputId": "f22d3ec6-4798-4cdf-bbd5-6c799ce64970"
      },
      "source": [
        "swav_resnet50_accuracies, swav_resnet50_f1_scores = run_evaluations(\n",
        "    swav_resnet50_embeddings_test, \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:18] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXPWqOW55LRX",
        "outputId": "c42232cf-088b-4f5a-b7a7-808c863ee5e1"
      },
      "source": [
        "swav_resnet50_mean_accuracy = np.mean(swav_resnet50_accuracies)\n",
        "print(\"Swav Resnet Mean accuracy: \", swav_resnet50_mean_accuracy)\n",
        "swav_resnet50_mean_f1_score = np.mean(swav_resnet50_f1_scores)\n",
        "print(\"Swav Resnet Mean f1 score: \", swav_resnet50_mean_f1_score)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Swav Resnet Mean accuracy:  0.5482666666666667\n",
            "Swav Resnet Mean f1 score:  0.5391418687944198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUuQyU_pFBy5"
      },
      "source": [
        "## SimCLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEBOCPwlFBy6",
        "outputId": "75365701-47f8-4d97-bf87-c414a3e72299"
      },
      "source": [
        "simclr_embeddings_test_fn = \"simclr\" + test_embeddings_filename_suffix\n",
        "\n",
        "simclr_embeddings_test = get_ndarray_from_drive(drive, folderid, simclr_embeddings_test_fn)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading simclr_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy6wWNV7x63R",
        "outputId": "a486cdc9-8152-4f7b-93cd-dc1673201d97"
      },
      "source": [
        "simclr_accuracies, simclr_f1_scores = run_evaluations(\n",
        "    simclr_embeddings_test, \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:17] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsGJt2GS5wu7",
        "outputId": "25afd13f-2083-48fb-caa6-318448081f5e"
      },
      "source": [
        "simclr_mean_accuracy = np.mean(simclr_accuracies)\n",
        "print(\"Simclr Mean accuracy: \", simclr_mean_accuracy)\n",
        "simclr_mean_f1_score = np.mean(simclr_f1_scores)\n",
        "print(\"Simclr Mean f1 score: \", simclr_mean_f1_score)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simclr Mean accuracy:  0.7685333333333334\n",
            "Simclr Mean f1 score:  0.7648372919531394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9TjD20ZF--3"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_nT_W7eF--5",
        "outputId": "28b0c57d-4bea-478e-a987-8c3890d0e9f7"
      },
      "source": [
        "vgg16_embeddings_test_fn = \"vgg16\" + test_embeddings_filename_suffix\n",
        "\n",
        "vgg16_embeddings_test = get_ndarray_from_drive(drive, folderid, vgg16_embeddings_test_fn)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading vgg16_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMDgkyZVyBIS",
        "outputId": "81570351-723e-491d-cdbe-b4bf91184573"
      },
      "source": [
        "vgg16_accuracies, vgg16_f1_scores = run_evaluations(\n",
        "    vgg16_embeddings_test, \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:18] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB1ONpxC7UJF",
        "outputId": "632c2662-4020-4d80-c9a2-8e263728186a"
      },
      "source": [
        "vgg16_mean_accuracy = np.mean(vgg16_accuracies)\n",
        "print(\"VGG16 Mean accuracy: \", vgg16_mean_accuracy)\n",
        "vgg16_mean_f1_score = np.mean(vgg16_f1_scores)\n",
        "print(\"VGG16 Mean f1 score: \", vgg16_mean_f1_score)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG16 Mean accuracy:  0.7364\n",
            "VGG16 Mean f1 score:  0.7326119458759817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9dYlVFDF_vs"
      },
      "source": [
        "## CLIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y6RpvnEF_vs",
        "outputId": "b041289c-f2ae-4a75-b521-b6a5d3e62bcc"
      },
      "source": [
        "clip_embeddings_test_fn = \"clip\" + test_embeddings_filename_suffix\n",
        "\n",
        "clip_embeddings_test = get_ndarray_from_drive(drive, folderid, clip_embeddings_test_fn)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading clip_embeddings_test.npz from GDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obC4ZNZ-yFPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10db6ba-e0ec-4357-d848-1943ce8fbb75"
      },
      "source": [
        "clip_accuracies, clip_f1_scores = run_evaluations(\n",
        "    clip_embeddings_test, \n",
        "    train_indices, \n",
        "    eval_indices, \n",
        "    wi_y, \n",
        "    eval_y, \n",
        "    num_episodes, \n",
        "    num_ways\n",
        ")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:18] |**********************************| (ETA:  00:00:00) "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDVdzHOH8Lf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20023308-9975-4c9b-e290-f725a846c1f8"
      },
      "source": [
        "clip_mean_accuracy = np.mean(clip_accuracies)\n",
        "print(\"CLIP Mean accuracy: \", clip_mean_accuracy)\n",
        "clip_mean_f1_score = np.mean(clip_f1_scores)\n",
        "print(\"CLIP Mean f1 score: \", clip_mean_f1_score)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CLIP Mean accuracy:  0.8864\n",
            "CLIP Mean f1 score:  0.886604803626261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn0jXMft8yHQ"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is2QJads_ON_"
      },
      "source": [
        "mean_accuracy_dict={\n",
        "    inceptionv3_mean_accuracy: \"Inception V3\",\n",
        "    resnet50_mean_accuracy: \"Resnet 50\",\n",
        "    moco_resnet50_mean_accuracy: \"MoCo Resnet 50\",\n",
        "    pcl_resnet50_mean_accuracy: \"PCL Resnet 50\",\n",
        "    swav_resnet50_mean_accuracy: \"SwAV Resnet 50\",\n",
        "    simclr_mean_accuracy: \"SimCLR\",\n",
        "    vgg16_mean_accuracy: \"VGG 16\", \n",
        "    clip_mean_accuracy: \"CLIP\"\n",
        "}\n",
        "\n",
        "acc_vals = sorted(list(mean_accuracy_dict.keys()), reverse=True)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjkXM_CZHCON"
      },
      "source": [
        "mean_f1_score_dict={\n",
        "    inceptionv3_mean_f1_score: \"Inception V3\",\n",
        "    resnet50_mean_f1_score: \"Resnet 50\",\n",
        "    moco_resnet50_mean_f1_score: \"MoCo Resnet 50\",\n",
        "    pcl_resnet50_mean_f1_score: \"PCL Resnet 50\",\n",
        "    swav_resnet50_mean_f1_score: \"SwAV Resnet 50\",\n",
        "    simclr_mean_f1_score: \"SimCLR\",\n",
        "    vgg16_mean_f1_score: \"VGG 16\", \n",
        "    clip_mean_f1_score: \"CLIP\"\n",
        "}\n",
        "\n",
        "f1_vals = sorted(list(mean_f1_score_dict.keys()), reverse=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVc0H-s_F0M1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1859f4-c8f1-4374-e0ed-948799495049"
      },
      "source": [
        "print(\"All accuracies for {} way {} shot classification on CIFAR10 with {} random episodes- \".format(\n",
        "    num_ways, num_shot, num_episodes\n",
        "    ))\n",
        "for val in acc_vals:\n",
        "    print(mean_accuracy_dict[val], \": \", val)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All accuracies for 5 way 5 shot classification on CIFAR10 with 100 random episodes- \n",
            "CLIP :  0.8864\n",
            "SimCLR :  0.7685333333333334\n",
            "VGG 16 :  0.7364\n",
            "Resnet 50 :  0.6666666666666665\n",
            "PCL Resnet 50 :  0.6429333333333332\n",
            "MoCo Resnet 50 :  0.6413333333333334\n",
            "SwAV Resnet 50 :  0.5482666666666667\n",
            "Inception V3 :  0.4593333333333332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf7RFuo0K6-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a01010-342c-47b9-b3c6-556899868488"
      },
      "source": [
        "print(\"All f1 scores for {} way {} shot classification on Omniglot with {} random episodes- \".format(\n",
        "    num_ways, num_shot, num_episodes\n",
        "    ))\n",
        "for val in f1_vals:\n",
        "    print(mean_f1_score_dict[val], \": \", val)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All f1 scores for 5 way 5 shot classification on Omniglot with 100 random episodes- \n",
            "CLIP :  0.886604803626261\n",
            "SimCLR :  0.7648372919531394\n",
            "VGG 16 :  0.7326119458759817\n",
            "Resnet 50 :  0.6616931358869378\n",
            "MoCo Resnet 50 :  0.6361027522421296\n",
            "PCL Resnet 50 :  0.6360187649762978\n",
            "SwAV Resnet 50 :  0.5391418687944198\n",
            "Inception V3 :  0.45041905569303997\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}